{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_ml_models_part3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZPzHReth5qU"
      },
      "source": [
        "# import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "# for making the output constant across all run\n",
        "np.random.seed(42)\n",
        "\n",
        "# display settings & code formatting\n",
        "pd.options.display.max_columns = 999\n",
        "%matplotlib inline\n",
        "\n",
        "# project paths\n",
        "# project_root_dir = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
        "\n",
        "# data_path = os.path.join(project_root_dir, \"data\")\n",
        "# os.makedirs(data_path, exist_ok=True)\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/workspace/walmart/data\"\n",
        "\n",
        "# function for loading data\n",
        "def read_data(filename, date_col=None, data_path=data_path):\n",
        "    csv_path = os.path.join(data_path, filename)\n",
        "    return pd.read_csv(csv_path, parse_dates=date_col)\n",
        "\n",
        "# function for saving data as csv file\n",
        "def save_dataframe(df, filename, file_path=data_path):\n",
        "    path = os.path.join(file_path, filename)\n",
        "    df.to_csv(path, index=False)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVY3GG2PiHsR"
      },
      "source": [
        "## Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6980RcWiPup",
        "outputId": "acce1ea5-c58e-4cbe-d449-7a3525c33677"
      },
      "source": [
        "# Read data\n",
        "train = read_data(\"train.csv\", date_col=[\"Date\"])\n",
        "test = read_data(\"test.csv\", date_col=[\"Date\"])\n",
        "stores = read_data(\"stores.csv\")\n",
        "features = read_data(\"features.csv\", date_col=[\"Date\"])\n",
        "sample_submission = read_data(\"sampleSubmission.csv\")\n",
        "\n",
        "\n",
        "# Merge the stores data with train and test\n",
        "train = pd.merge(train, stores, how=\"left\", on=\"Store\")\n",
        "test = pd.merge(test, stores, how=\"left\", on=\"Store\")\n",
        "\n",
        "# Merge the features data with train and test\n",
        "train = pd.merge(train, features, how=\"left\", on=[\"Store\", \"Date\"])\n",
        "test = pd.merge(test, features, how=\"left\", on=[\"Store\", \"Date\"])\n",
        "\n",
        "train.drop([\"IsHoliday_y\"], axis=1, inplace=True)\n",
        "test.drop([\"IsHoliday_y\"], axis=1, inplace=True)\n",
        "\n",
        "# rename column\n",
        "train.rename(columns={\"IsHoliday_x\": \"IsHoliday\"}, inplace=True)\n",
        "test.rename(columns={\"IsHoliday_x\": \"IsHoliday\"}, inplace=True)\n",
        "\n",
        "## Datetime features\n",
        "train[\"Year\"] = train[\"Date\"].dt.year\n",
        "train[\"Month\"] = train[\"Date\"].dt.month\n",
        "train[\"Day\"] = train[\"Date\"].dt.day\n",
        "train[\"WeekOfYear\"] = train[\"Date\"].dt.weekofyear\n",
        "train[\"DayOfWeek\"] = train[\"Date\"].dt.dayofweek\n",
        "train[\"Weekend\"] = (train[\"Date\"].dt.weekday >= 5).astype(int)\n",
        "\n",
        "test[\"Year\"] = test[\"Date\"].dt.year\n",
        "test[\"Month\"] = test[\"Date\"].dt.month\n",
        "test[\"Day\"] = test[\"Date\"].dt.day\n",
        "test[\"WeekOfYear\"] = test[\"Date\"].dt.weekofyear\n",
        "test[\"DayOfWeek\"] = test[\"Date\"].dt.dayofweek\n",
        "test[\"Weekend\"] = (test[\"Date\"].dt.weekday >= 5).astype(int)\n",
        "\n",
        "# convert boolean column to categorical column\n",
        "train[\"IsHoliday\"] = train[\"IsHoliday\"].map({True: \"Yes\", False: \"No\"})\n",
        "test[\"IsHoliday\"] = test[\"IsHoliday\"].map({True: \"Yes\", False: \"No\"})\n",
        "train[\"IsHoliday\"] = train[\"IsHoliday\"].astype(\"category\")\n",
        "test[\"IsHoliday\"] = test[\"IsHoliday\"].astype(\"category\")\n",
        "\n",
        "# ordered the categorical store type col\n",
        "from pandas.api.types import CategoricalDtype\n",
        "\n",
        "cat_type = CategoricalDtype(categories=[\"C\", \"B\", \"A\"], ordered=True)\n",
        "train[\"Type\"] = train[\"Type\"].astype(cat_type)\n",
        "test[\"Type\"] = test[\"Type\"].astype(cat_type)\n",
        "\n",
        "# convert to categorical columns\n",
        "train[\"Store\"] = train[\"Store\"].astype(\"category\")\n",
        "train[\"Dept\"] = train[\"Dept\"].astype(\"category\")\n",
        "train[\"Year\"] = train[\"Year\"].astype(\"category\")\n",
        "train[\"Month\"] = train[\"Month\"].astype(\"category\")\n",
        "train[\"DayOfWeek\"] = train[\"DayOfWeek\"].astype(\"category\")\n",
        "train[\"Weekend\"] = train[\"Weekend\"].astype(\"category\")\n",
        "\n",
        "# convert to categorical columns\n",
        "test[\"Store\"] = test[\"Store\"].astype(\"category\")\n",
        "test[\"Dept\"] = test[\"Dept\"].astype(\"category\")\n",
        "test[\"Year\"] = test[\"Year\"].astype(\"category\")\n",
        "test[\"Month\"] = test[\"Month\"].astype(\"category\")\n",
        "test[\"DayOfWeek\"] = test[\"DayOfWeek\"].astype(\"category\")\n",
        "test[\"Weekend\"] = test[\"Weekend\"].astype(\"category\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: FutureWarning:\n",
            "\n",
            "Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: FutureWarning:\n",
            "\n",
            "Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jekUOl9DivAP"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "# features and labels of train and test set\n",
        "# labels of test are not provided as we need to predict them\n",
        "\n",
        "X_train = train.drop([\"Weekly_Sales\"], axis=1).copy()\n",
        "y_train = train[\"Weekly_Sales\"].copy()\n",
        "\n",
        "X_test = test.copy()\n",
        "\n",
        "# drop and save the date column in a variable\n",
        "train_date = X_train.pop(\"Date\")\n",
        "test_date = X_test.pop(\"Date\")\n",
        "\n",
        "\n",
        "#### Data preparation pipeline\n",
        "\n",
        "# select numerical and categorical columns\n",
        "num_cols = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "\n",
        "# numerical date preprocessing pipeline\n",
        "num_pipe = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
        "\n",
        "# categorical data preprocessing pipeline\n",
        "cat_pipe = make_pipeline(\n",
        "    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n",
        "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
        ")\n",
        "\n",
        "# full pipeline\n",
        "full_pipe = ColumnTransformer(\n",
        "    [(\"num\", num_pipe, num_cols), (\"cat\", cat_pipe, cat_cols)]\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-2YtCAejBfm"
      },
      "source": [
        "X_train_tr = full_pipe.fit_transform(X_train)\n",
        "X_test_tr = full_pipe.transform(X_test)\n",
        "\n",
        "\n",
        "# Get the list of categories generated by the one-hot-encoder\n",
        "ohe_categories = full_pipe.named_transformers_.cat.named_steps.onehotencoder.categories_\n",
        "\n",
        "# Create nice names for our one hot encoded features\n",
        "new_ohe_features = [\n",
        "    f\"{col}__{val}\" for col, vals in zip(cat_cols, ohe_categories) for val in vals\n",
        "]\n",
        "\n",
        "# Create a new list with all names of features\n",
        "all_features = num_cols + new_ohe_features\n",
        "\n",
        "# Create pandas dataframe\n",
        "X_train_tr = pd.DataFrame(X_train_tr, columns=all_features)\n",
        "X_test_tr = pd.DataFrame(X_test_tr, columns=all_features)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_tr, X_valid_tr, y_train, y_valid = train_test_split(X_train_tr,y_train, test_size=0.2, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS64uwTQjLiX"
      },
      "source": [
        "## Build deep Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL9XPb0XjT-C"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVd7X34UjWku"
      },
      "source": [
        "# model = keras.models.Sequential([\n",
        "#         keras.layers.Dense(64, activation=\"relu\", input_shape=X_train_tr.shape[1:]),\n",
        "#         keras.layers.Dropout(0.2),\n",
        "#         keras.layers.Dense(64, activation=\"relu\"),\n",
        "#         keras.layers.Dropout(0.2),\n",
        "#         keras.layers.Dense(64, activation=\"relu\"),\n",
        "#         keras.layers.Dropout(0.2),\n",
        "#         keras.layers.Dense(1)\n",
        "# ])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhvP2whwjgMS"
      },
      "source": [
        "# # compile and train the model\n",
        "# model.compile(optimizer=\"rmsprop\", loss= keras.losses.Huber(), metrics=['mae'])\n",
        "# history = model.fit(X_train_tr, y_train,\n",
        "#                     validation_data=(X_valid_tr, y_valid),\n",
        "#                     epochs=25)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFKnDuW3ji-z"
      },
      "source": [
        "# results = pd.DataFrame(history.history)\n",
        "# results.head()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aXagw_ApbTE"
      },
      "source": [
        "# fig = go.Figure()\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=list(range(len(results))), \n",
        "#     y= results['loss'], \n",
        "#     name=\"Training Loss\" , \n",
        "#     mode=\"lines\",\n",
        "#     line=dict(color=\"blue\")))\n",
        "# fig.add_trace(go.Scatter(\n",
        "#     x=list(range(len(results))), \n",
        "#     y= results['val_loss'], \n",
        "#     name=\"Validation Loss\", \n",
        "#     mode=\"lines\",\n",
        "#     line=dict(color=\"green\")))\n",
        "# fig.update_layout(title=\"Training vs Validation Loss\",\n",
        "#                   xaxis=dict(title=\"Epochs\"),\n",
        "#                   yaxis=dict(title=\"Huber Loss\"))\n",
        "# fig.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGZx670HyQJO"
      },
      "source": [
        "def plot_loss(results):\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(\n",
        "      x=list(range(len(results))), \n",
        "      y= results['loss'], \n",
        "      name=\"Training Loss\" , \n",
        "      mode=\"lines\",\n",
        "      line=dict(color=\"blue\")))\n",
        "  fig.add_trace(go.Scatter(\n",
        "      x=list(range(len(results))), \n",
        "      y= results['val_loss'], \n",
        "      name=\"Validation Loss\", \n",
        "      mode=\"lines\",\n",
        "      line=dict(color=\"green\")))\n",
        "  fig.update_layout(title=\"Training vs Validation Loss\",\n",
        "                    xaxis=dict(title=\"Epochs\"),\n",
        "                    yaxis=dict(title=\"Huber Loss\"))\n",
        "  fig.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOgIEXCo0jRR"
      },
      "source": [
        "def plot_mae(results):\n",
        "  fig = go.Figure()\n",
        "  fig.add_trace(go.Scatter(\n",
        "      x=list(range(len(results))), \n",
        "      y= results['mae'], \n",
        "      name=\"Training MAE\" , \n",
        "      mode=\"lines\",\n",
        "      line=dict(color=\"blue\")))\n",
        "  fig.add_trace(go.Scatter(\n",
        "      x=list(range(len(results))), \n",
        "      y= results['val_mae'], \n",
        "      name=\"Validation MAE\", \n",
        "      mode=\"lines\",\n",
        "      line=dict(color=\"green\")))\n",
        "  fig.update_layout(title=\"Training vs Validation MAE\",\n",
        "                    xaxis=dict(title=\"Epochs\"),\n",
        "                    yaxis=dict(title=\"Mean Absolute Error\"))\n",
        "  fig.show()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnb8iJh2UyuF"
      },
      "source": [
        "## HyperParameter Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y9brkJ0qvNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14812d5d-fe5e-4496-9016-c1e5ac038e98"
      },
      "source": [
        "from scipy.stats import reciprocal\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "def build_model(n_hidden=1, n_neurons=32, learning_rate=3e-3, dropout=0.2,input_shape=X_train_tr.shape[1:]):\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
        "  for layer in range(n_hidden):\n",
        "    model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    keras.layers.Dropout(dropout)\n",
        "  model.add(keras.layers.Dense(1))\n",
        "  optimizer = keras.optimizers.RMSprop(lr=learning_rate)\n",
        "  model.compile(optimizer=optimizer, loss= keras.losses.Huber(), metrics=['mae'])\n",
        "  return model\n",
        "\n",
        "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
        "\n",
        "\n",
        "param_distribs = {\n",
        "    \"n_hidden\":[1, 2, 3, 4, 5, 6],\n",
        "    \"n_neurons\": np.arange(1,100),\n",
        "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
        "    \"dropout\":[0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
        "\n",
        "rnd_search_cv.fit(X_train_tr, y_train, epochs=100,\n",
        "                  validation_data=(X_valid_tr, y_valid),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 5681.3970 - mae: 5681.9141 - val_loss: 3517.1565 - val_mae: 3517.6545\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3232.2297 - mae: 3232.7314 - val_loss: 3064.6687 - val_mae: 3065.1687\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2920.9272 - mae: 2921.4312 - val_loss: 2869.9612 - val_mae: 2870.4604\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2744.0056 - mae: 2744.5037 - val_loss: 2718.2666 - val_mae: 2718.7659\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2611.7844 - mae: 2612.2812 - val_loss: 2542.0227 - val_mae: 2542.5222\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2509.5281 - mae: 2510.0264 - val_loss: 2511.6445 - val_mae: 2512.1440\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2439.4243 - mae: 2439.9260 - val_loss: 2528.6411 - val_mae: 2529.1409\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2380.1667 - mae: 2380.6648 - val_loss: 2501.6965 - val_mae: 2502.1963\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2331.9902 - mae: 2332.4873 - val_loss: 2336.5168 - val_mae: 2337.0168\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2294.7549 - mae: 2295.2490 - val_loss: 2430.7351 - val_mae: 2431.2349\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2258.9761 - mae: 2259.4717 - val_loss: 2261.4307 - val_mae: 2261.9307\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2236.0759 - mae: 2236.5803 - val_loss: 2363.9292 - val_mae: 2364.4290\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2216.5618 - mae: 2217.0659 - val_loss: 2220.3416 - val_mae: 2220.8411\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2199.2109 - mae: 2199.7144 - val_loss: 2198.6660 - val_mae: 2199.1653\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2180.0398 - mae: 2180.5403 - val_loss: 2215.7917 - val_mae: 2216.2913\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2165.1179 - mae: 2165.6189 - val_loss: 2190.3804 - val_mae: 2190.8799\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2151.8752 - mae: 2152.3757 - val_loss: 2186.8328 - val_mae: 2187.3325\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2140.2522 - mae: 2140.7551 - val_loss: 2299.6040 - val_mae: 2300.1038\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2126.5161 - mae: 2127.0171 - val_loss: 2132.9441 - val_mae: 2133.4436\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2118.0574 - mae: 2118.5576 - val_loss: 2137.2361 - val_mae: 2137.7356\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2107.3560 - mae: 2107.8574 - val_loss: 2727.3401 - val_mae: 2727.8401\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2096.7854 - mae: 2097.2869 - val_loss: 2183.7371 - val_mae: 2184.2371\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2088.2107 - mae: 2088.7129 - val_loss: 2140.1223 - val_mae: 2140.6221\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2082.6477 - mae: 2083.1528 - val_loss: 2103.7048 - val_mae: 2104.2048\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2072.8789 - mae: 2073.3804 - val_loss: 2101.3352 - val_mae: 2101.8345\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2064.1826 - mae: 2064.6804 - val_loss: 2076.4763 - val_mae: 2076.9758\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2058.4756 - mae: 2058.9724 - val_loss: 2062.6128 - val_mae: 2063.1123\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2051.4246 - mae: 2051.9324 - val_loss: 2069.2236 - val_mae: 2069.7231\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2042.4677 - mae: 2042.9674 - val_loss: 2161.6421 - val_mae: 2162.1416\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2035.3313 - mae: 2035.8289 - val_loss: 2098.5081 - val_mae: 2099.0071\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2033.5624 - mae: 2034.0640 - val_loss: 2087.9126 - val_mae: 2088.4121\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2028.3979 - mae: 2028.9025 - val_loss: 2183.7214 - val_mae: 2184.2212\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2020.1935 - mae: 2020.6887 - val_loss: 2090.3896 - val_mae: 2090.8896\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2013.1127 - mae: 2013.6134 - val_loss: 2094.5105 - val_mae: 2095.0103\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2007.9431 - mae: 2008.4436 - val_loss: 2034.1848 - val_mae: 2034.6842\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2005.6897 - mae: 2006.1906 - val_loss: 2065.6182 - val_mae: 2066.1179\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1998.7729 - mae: 1999.2711 - val_loss: 2100.5266 - val_mae: 2101.0264\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1994.1488 - mae: 1994.6381 - val_loss: 2028.3424 - val_mae: 2028.8419\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1988.4946 - mae: 1988.9939 - val_loss: 2101.5398 - val_mae: 2102.0396\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1986.6923 - mae: 1987.1952 - val_loss: 2222.3196 - val_mae: 2222.8196\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1980.6923 - mae: 1981.1945 - val_loss: 2031.9862 - val_mae: 2032.4858\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1978.9971 - mae: 1979.4985 - val_loss: 2024.2524 - val_mae: 2024.7522\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1976.4752 - mae: 1976.9742 - val_loss: 2000.2440 - val_mae: 2000.7437\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1972.4651 - mae: 1972.9670 - val_loss: 2031.4755 - val_mae: 2031.9753\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1966.4027 - mae: 1966.9033 - val_loss: 2062.5247 - val_mae: 2063.0239\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1958.9958 - mae: 1959.4994 - val_loss: 1988.6425 - val_mae: 1989.1423\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1958.4154 - mae: 1958.9178 - val_loss: 2056.2510 - val_mae: 2056.7510\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1953.1663 - mae: 1953.6656 - val_loss: 2056.2104 - val_mae: 2056.7102\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1949.6967 - mae: 1950.1989 - val_loss: 2066.7412 - val_mae: 2067.2412\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1948.2837 - mae: 1948.7876 - val_loss: 2013.0333 - val_mae: 2013.5331\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1944.9542 - mae: 1945.4568 - val_loss: 2003.3811 - val_mae: 2003.8805\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1940.8663 - mae: 1941.3636 - val_loss: 2061.0220 - val_mae: 2061.5210\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1936.9280 - mae: 1937.4314 - val_loss: 1955.4589 - val_mae: 1955.9587\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1932.4290 - mae: 1932.9305 - val_loss: 1946.2296 - val_mae: 1946.7292\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1926.7385 - mae: 1927.2369 - val_loss: 1999.5558 - val_mae: 2000.0554\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1924.7115 - mae: 1925.2120 - val_loss: 2008.7223 - val_mae: 2009.2220\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1921.5834 - mae: 1922.0829 - val_loss: 1965.1404 - val_mae: 1965.6399\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1921.8965 - mae: 1922.3903 - val_loss: 1947.8879 - val_mae: 1948.3875\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1919.5142 - mae: 1920.0135 - val_loss: 1946.0157 - val_mae: 1946.5154\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1915.8744 - mae: 1916.3704 - val_loss: 2028.5029 - val_mae: 2029.0027\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1914.3828 - mae: 1914.8829 - val_loss: 1996.9542 - val_mae: 1997.4539\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1909.3784 - mae: 1909.8784 - val_loss: 2213.6631 - val_mae: 2214.1628\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1910.6876 - mae: 1911.1892 - val_loss: 2000.1801 - val_mae: 2000.6797\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1905.4030 - mae: 1905.9066 - val_loss: 2096.9531 - val_mae: 2097.4529\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1903.5331 - mae: 1904.0359 - val_loss: 1961.8075 - val_mae: 1962.3071\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1903.9131 - mae: 1904.4119 - val_loss: 2012.1593 - val_mae: 2012.6593\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1899.9431 - mae: 1900.4434 - val_loss: 1924.6602 - val_mae: 1925.1599\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1898.1714 - mae: 1898.6667 - val_loss: 1910.7969 - val_mae: 1911.2964\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1894.0175 - mae: 1894.5138 - val_loss: 2046.6251 - val_mae: 2047.1248\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1895.7385 - mae: 1896.2385 - val_loss: 1923.4749 - val_mae: 1923.9741\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1889.1516 - mae: 1889.6484 - val_loss: 1905.6846 - val_mae: 1906.1842\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1889.0603 - mae: 1889.5563 - val_loss: 1922.3123 - val_mae: 1922.8120\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1887.7350 - mae: 1888.2310 - val_loss: 1961.9878 - val_mae: 1962.4878\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1885.4536 - mae: 1885.9541 - val_loss: 1991.7964 - val_mae: 1992.2957\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1881.8124 - mae: 1882.3099 - val_loss: 1975.9337 - val_mae: 1976.4336\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1878.2289 - mae: 1878.7310 - val_loss: 1965.7662 - val_mae: 1966.2657\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1877.0820 - mae: 1877.5812 - val_loss: 2159.1423 - val_mae: 2159.6416\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1874.6729 - mae: 1875.1766 - val_loss: 1958.1255 - val_mae: 1958.6251\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1875.2145 - mae: 1875.7145 - val_loss: 1900.4028 - val_mae: 1900.9028\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1868.1713 - mae: 1868.6669 - val_loss: 1909.7081 - val_mae: 1910.2079\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1871.5941 - mae: 1872.0929 - val_loss: 2038.8519 - val_mae: 2039.3516\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1867.8263 - mae: 1868.3285 - val_loss: 1957.1628 - val_mae: 1957.6625\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1866.3690 - mae: 1866.8666 - val_loss: 1895.9822 - val_mae: 1896.4816\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1863.2194 - mae: 1863.7185 - val_loss: 1942.7106 - val_mae: 1943.2100\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1859.7311 - mae: 1860.2263 - val_loss: 1900.1970 - val_mae: 1900.6968\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1859.5997 - mae: 1860.0978 - val_loss: 1898.2441 - val_mae: 1898.7439\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1858.8965 - mae: 1859.4021 - val_loss: 1902.0907 - val_mae: 1902.5906\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1856.4548 - mae: 1856.9564 - val_loss: 1950.9166 - val_mae: 1951.4156\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1852.8451 - mae: 1853.3477 - val_loss: 1901.7141 - val_mae: 1902.2131\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1852.7091 - mae: 1853.2131 - val_loss: 2017.0792 - val_mae: 2017.5791\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1852.9641 - mae: 1853.4597 - val_loss: 1888.8801 - val_mae: 1889.3798\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1849.0854 - mae: 1849.5797 - val_loss: 1953.3705 - val_mae: 1953.8701\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1851.0828 - mae: 1851.5797 - val_loss: 1894.1925 - val_mae: 1894.6919\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1846.6974 - mae: 1847.1945 - val_loss: 1930.6307 - val_mae: 1931.1304\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1843.0042 - mae: 1843.5027 - val_loss: 1894.7701 - val_mae: 1895.2698\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1842.9460 - mae: 1843.4518 - val_loss: 1852.5536 - val_mae: 1853.0531\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1837.8689 - mae: 1838.3705 - val_loss: 1858.4709 - val_mae: 1858.9705\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1839.4308 - mae: 1839.9326 - val_loss: 1878.1483 - val_mae: 1878.6479\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1836.2834 - mae: 1836.7880 - val_loss: 1898.0243 - val_mae: 1898.5239\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1834.8414 - mae: 1835.3372 - val_loss: 1927.9857 - val_mae: 1928.4855\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 1920.4335 - mae: 1920.9332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 5754.7183 - mae: 5755.2236 - val_loss: 3609.4766 - val_mae: 3609.9734\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3323.8799 - mae: 3324.3831 - val_loss: 3189.5078 - val_mae: 3190.0076\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2968.9460 - mae: 2969.4475 - val_loss: 2860.9031 - val_mae: 2861.4023\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2755.5000 - mae: 2756.0005 - val_loss: 2720.3613 - val_mae: 2720.8608\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2618.4863 - mae: 2618.9827 - val_loss: 2594.0027 - val_mae: 2594.5024\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2519.2212 - mae: 2519.7219 - val_loss: 2461.8665 - val_mae: 2462.3660\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2451.7573 - mae: 2452.2532 - val_loss: 2449.7634 - val_mae: 2450.2629\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2396.4568 - mae: 2396.9595 - val_loss: 2430.8423 - val_mae: 2431.3418\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2347.9141 - mae: 2348.4211 - val_loss: 2414.7815 - val_mae: 2415.2812\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2301.0198 - mae: 2301.5186 - val_loss: 2347.4578 - val_mae: 2347.9573\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2263.7402 - mae: 2264.2432 - val_loss: 2266.5669 - val_mae: 2267.0664\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2230.4106 - mae: 2230.9055 - val_loss: 2292.9143 - val_mae: 2293.4138\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2200.1606 - mae: 2200.6560 - val_loss: 2314.4294 - val_mae: 2314.9290\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2176.1052 - mae: 2176.6101 - val_loss: 2190.7573 - val_mae: 2191.2573\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2160.3567 - mae: 2160.8582 - val_loss: 2323.2607 - val_mae: 2323.7607\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2138.7461 - mae: 2139.2466 - val_loss: 2163.4443 - val_mae: 2163.9438\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2123.8628 - mae: 2124.3691 - val_loss: 2204.6643 - val_mae: 2205.1638\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2110.6758 - mae: 2111.1704 - val_loss: 2135.8728 - val_mae: 2136.3728\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2095.0493 - mae: 2095.5457 - val_loss: 2100.4553 - val_mae: 2100.9551\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2084.7214 - mae: 2085.2188 - val_loss: 2507.4324 - val_mae: 2507.9319\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2072.5596 - mae: 2073.0566 - val_loss: 2448.3337 - val_mae: 2448.8333\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2062.8213 - mae: 2063.3123 - val_loss: 2349.7466 - val_mae: 2350.2463\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2053.3108 - mae: 2053.8135 - val_loss: 2094.3303 - val_mae: 2094.8296\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2044.7996 - mae: 2045.2964 - val_loss: 2200.8047 - val_mae: 2201.3042\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2034.9329 - mae: 2035.4324 - val_loss: 2166.0566 - val_mae: 2166.5562\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2028.3094 - mae: 2028.8090 - val_loss: 2173.9905 - val_mae: 2174.4897\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2021.1919 - mae: 2021.6908 - val_loss: 2060.1191 - val_mae: 2060.6187\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2017.8186 - mae: 2018.3113 - val_loss: 2045.1201 - val_mae: 2045.6195\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2008.1970 - mae: 2008.6935 - val_loss: 2115.0535 - val_mae: 2115.5530\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1999.9072 - mae: 2000.4065 - val_loss: 2030.9893 - val_mae: 2031.4888\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1994.0537 - mae: 1994.5566 - val_loss: 2045.8904 - val_mae: 2046.3904\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1994.1200 - mae: 1994.6191 - val_loss: 2081.0349 - val_mae: 2081.5347\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1987.0634 - mae: 1987.5703 - val_loss: 2006.9686 - val_mae: 2007.4685\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1979.6931 - mae: 1980.1910 - val_loss: 2039.8108 - val_mae: 2040.3107\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1978.3646 - mae: 1978.8693 - val_loss: 2144.4280 - val_mae: 2144.9277\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1969.2192 - mae: 1969.7214 - val_loss: 1986.8998 - val_mae: 1987.3997\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1965.9520 - mae: 1966.4491 - val_loss: 2002.5521 - val_mae: 2003.0516\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1960.1285 - mae: 1960.6248 - val_loss: 1970.3365 - val_mae: 1970.8361\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1957.2478 - mae: 1957.7500 - val_loss: 2114.8176 - val_mae: 2115.3174\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1951.9098 - mae: 1952.4094 - val_loss: 2073.4202 - val_mae: 2073.9202\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1950.7264 - mae: 1951.2213 - val_loss: 1986.1740 - val_mae: 1986.6740\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1947.6741 - mae: 1948.1807 - val_loss: 2017.2747 - val_mae: 2017.7745\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1946.5688 - mae: 1947.0659 - val_loss: 1968.3755 - val_mae: 1968.8752\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1940.6198 - mae: 1941.1215 - val_loss: 2000.3901 - val_mae: 2000.8900\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1937.1754 - mae: 1937.6738 - val_loss: 2031.6674 - val_mae: 2032.1670\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1935.2339 - mae: 1935.7334 - val_loss: 1958.3281 - val_mae: 1958.8278\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1931.1725 - mae: 1931.6794 - val_loss: 1950.9113 - val_mae: 1951.4108\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1930.4567 - mae: 1930.9583 - val_loss: 1941.9102 - val_mae: 1942.4098\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1925.7858 - mae: 1926.2885 - val_loss: 1946.9198 - val_mae: 1947.4192\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1925.4275 - mae: 1925.9191 - val_loss: 1945.8705 - val_mae: 1946.3700\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1920.9829 - mae: 1921.4822 - val_loss: 2015.4247 - val_mae: 2015.9243\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1917.0842 - mae: 1917.5792 - val_loss: 1992.9554 - val_mae: 1993.4556\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1913.8915 - mae: 1914.3884 - val_loss: 2181.4612 - val_mae: 2181.9607\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1914.4773 - mae: 1914.9736 - val_loss: 1991.8016 - val_mae: 1992.3014\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1910.8068 - mae: 1911.3065 - val_loss: 2153.0623 - val_mae: 2153.5620\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1907.9287 - mae: 1908.4326 - val_loss: 2074.8442 - val_mae: 2075.3440\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1907.6809 - mae: 1908.1804 - val_loss: 1971.8196 - val_mae: 1972.3188\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1903.3229 - mae: 1903.8174 - val_loss: 2039.8375 - val_mae: 2040.3370\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 2027.6389 - mae: 2028.1389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 5670.1997 - mae: 5670.7061 - val_loss: 3508.1790 - val_mae: 3508.6790\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3195.4009 - mae: 3195.9016 - val_loss: 3229.0818 - val_mae: 3229.5830\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2872.5781 - mae: 2873.0818 - val_loss: 2803.6909 - val_mae: 2804.1909\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2701.9546 - mae: 2702.4563 - val_loss: 2667.9319 - val_mae: 2668.4316\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2585.8035 - mae: 2586.3015 - val_loss: 2612.4976 - val_mae: 2612.9976\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2501.2266 - mae: 2501.7312 - val_loss: 2509.5552 - val_mae: 2510.0547\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2436.6853 - mae: 2437.1816 - val_loss: 2532.2556 - val_mae: 2532.7559\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2388.4822 - mae: 2388.9856 - val_loss: 2425.6023 - val_mae: 2426.1025\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2350.1064 - mae: 2350.6074 - val_loss: 2405.6848 - val_mae: 2406.1846\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2307.4094 - mae: 2307.9126 - val_loss: 2368.4050 - val_mae: 2368.9045\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2280.8916 - mae: 2281.3826 - val_loss: 2302.5220 - val_mae: 2303.0220\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2255.9158 - mae: 2256.4089 - val_loss: 2320.2661 - val_mae: 2320.7656\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2229.7598 - mae: 2230.2568 - val_loss: 2308.4805 - val_mae: 2308.9800\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2211.1443 - mae: 2211.6423 - val_loss: 2204.0510 - val_mae: 2204.5510\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2191.2012 - mae: 2191.6960 - val_loss: 2227.5232 - val_mae: 2228.0222\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2178.1152 - mae: 2178.6174 - val_loss: 2239.2966 - val_mae: 2239.7961\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2170.2546 - mae: 2170.7627 - val_loss: 2216.0464 - val_mae: 2216.5461\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2151.0588 - mae: 2151.5652 - val_loss: 2245.7844 - val_mae: 2246.2834\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2141.9937 - mae: 2142.4895 - val_loss: 2236.9851 - val_mae: 2237.4851\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2129.2183 - mae: 2129.7185 - val_loss: 2152.2852 - val_mae: 2152.7852\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2122.1006 - mae: 2122.5940 - val_loss: 2186.9282 - val_mae: 2187.4280\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2108.3015 - mae: 2108.7996 - val_loss: 2378.5522 - val_mae: 2379.0520\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2101.8877 - mae: 2102.3862 - val_loss: 2228.1235 - val_mae: 2228.6235\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2091.3120 - mae: 2091.8120 - val_loss: 2260.8203 - val_mae: 2261.3203\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2082.8491 - mae: 2083.3477 - val_loss: 2310.2021 - val_mae: 2310.7017\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2074.7397 - mae: 2075.2378 - val_loss: 2154.6057 - val_mae: 2155.1055\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2068.1030 - mae: 2068.6033 - val_loss: 2132.8552 - val_mae: 2133.3550\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2060.3813 - mae: 2060.8784 - val_loss: 2256.4683 - val_mae: 2256.9675\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2054.4065 - mae: 2054.8960 - val_loss: 2095.7800 - val_mae: 2096.2798\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2048.8613 - mae: 2049.3584 - val_loss: 2197.2908 - val_mae: 2197.7903\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2043.3251 - mae: 2043.8246 - val_loss: 2133.2859 - val_mae: 2133.7854\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2039.8329 - mae: 2040.3279 - val_loss: 2066.9744 - val_mae: 2067.4741\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2028.2139 - mae: 2028.7146 - val_loss: 2066.9702 - val_mae: 2067.4702\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2022.1241 - mae: 2022.6278 - val_loss: 2077.4031 - val_mae: 2077.9026\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 2015.5488 - mae: 2016.0480 - val_loss: 2254.6619 - val_mae: 2255.1616\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2010.1802 - mae: 2010.6794 - val_loss: 2052.0166 - val_mae: 2052.5164\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2008.1196 - mae: 2008.6151 - val_loss: 2047.3789 - val_mae: 2047.8784\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2001.3831 - mae: 2001.8792 - val_loss: 2065.9585 - val_mae: 2066.4580\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1996.2926 - mae: 1996.7926 - val_loss: 2108.2988 - val_mae: 2108.7983\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1993.6755 - mae: 1994.1777 - val_loss: 2002.9863 - val_mae: 2003.4858\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1986.4094 - mae: 1986.9077 - val_loss: 2260.9744 - val_mae: 2261.4741\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1985.5322 - mae: 1986.0245 - val_loss: 2017.6813 - val_mae: 2018.1810\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1978.6810 - mae: 1979.1761 - val_loss: 2007.6520 - val_mae: 2008.1515\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1972.7137 - mae: 1973.2133 - val_loss: 2037.4287 - val_mae: 2037.9285\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1970.6769 - mae: 1971.1764 - val_loss: 2008.7957 - val_mae: 2009.2953\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1966.2920 - mae: 1966.7922 - val_loss: 2127.4961 - val_mae: 2127.9958\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1959.3457 - mae: 1959.8406 - val_loss: 2021.1848 - val_mae: 2021.6838\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1955.4056 - mae: 1955.9058 - val_loss: 2013.4319 - val_mae: 2013.9314\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1950.9277 - mae: 1951.4321 - val_loss: 1984.0093 - val_mae: 1984.5088\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1944.5161 - mae: 1945.0117 - val_loss: 2043.3727 - val_mae: 2043.8724\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1942.0015 - mae: 1942.5046 - val_loss: 1981.3738 - val_mae: 1981.8737\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1939.4805 - mae: 1939.9780 - val_loss: 2203.2695 - val_mae: 2203.7690\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1933.9257 - mae: 1934.4258 - val_loss: 2037.1147 - val_mae: 2037.6145\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1933.7002 - mae: 1934.1967 - val_loss: 2083.4070 - val_mae: 2083.9067\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1927.5889 - mae: 1928.0889 - val_loss: 2043.9481 - val_mae: 2044.4478\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1924.5248 - mae: 1925.0156 - val_loss: 2014.8499 - val_mae: 2015.3496\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1919.4243 - mae: 1919.9202 - val_loss: 1959.3652 - val_mae: 1959.8647\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1919.7607 - mae: 1920.2584 - val_loss: 1946.4698 - val_mae: 1946.9695\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1918.4216 - mae: 1918.9232 - val_loss: 1986.5798 - val_mae: 1987.0797\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1912.5527 - mae: 1913.0579 - val_loss: 2011.8430 - val_mae: 2012.3427\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1911.5992 - mae: 1912.0981 - val_loss: 1939.5063 - val_mae: 1940.0057\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1907.4396 - mae: 1907.9392 - val_loss: 1998.8396 - val_mae: 1999.3392\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1909.0731 - mae: 1909.5720 - val_loss: 1980.6754 - val_mae: 1981.1749\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1905.6632 - mae: 1906.1635 - val_loss: 2106.5063 - val_mae: 2107.0061\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1898.0250 - mae: 1898.5205 - val_loss: 1931.3527 - val_mae: 1931.8523\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1900.7269 - mae: 1901.2274 - val_loss: 1927.6019 - val_mae: 1928.1012\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1897.6849 - mae: 1898.1852 - val_loss: 1947.7267 - val_mae: 1948.2260\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1892.5745 - mae: 1893.0747 - val_loss: 1938.4924 - val_mae: 1938.9918\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1891.0802 - mae: 1891.5813 - val_loss: 1905.1809 - val_mae: 1905.6808\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1890.8411 - mae: 1891.3438 - val_loss: 1917.4429 - val_mae: 1917.9425\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1889.6605 - mae: 1890.1575 - val_loss: 2026.0347 - val_mae: 2026.5345\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1887.3158 - mae: 1887.8142 - val_loss: 2001.1118 - val_mae: 2001.6117\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1887.0588 - mae: 1887.5532 - val_loss: 1915.0647 - val_mae: 1915.5643\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1882.5068 - mae: 1883.0055 - val_loss: 1931.5331 - val_mae: 1932.0327\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1880.1639 - mae: 1880.6602 - val_loss: 1914.7902 - val_mae: 1915.2902\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1880.1405 - mae: 1880.6376 - val_loss: 1903.8354 - val_mae: 1904.3351\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1879.5652 - mae: 1880.0743 - val_loss: 2024.6819 - val_mae: 2025.1815\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1879.6687 - mae: 1880.1660 - val_loss: 2069.3643 - val_mae: 2069.8640\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1875.6858 - mae: 1876.1852 - val_loss: 1925.6089 - val_mae: 1926.1088\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1875.6412 - mae: 1876.1401 - val_loss: 1936.0863 - val_mae: 1936.5861\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1869.2788 - mae: 1869.7767 - val_loss: 1964.2551 - val_mae: 1964.7546\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1870.6240 - mae: 1871.1234 - val_loss: 2062.7087 - val_mae: 2063.2083\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1867.0977 - mae: 1867.5990 - val_loss: 1946.9547 - val_mae: 1947.4543\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1868.1862 - mae: 1868.6901 - val_loss: 1892.5087 - val_mae: 1893.0082\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1866.4908 - mae: 1866.9880 - val_loss: 1960.0913 - val_mae: 1960.5906\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1864.3047 - mae: 1864.8027 - val_loss: 1906.9750 - val_mae: 1907.4746\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1865.3615 - mae: 1865.8590 - val_loss: 1903.3821 - val_mae: 1903.8813\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1863.3317 - mae: 1863.8325 - val_loss: 1936.2563 - val_mae: 1936.7559\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1860.1356 - mae: 1860.6395 - val_loss: 1924.0331 - val_mae: 1924.5330\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1857.9642 - mae: 1858.4630 - val_loss: 1937.1251 - val_mae: 1937.6250\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1857.4438 - mae: 1857.9421 - val_loss: 1892.6639 - val_mae: 1893.1633\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1856.0341 - mae: 1856.5338 - val_loss: 1880.5009 - val_mae: 1881.0005\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1857.7085 - mae: 1858.2079 - val_loss: 1873.0201 - val_mae: 1873.5200\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1853.3901 - mae: 1853.8856 - val_loss: 1942.5488 - val_mae: 1943.0485\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1850.5564 - mae: 1851.0564 - val_loss: 1902.1854 - val_mae: 1902.6854\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1852.4791 - mae: 1852.9753 - val_loss: 1871.4915 - val_mae: 1871.9911\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1848.2012 - mae: 1848.7046 - val_loss: 1974.0826 - val_mae: 1974.5823\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1849.0614 - mae: 1849.5640 - val_loss: 1964.0874 - val_mae: 1964.5870\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1846.1317 - mae: 1846.6287 - val_loss: 1919.7795 - val_mae: 1920.2792\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1849.2827 - mae: 1849.7800 - val_loss: 1946.5278 - val_mae: 1947.0277\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 1950.8657 - mae: 1951.3654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 4047.2026 - mae: 4047.7061 - val_loss: 3076.8794 - val_mae: 3077.3789\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2902.8142 - mae: 2903.3184 - val_loss: 2732.3054 - val_mae: 2732.8052\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2564.7263 - mae: 2565.2371 - val_loss: 2481.8035 - val_mae: 2482.3032\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2405.2510 - mae: 2405.7539 - val_loss: 2618.9778 - val_mae: 2619.4778\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2301.9683 - mae: 2302.4675 - val_loss: 3385.1301 - val_mae: 3385.6299\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2232.4741 - mae: 2232.9658 - val_loss: 2536.0725 - val_mae: 2536.5723\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2164.2666 - mae: 2164.7629 - val_loss: 2078.5425 - val_mae: 2079.0422\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2116.0022 - mae: 2116.5000 - val_loss: 2429.3965 - val_mae: 2429.8960\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2080.6865 - mae: 2081.1860 - val_loss: 2813.4175 - val_mae: 2813.9172\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2054.3923 - mae: 2054.8933 - val_loss: 2113.8279 - val_mae: 2114.3276\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2029.7455 - mae: 2030.2478 - val_loss: 2515.7725 - val_mae: 2516.2720\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 2003.8763 - mae: 2004.3755 - val_loss: 3858.4714 - val_mae: 3858.9749\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1977.4907 - mae: 1977.9913 - val_loss: 2022.1973 - val_mae: 2022.6970\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1965.5034 - mae: 1966.0090 - val_loss: 2039.2311 - val_mae: 2039.7310\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1955.6829 - mae: 1956.1771 - val_loss: 1872.9462 - val_mae: 1873.4462\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1928.9855 - mae: 1929.4901 - val_loss: 2501.5347 - val_mae: 2502.0347\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1917.9767 - mae: 1918.4723 - val_loss: 1991.7643 - val_mae: 1992.2638\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1908.7122 - mae: 1909.2086 - val_loss: 1921.1268 - val_mae: 1921.6267\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1895.4729 - mae: 1895.9739 - val_loss: 2607.5874 - val_mae: 2608.0874\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1882.7847 - mae: 1883.2822 - val_loss: 2412.5728 - val_mae: 2413.0730\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1877.8226 - mae: 1878.3264 - val_loss: 1937.7749 - val_mae: 1938.2749\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1870.1011 - mae: 1870.6042 - val_loss: 3121.3621 - val_mae: 3121.8616\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1866.2106 - mae: 1866.7109 - val_loss: 2512.0107 - val_mae: 2512.5107\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1858.3723 - mae: 1858.8717 - val_loss: 1838.7489 - val_mae: 1839.2487\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1854.5660 - mae: 1855.0616 - val_loss: 2118.9871 - val_mae: 2119.4866\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1847.5780 - mae: 1848.0811 - val_loss: 1919.0868 - val_mae: 1919.5863\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1841.6154 - mae: 1842.1122 - val_loss: 2440.1130 - val_mae: 2440.6130\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1831.0342 - mae: 1831.5303 - val_loss: 2305.0750 - val_mae: 2305.5745\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1830.8844 - mae: 1831.3866 - val_loss: 2433.3938 - val_mae: 2433.8938\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1817.8510 - mae: 1818.3478 - val_loss: 1796.9563 - val_mae: 1797.4564\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1819.1659 - mae: 1819.6624 - val_loss: 1807.0052 - val_mae: 1807.5049\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1805.7222 - mae: 1806.2258 - val_loss: 1764.2476 - val_mae: 1764.7471\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1812.1340 - mae: 1812.6323 - val_loss: 1941.7976 - val_mae: 1942.2970\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1805.0049 - mae: 1805.5095 - val_loss: 2350.1589 - val_mae: 2350.6587\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1795.2990 - mae: 1795.8047 - val_loss: 1806.0529 - val_mae: 1806.5525\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1794.6918 - mae: 1795.1917 - val_loss: 2150.9048 - val_mae: 2151.4043\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1790.6685 - mae: 1791.1675 - val_loss: 2068.1262 - val_mae: 2068.6260\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1784.4365 - mae: 1784.9362 - val_loss: 2070.1545 - val_mae: 2070.6541\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1785.7554 - mae: 1786.2610 - val_loss: 1838.0824 - val_mae: 1838.5820\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1777.7999 - mae: 1778.2994 - val_loss: 2412.7925 - val_mae: 2413.2925\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1777.2183 - mae: 1777.7219 - val_loss: 2276.6831 - val_mae: 2277.1824\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1770.4205 - mae: 1770.9197 - val_loss: 2967.8088 - val_mae: 2968.3088\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 2958.4976 - mae: 2958.9993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 4107.9614 - mae: 4108.4629 - val_loss: 3086.0884 - val_mae: 3086.5886\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2950.2959 - mae: 2950.7869 - val_loss: 2696.8562 - val_mae: 2697.3555\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2640.5608 - mae: 2641.0623 - val_loss: 2599.2488 - val_mae: 2599.7490\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2479.6870 - mae: 2480.1907 - val_loss: 4568.5898 - val_mae: 4569.0845\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2375.4636 - mae: 2375.9568 - val_loss: 3551.5796 - val_mae: 3552.0762\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2290.0144 - mae: 2290.5112 - val_loss: 2280.2273 - val_mae: 2280.7273\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2214.5637 - mae: 2215.0684 - val_loss: 2731.8777 - val_mae: 2732.3777\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2165.3015 - mae: 2165.8096 - val_loss: 2426.2644 - val_mae: 2426.7644\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2108.8499 - mae: 2109.3467 - val_loss: 2475.6562 - val_mae: 2476.1562\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2082.6301 - mae: 2083.1260 - val_loss: 3706.6018 - val_mae: 3707.1079\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2060.4326 - mae: 2060.9324 - val_loss: 2325.0574 - val_mae: 2325.5569\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2030.3713 - mae: 2030.8685 - val_loss: 2229.7168 - val_mae: 2230.2163\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1997.1010 - mae: 1997.5933 - val_loss: 1941.9719 - val_mae: 1942.4716\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1985.2935 - mae: 1985.7915 - val_loss: 1957.4199 - val_mae: 1957.9196\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1961.7194 - mae: 1962.2203 - val_loss: 1935.0709 - val_mae: 1935.5706\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1949.2169 - mae: 1949.7175 - val_loss: 2019.4274 - val_mae: 2019.9270\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1932.8904 - mae: 1933.3872 - val_loss: 1863.4812 - val_mae: 1863.9808\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1925.2571 - mae: 1925.7554 - val_loss: 1918.6838 - val_mae: 1919.1836\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1913.3147 - mae: 1913.8141 - val_loss: 2449.6851 - val_mae: 2450.1851\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1899.1476 - mae: 1899.6404 - val_loss: 2103.8115 - val_mae: 2104.3115\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1892.9888 - mae: 1893.4893 - val_loss: 1920.1112 - val_mae: 1920.6111\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1880.8538 - mae: 1881.3479 - val_loss: 2037.9510 - val_mae: 2038.4506\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1877.4791 - mae: 1877.9761 - val_loss: 2143.8367 - val_mae: 2144.3362\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1867.9646 - mae: 1868.4628 - val_loss: 2002.2123 - val_mae: 2002.7119\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1859.8002 - mae: 1860.2925 - val_loss: 1912.6594 - val_mae: 1913.1589\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1855.9252 - mae: 1856.4269 - val_loss: 1987.9578 - val_mae: 1988.4574\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1853.2804 - mae: 1853.7773 - val_loss: 2604.6272 - val_mae: 2605.1265\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 2603.1533 - mae: 2603.6533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 4039.1445 - mae: 4039.6553 - val_loss: 3065.4236 - val_mae: 3065.9229\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2843.8367 - mae: 2844.3474 - val_loss: 4447.8911 - val_mae: 4448.3979\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2563.7314 - mae: 2564.2356 - val_loss: 2355.0964 - val_mae: 2355.5962\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2421.1902 - mae: 2421.6851 - val_loss: 2269.9333 - val_mae: 2270.4329\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2305.3975 - mae: 2305.8933 - val_loss: 2363.4070 - val_mae: 2363.9065\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2214.8188 - mae: 2215.3193 - val_loss: 2176.4810 - val_mae: 2176.9807\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2147.5020 - mae: 2148.0044 - val_loss: 2114.4248 - val_mae: 2114.9246\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2103.1401 - mae: 2103.6387 - val_loss: 2371.2888 - val_mae: 2371.7886\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2069.4324 - mae: 2069.9412 - val_loss: 2820.3689 - val_mae: 2820.8682\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2040.1237 - mae: 2040.6221 - val_loss: 2374.7998 - val_mae: 2375.2996\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 2015.3392 - mae: 2015.8353 - val_loss: 2176.2954 - val_mae: 2176.7954\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1994.1450 - mae: 1994.6472 - val_loss: 2247.0698 - val_mae: 2247.5693\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1977.1166 - mae: 1977.6112 - val_loss: 1900.8516 - val_mae: 1901.3512\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 1958.8113 - mae: 1959.3157 - val_loss: 1916.3704 - val_mae: 1916.8698\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1942.2205 - mae: 1942.7186 - val_loss: 1965.7429 - val_mae: 1966.2424\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1923.5549 - mae: 1924.0526 - val_loss: 1990.4777 - val_mae: 1990.9772\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1910.8855 - mae: 1911.3804 - val_loss: 2369.9927 - val_mae: 2370.4927\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1895.9556 - mae: 1896.4532 - val_loss: 1907.1152 - val_mae: 1907.6149\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1894.1521 - mae: 1894.6484 - val_loss: 2100.2820 - val_mae: 2100.7817\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1880.9132 - mae: 1881.4100 - val_loss: 1832.1221 - val_mae: 1832.6217\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1876.2778 - mae: 1876.7770 - val_loss: 2391.4346 - val_mae: 2391.9341\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1866.9012 - mae: 1867.4038 - val_loss: 1983.7998 - val_mae: 1984.2994\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1859.4558 - mae: 1859.9545 - val_loss: 2057.1150 - val_mae: 2057.6143\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1851.2068 - mae: 1851.7052 - val_loss: 1930.4042 - val_mae: 1930.9034\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1844.2101 - mae: 1844.7106 - val_loss: 1986.0942 - val_mae: 1986.5938\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1842.1853 - mae: 1842.6802 - val_loss: 2515.9287 - val_mae: 2516.4285\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1834.2037 - mae: 1834.6981 - val_loss: 1829.1628 - val_mae: 1829.6625\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1833.1273 - mae: 1833.6334 - val_loss: 1794.3545 - val_mae: 1794.8542\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1826.2147 - mae: 1826.7100 - val_loss: 1958.5172 - val_mae: 1959.0166\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1817.1393 - mae: 1817.6382 - val_loss: 2604.4573 - val_mae: 2604.9568\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1812.9974 - mae: 1813.4950 - val_loss: 1774.0000 - val_mae: 1774.4995\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1810.5101 - mae: 1811.0144 - val_loss: 1772.9508 - val_mae: 1773.4504\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1808.2659 - mae: 1808.7706 - val_loss: 1746.7131 - val_mae: 1747.2124\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1804.7990 - mae: 1805.3047 - val_loss: 2640.7783 - val_mae: 2641.2781\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1799.1193 - mae: 1799.6172 - val_loss: 1980.9656 - val_mae: 1981.4653\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1798.5430 - mae: 1799.0468 - val_loss: 2025.4402 - val_mae: 2025.9396\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1793.4988 - mae: 1793.9996 - val_loss: 1755.9310 - val_mae: 1756.4307\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1795.4897 - mae: 1795.9933 - val_loss: 1739.8574 - val_mae: 1740.3571\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1788.3400 - mae: 1788.8428 - val_loss: 2040.9661 - val_mae: 2041.4656\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1782.6174 - mae: 1783.1133 - val_loss: 1921.1156 - val_mae: 1921.6155\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1783.1089 - mae: 1783.6139 - val_loss: 1919.8009 - val_mae: 1920.3008\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1781.9495 - mae: 1782.4484 - val_loss: 2729.9167 - val_mae: 2730.4167\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1778.7072 - mae: 1779.2040 - val_loss: 1781.6630 - val_mae: 1782.1627\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1773.8364 - mae: 1774.3373 - val_loss: 2146.4856 - val_mae: 2146.9856\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1773.0161 - mae: 1773.5200 - val_loss: 1748.4149 - val_mae: 1748.9146\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1769.0775 - mae: 1769.5789 - val_loss: 1724.1008 - val_mae: 1724.6001\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1767.3187 - mae: 1767.8132 - val_loss: 1761.5710 - val_mae: 1762.0709\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1765.9501 - mae: 1766.4515 - val_loss: 1768.0978 - val_mae: 1768.5975\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1763.4706 - mae: 1763.9764 - val_loss: 1896.6453 - val_mae: 1897.1453\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1758.3173 - mae: 1758.8218 - val_loss: 1806.1875 - val_mae: 1806.6874\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1761.1180 - mae: 1761.6248 - val_loss: 1766.4963 - val_mae: 1766.9965\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1759.8219 - mae: 1760.3201 - val_loss: 1763.7799 - val_mae: 1764.2797\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1758.1318 - mae: 1758.6339 - val_loss: 1753.7863 - val_mae: 1754.2863\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1753.9470 - mae: 1754.4449 - val_loss: 2160.2922 - val_mae: 2160.7922\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1757.8726 - mae: 1758.3660 - val_loss: 1842.9551 - val_mae: 1843.4548\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 1753.7406 - mae: 1754.2389 - val_loss: 1763.6337 - val_mae: 1764.1335\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 1776.7737 - mae: 1777.2736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 7771.5479 - mae: 7772.0527 - val_loss: 5409.7544 - val_mae: 5410.2559\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4850.3159 - mae: 4850.8066 - val_loss: 4338.0737 - val_mae: 4338.5718\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3953.7031 - mae: 3954.1985 - val_loss: 3730.5762 - val_mae: 3731.0811\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3566.5652 - mae: 3567.0713 - val_loss: 3509.3523 - val_mae: 3509.8540\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3374.8245 - mae: 3375.3225 - val_loss: 3334.6711 - val_mae: 3335.1731\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3219.3733 - mae: 3219.8660 - val_loss: 3202.8989 - val_mae: 3203.3994\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3075.5518 - mae: 3076.0566 - val_loss: 3080.3086 - val_mae: 3080.8083\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2941.1919 - mae: 2941.6895 - val_loss: 2922.9656 - val_mae: 2923.4648\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2819.8774 - mae: 2820.3801 - val_loss: 2812.3928 - val_mae: 2812.8926\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2714.8967 - mae: 2715.3940 - val_loss: 2707.9050 - val_mae: 2708.4050\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2624.8005 - mae: 2625.3066 - val_loss: 2627.2573 - val_mae: 2627.7571\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2546.8813 - mae: 2547.3818 - val_loss: 2556.5742 - val_mae: 2557.0742\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2476.9473 - mae: 2477.4465 - val_loss: 2523.2847 - val_mae: 2523.7847\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2417.2075 - mae: 2417.7114 - val_loss: 2458.7778 - val_mae: 2459.2778\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2362.5613 - mae: 2363.0664 - val_loss: 2385.1672 - val_mae: 2385.6672\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2316.1624 - mae: 2316.6628 - val_loss: 2345.9099 - val_mae: 2346.4097\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2274.1235 - mae: 2274.6201 - val_loss: 2324.9568 - val_mae: 2325.4565\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2237.1560 - mae: 2237.6504 - val_loss: 2273.7859 - val_mae: 2274.2854\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2203.4983 - mae: 2204.0010 - val_loss: 2239.7849 - val_mae: 2240.2847\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2173.3157 - mae: 2173.8208 - val_loss: 2214.3308 - val_mae: 2214.8306\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2145.0312 - mae: 2145.5242 - val_loss: 2189.9187 - val_mae: 2190.4187\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2119.1858 - mae: 2119.6855 - val_loss: 2154.1467 - val_mae: 2154.6462\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2096.2085 - mae: 2096.7087 - val_loss: 2145.4604 - val_mae: 2145.9600\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2074.3391 - mae: 2074.8430 - val_loss: 2135.2651 - val_mae: 2135.7651\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2054.2776 - mae: 2054.7759 - val_loss: 2095.4771 - val_mae: 2095.9771\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2036.7559 - mae: 2037.2601 - val_loss: 2124.3259 - val_mae: 2124.8257\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2019.9576 - mae: 2020.4628 - val_loss: 2068.5007 - val_mae: 2069.0007\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2005.3568 - mae: 2005.8597 - val_loss: 2070.7725 - val_mae: 2071.2722\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1992.1947 - mae: 1992.6947 - val_loss: 2055.9658 - val_mae: 2056.4656\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1979.4943 - mae: 1979.9874 - val_loss: 2029.7091 - val_mae: 2030.2092\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1968.0743 - mae: 1968.5698 - val_loss: 2040.5724 - val_mae: 2041.0720\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1957.8761 - mae: 1958.3749 - val_loss: 2015.6726 - val_mae: 2016.1725\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1946.4399 - mae: 1946.9375 - val_loss: 2022.5576 - val_mae: 2023.0576\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1939.5839 - mae: 1940.0771 - val_loss: 1988.6814 - val_mae: 1989.1814\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1929.4521 - mae: 1929.9584 - val_loss: 1985.7089 - val_mae: 1986.2089\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1920.2238 - mae: 1920.7250 - val_loss: 1984.1715 - val_mae: 1984.6714\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1913.0482 - mae: 1913.5504 - val_loss: 1965.5143 - val_mae: 1966.0140\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1906.1147 - mae: 1906.6119 - val_loss: 1958.1304 - val_mae: 1958.6302\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1898.6843 - mae: 1899.1836 - val_loss: 1962.5524 - val_mae: 1963.0522\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1893.2272 - mae: 1893.7245 - val_loss: 1943.9708 - val_mae: 1944.4708\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1886.2812 - mae: 1886.7841 - val_loss: 1959.5398 - val_mae: 1960.0397\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1880.9785 - mae: 1881.4797 - val_loss: 1937.3995 - val_mae: 1937.8994\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1876.4225 - mae: 1876.9233 - val_loss: 1925.7708 - val_mae: 1926.2705\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1869.5132 - mae: 1870.0129 - val_loss: 1924.3468 - val_mae: 1924.8467\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1864.5989 - mae: 1865.0948 - val_loss: 1916.3024 - val_mae: 1916.8020\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1859.8142 - mae: 1860.3163 - val_loss: 1921.4854 - val_mae: 1921.9850\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1854.8835 - mae: 1855.3838 - val_loss: 1913.8181 - val_mae: 1914.3180\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1850.6495 - mae: 1851.1527 - val_loss: 1905.2633 - val_mae: 1905.7632\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1846.8091 - mae: 1847.3096 - val_loss: 1915.7072 - val_mae: 1916.2068\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1842.8260 - mae: 1843.3236 - val_loss: 1899.2775 - val_mae: 1899.7767\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1839.6147 - mae: 1840.1163 - val_loss: 1893.8966 - val_mae: 1894.3962\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1834.4886 - mae: 1834.9858 - val_loss: 1898.1472 - val_mae: 1898.6471\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1831.7435 - mae: 1832.2454 - val_loss: 1896.9344 - val_mae: 1897.4341\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1828.0422 - mae: 1828.5403 - val_loss: 1904.1910 - val_mae: 1904.6913\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1824.4661 - mae: 1824.9696 - val_loss: 1881.1860 - val_mae: 1881.6859\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1822.0795 - mae: 1822.5823 - val_loss: 1894.1710 - val_mae: 1894.6709\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1818.8397 - mae: 1819.3433 - val_loss: 1888.5630 - val_mae: 1889.0632\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1815.0818 - mae: 1815.5818 - val_loss: 1875.6772 - val_mae: 1876.1770\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1812.1143 - mae: 1812.6179 - val_loss: 1887.7000 - val_mae: 1888.1998\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1809.4452 - mae: 1809.9478 - val_loss: 1870.3961 - val_mae: 1870.8960\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1806.5769 - mae: 1807.0826 - val_loss: 1872.2761 - val_mae: 1872.7758\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1804.3627 - mae: 1804.8663 - val_loss: 1860.3363 - val_mae: 1860.8357\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1802.2667 - mae: 1802.7646 - val_loss: 1872.2771 - val_mae: 1872.7769\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1800.7269 - mae: 1801.2267 - val_loss: 1865.3992 - val_mae: 1865.8992\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1797.1727 - mae: 1797.6747 - val_loss: 1878.9032 - val_mae: 1879.4030\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1794.8690 - mae: 1795.3682 - val_loss: 1859.5695 - val_mae: 1860.0696\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1792.2827 - mae: 1792.7841 - val_loss: 1861.7655 - val_mae: 1862.2654\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1789.9713 - mae: 1790.4629 - val_loss: 1856.5875 - val_mae: 1857.0872\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1788.0769 - mae: 1788.5818 - val_loss: 1852.5084 - val_mae: 1853.0083\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1785.2523 - mae: 1785.7515 - val_loss: 1859.8506 - val_mae: 1860.3505\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1785.6149 - mae: 1786.1156 - val_loss: 1849.7800 - val_mae: 1850.2800\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1783.1284 - mae: 1783.6335 - val_loss: 1850.3975 - val_mae: 1850.8970\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1780.5380 - mae: 1781.0380 - val_loss: 1859.1010 - val_mae: 1859.6008\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1778.2180 - mae: 1778.7189 - val_loss: 1846.5802 - val_mae: 1847.0800\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1777.8451 - mae: 1778.3496 - val_loss: 1861.1969 - val_mae: 1861.6968\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1775.0321 - mae: 1775.5302 - val_loss: 1846.6046 - val_mae: 1847.1042\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1773.4231 - mae: 1773.9247 - val_loss: 1842.3608 - val_mae: 1842.8607\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1770.5907 - mae: 1771.0892 - val_loss: 1831.0876 - val_mae: 1831.5874\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1769.1417 - mae: 1769.6433 - val_loss: 1838.4392 - val_mae: 1838.9388\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1768.1805 - mae: 1768.6804 - val_loss: 1841.6052 - val_mae: 1842.1055\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1764.6885 - mae: 1765.1917 - val_loss: 1837.6909 - val_mae: 1838.1906\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1764.5210 - mae: 1765.0189 - val_loss: 1833.5963 - val_mae: 1834.0962\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1762.7706 - mae: 1763.2750 - val_loss: 1825.2887 - val_mae: 1825.7887\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1760.7196 - mae: 1761.2162 - val_loss: 1836.5802 - val_mae: 1837.0798\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1760.1941 - mae: 1760.6925 - val_loss: 1842.9164 - val_mae: 1843.4161\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1757.2742 - mae: 1757.7708 - val_loss: 1844.2119 - val_mae: 1844.7117\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1756.6986 - mae: 1757.1934 - val_loss: 1821.0452 - val_mae: 1821.5450\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1754.7181 - mae: 1755.2170 - val_loss: 1819.1201 - val_mae: 1819.6200\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1753.3273 - mae: 1753.8196 - val_loss: 1821.3127 - val_mae: 1821.8125\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1751.6152 - mae: 1752.1113 - val_loss: 1832.7693 - val_mae: 1833.2689\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1750.2999 - mae: 1750.7958 - val_loss: 1818.6761 - val_mae: 1819.1758\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1749.3962 - mae: 1749.8981 - val_loss: 1830.3849 - val_mae: 1830.8848\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1747.0291 - mae: 1747.5294 - val_loss: 1812.8813 - val_mae: 1813.3812\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1745.1489 - mae: 1745.6461 - val_loss: 1826.1848 - val_mae: 1826.6846\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1745.0974 - mae: 1745.5947 - val_loss: 1825.4081 - val_mae: 1825.9080\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1743.4716 - mae: 1743.9709 - val_loss: 1817.5912 - val_mae: 1818.0912\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1742.4044 - mae: 1742.9016 - val_loss: 1808.3911 - val_mae: 1808.8911\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1742.5188 - mae: 1743.0236 - val_loss: 1812.1305 - val_mae: 1812.6301\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1741.7217 - mae: 1742.2266 - val_loss: 1817.0682 - val_mae: 1817.5676\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1738.9817 - mae: 1739.4751 - val_loss: 1816.3298 - val_mae: 1816.8295\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 1801.6522 - mae: 1802.1520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 7931.7637 - mae: 7932.2705 - val_loss: 5503.1821 - val_mae: 5503.6738\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4991.6787 - mae: 4992.1860 - val_loss: 4508.2173 - val_mae: 4508.7202\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4082.1616 - mae: 4082.6821 - val_loss: 3824.1675 - val_mae: 3824.6641\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3636.1018 - mae: 3636.6067 - val_loss: 3570.2961 - val_mae: 3570.7976\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3435.8379 - mae: 3436.3406 - val_loss: 3405.1399 - val_mae: 3405.6360\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3286.5071 - mae: 3287.0024 - val_loss: 3291.0649 - val_mae: 3291.5637\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3157.0044 - mae: 3157.5090 - val_loss: 3184.2612 - val_mae: 3184.7610\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3041.3855 - mae: 3041.8857 - val_loss: 3050.9219 - val_mae: 3051.4219\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2941.6982 - mae: 2942.1938 - val_loss: 2946.0698 - val_mae: 2946.5696\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2849.9795 - mae: 2850.4880 - val_loss: 2867.5613 - val_mae: 2868.0613\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2766.3735 - mae: 2766.8735 - val_loss: 2779.8005 - val_mae: 2780.3008\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2689.4424 - mae: 2689.9409 - val_loss: 2716.8896 - val_mae: 2717.3892\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2621.5825 - mae: 2622.0842 - val_loss: 2658.4290 - val_mae: 2658.9287\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2562.7156 - mae: 2563.2168 - val_loss: 2587.7146 - val_mae: 2588.2144\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2508.0640 - mae: 2508.5728 - val_loss: 2578.0728 - val_mae: 2578.5728\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2458.8867 - mae: 2459.3755 - val_loss: 2499.0637 - val_mae: 2499.5637\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2416.8945 - mae: 2417.3918 - val_loss: 2471.0867 - val_mae: 2471.5864\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2377.0576 - mae: 2377.5461 - val_loss: 2414.3420 - val_mae: 2414.8418\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2341.6045 - mae: 2342.1030 - val_loss: 2392.9377 - val_mae: 2393.4377\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2309.2998 - mae: 2309.8005 - val_loss: 2363.8457 - val_mae: 2364.3452\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2279.7761 - mae: 2280.2729 - val_loss: 2315.7744 - val_mae: 2316.2744\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2250.9419 - mae: 2251.4404 - val_loss: 2297.6125 - val_mae: 2298.1123\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2225.3491 - mae: 2225.8528 - val_loss: 2273.1826 - val_mae: 2273.6826\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2203.0586 - mae: 2203.5615 - val_loss: 2247.2771 - val_mae: 2247.7771\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2180.2222 - mae: 2180.7227 - val_loss: 2231.0808 - val_mae: 2231.5803\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2159.9026 - mae: 2160.4016 - val_loss: 2209.9089 - val_mae: 2210.4087\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2142.0708 - mae: 2142.5676 - val_loss: 2206.2183 - val_mae: 2206.7180\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2122.8669 - mae: 2123.3650 - val_loss: 2197.9546 - val_mae: 2198.4548\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2106.1191 - mae: 2106.6201 - val_loss: 2187.2720 - val_mae: 2187.7717\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2091.4009 - mae: 2091.8992 - val_loss: 2147.4490 - val_mae: 2147.9487\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2078.5852 - mae: 2079.0842 - val_loss: 2155.1074 - val_mae: 2155.6074\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2064.9470 - mae: 2065.4431 - val_loss: 2124.3831 - val_mae: 2124.8828\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2052.3430 - mae: 2052.8489 - val_loss: 2100.5334 - val_mae: 2101.0332\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2040.7394 - mae: 2041.2384 - val_loss: 2123.6514 - val_mae: 2124.1509\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2030.8384 - mae: 2031.3417 - val_loss: 2082.6111 - val_mae: 2083.1108\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2019.9647 - mae: 2020.4634 - val_loss: 2078.7437 - val_mae: 2079.2437\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2010.9982 - mae: 2011.4966 - val_loss: 2069.8899 - val_mae: 2070.3892\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2002.0992 - mae: 2002.5978 - val_loss: 2071.8923 - val_mae: 2072.3921\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1994.4648 - mae: 1994.9692 - val_loss: 2056.5457 - val_mae: 2057.0454\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1985.7042 - mae: 1986.2054 - val_loss: 2052.0889 - val_mae: 2052.5886\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1979.0785 - mae: 1979.5800 - val_loss: 2039.3751 - val_mae: 2039.8750\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1972.4238 - mae: 1972.9308 - val_loss: 2042.8337 - val_mae: 2043.3335\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1964.0233 - mae: 1964.5323 - val_loss: 2039.2421 - val_mae: 2039.7416\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1958.6431 - mae: 1959.1504 - val_loss: 2014.8389 - val_mae: 2015.3383\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1952.3345 - mae: 1952.8354 - val_loss: 2020.0214 - val_mae: 2020.5210\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1947.5612 - mae: 1948.0592 - val_loss: 2002.0942 - val_mae: 2002.5944\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1941.5695 - mae: 1942.0721 - val_loss: 2004.2703 - val_mae: 2004.7700\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1935.8875 - mae: 1936.3879 - val_loss: 2006.0752 - val_mae: 2006.5748\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1930.0271 - mae: 1930.5217 - val_loss: 1996.3359 - val_mae: 1996.8361\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1925.5557 - mae: 1926.0557 - val_loss: 2008.1801 - val_mae: 2008.6797\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1920.7858 - mae: 1921.2838 - val_loss: 1979.4047 - val_mae: 1979.9043\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1916.4524 - mae: 1916.9545 - val_loss: 1977.8262 - val_mae: 1978.3262\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1911.9348 - mae: 1912.4369 - val_loss: 1987.0238 - val_mae: 1987.5236\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1908.5775 - mae: 1909.0797 - val_loss: 1977.5468 - val_mae: 1978.0466\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1902.8014 - mae: 1903.3066 - val_loss: 2003.0704 - val_mae: 2003.5704\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1899.2631 - mae: 1899.7614 - val_loss: 1968.6721 - val_mae: 1969.1720\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1894.4194 - mae: 1894.9196 - val_loss: 1986.9194 - val_mae: 1987.4192\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1890.3607 - mae: 1890.8579 - val_loss: 1970.5767 - val_mae: 1971.0763\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1887.5886 - mae: 1888.0946 - val_loss: 1962.0015 - val_mae: 1962.5013\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1884.7113 - mae: 1885.2109 - val_loss: 1970.6722 - val_mae: 1971.1720\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1880.9813 - mae: 1881.4855 - val_loss: 1946.4984 - val_mae: 1946.9983\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1877.5538 - mae: 1878.0526 - val_loss: 1939.2546 - val_mae: 1939.7545\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1873.9149 - mae: 1874.4095 - val_loss: 1953.1829 - val_mae: 1953.6823\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1870.6428 - mae: 1871.1375 - val_loss: 1967.2261 - val_mae: 1967.7260\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1868.2476 - mae: 1868.7412 - val_loss: 1952.4695 - val_mae: 1952.9691\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1866.6908 - mae: 1867.1929 - val_loss: 1929.2961 - val_mae: 1929.7959\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1863.0607 - mae: 1863.5568 - val_loss: 1936.2588 - val_mae: 1936.7587\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1860.7533 - mae: 1861.2572 - val_loss: 1931.5010 - val_mae: 1932.0009\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1857.5892 - mae: 1858.0938 - val_loss: 1929.6294 - val_mae: 1930.1294\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1855.8330 - mae: 1856.3326 - val_loss: 1940.1259 - val_mae: 1940.6257\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1853.6732 - mae: 1854.1681 - val_loss: 1932.9988 - val_mae: 1933.4983\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1850.9885 - mae: 1851.4845 - val_loss: 1941.9435 - val_mae: 1942.4434\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1848.9788 - mae: 1849.4817 - val_loss: 1919.3586 - val_mae: 1919.8583\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1846.0193 - mae: 1846.5188 - val_loss: 1928.9150 - val_mae: 1929.4149\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1844.1705 - mae: 1844.6709 - val_loss: 1924.1045 - val_mae: 1924.6045\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1842.4189 - mae: 1842.9230 - val_loss: 1911.4943 - val_mae: 1911.9938\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1840.4247 - mae: 1840.9320 - val_loss: 1915.2053 - val_mae: 1915.7054\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1837.5997 - mae: 1838.1022 - val_loss: 1906.1007 - val_mae: 1906.6006\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1835.6982 - mae: 1836.1952 - val_loss: 1918.6343 - val_mae: 1919.1343\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1834.9552 - mae: 1835.4578 - val_loss: 1906.0562 - val_mae: 1906.5560\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1832.1169 - mae: 1832.6118 - val_loss: 1906.5239 - val_mae: 1907.0239\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1829.9001 - mae: 1830.3976 - val_loss: 1895.3950 - val_mae: 1895.8950\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1827.8167 - mae: 1828.3179 - val_loss: 1907.7086 - val_mae: 1908.2086\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1826.5330 - mae: 1827.0253 - val_loss: 1902.8401 - val_mae: 1903.3402\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1824.4279 - mae: 1824.9309 - val_loss: 1907.6129 - val_mae: 1908.1124\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1822.8025 - mae: 1823.3053 - val_loss: 1903.1011 - val_mae: 1903.6010\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1821.8129 - mae: 1822.3114 - val_loss: 1900.4902 - val_mae: 1900.9901\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1820.6702 - mae: 1821.1726 - val_loss: 1889.5586 - val_mae: 1890.0582\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1818.4006 - mae: 1818.9060 - val_loss: 1907.9564 - val_mae: 1908.4563\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1816.5879 - mae: 1817.0900 - val_loss: 1927.7679 - val_mae: 1928.2673\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1814.9274 - mae: 1815.4279 - val_loss: 1914.5852 - val_mae: 1915.0852\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1813.7968 - mae: 1814.2938 - val_loss: 1895.9935 - val_mae: 1896.4935\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1811.6195 - mae: 1812.1166 - val_loss: 1885.6698 - val_mae: 1886.1699\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1810.2153 - mae: 1810.7128 - val_loss: 1920.4607 - val_mae: 1920.9608\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1809.6775 - mae: 1810.1752 - val_loss: 1885.6895 - val_mae: 1886.1895\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1807.5366 - mae: 1808.0380 - val_loss: 1886.3405 - val_mae: 1886.8401\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1804.7170 - mae: 1805.2162 - val_loss: 1887.4146 - val_mae: 1887.9142\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1804.4702 - mae: 1804.9674 - val_loss: 1884.9963 - val_mae: 1885.4962\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1803.6179 - mae: 1804.1199 - val_loss: 1872.1353 - val_mae: 1872.6351\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 1801.8816 - mae: 1802.3798 - val_loss: 1883.4528 - val_mae: 1883.9526\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 1865.2427 - mae: 1865.7423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 7700.1821 - mae: 7700.7026 - val_loss: 5346.9150 - val_mae: 5347.4136\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4697.1719 - mae: 4697.6670 - val_loss: 4175.5981 - val_mae: 4176.0981\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3821.6169 - mae: 3822.1257 - val_loss: 3660.0183 - val_mae: 3660.5105\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3488.8269 - mae: 3489.3186 - val_loss: 3447.8081 - val_mae: 3448.3091\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3297.3198 - mae: 3297.8096 - val_loss: 3276.9602 - val_mae: 3277.4583\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3136.9377 - mae: 3137.4336 - val_loss: 3120.7825 - val_mae: 3121.2825\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2992.5657 - mae: 2993.0718 - val_loss: 3000.6270 - val_mae: 3001.1270\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2866.8137 - mae: 2867.3101 - val_loss: 2864.1379 - val_mae: 2864.6377\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2757.8787 - mae: 2758.3728 - val_loss: 2782.3508 - val_mae: 2782.8511\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2660.7009 - mae: 2661.2012 - val_loss: 2671.4065 - val_mae: 2671.9062\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2576.8301 - mae: 2577.3264 - val_loss: 2596.8203 - val_mae: 2597.3201\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2501.7705 - mae: 2502.2700 - val_loss: 2528.6631 - val_mae: 2529.1628\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2436.6538 - mae: 2437.1553 - val_loss: 2460.1719 - val_mae: 2460.6719\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2378.5894 - mae: 2379.0891 - val_loss: 2401.1174 - val_mae: 2401.6169\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2327.4851 - mae: 2327.9849 - val_loss: 2369.8333 - val_mae: 2370.3333\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2278.7351 - mae: 2279.2351 - val_loss: 2319.8206 - val_mae: 2320.3201\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2239.0039 - mae: 2239.5056 - val_loss: 2275.1299 - val_mae: 2275.6296\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2200.2539 - mae: 2200.7566 - val_loss: 2237.4382 - val_mae: 2237.9382\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2167.4709 - mae: 2167.9719 - val_loss: 2197.3486 - val_mae: 2197.8486\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2134.3350 - mae: 2134.8311 - val_loss: 2175.1675 - val_mae: 2175.6672\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2106.3235 - mae: 2106.8193 - val_loss: 2139.7173 - val_mae: 2140.2173\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2079.2937 - mae: 2079.7983 - val_loss: 2119.2432 - val_mae: 2119.7432\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 2053.7412 - mae: 2054.2405 - val_loss: 2100.4856 - val_mae: 2100.9854\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2031.2886 - mae: 2031.7936 - val_loss: 2078.5151 - val_mae: 2079.0149\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 2012.2661 - mae: 2012.7576 - val_loss: 2058.4194 - val_mae: 2058.9194\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1994.2607 - mae: 1994.7604 - val_loss: 2036.3441 - val_mae: 2036.8442\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1978.0637 - mae: 1978.5665 - val_loss: 2049.8154 - val_mae: 2050.3154\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1963.5979 - mae: 1964.0946 - val_loss: 2013.8292 - val_mae: 2014.3289\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1949.7808 - mae: 1950.2826 - val_loss: 2009.6787 - val_mae: 2010.1783\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1936.9871 - mae: 1937.4860 - val_loss: 1993.5242 - val_mae: 1994.0240\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1925.5492 - mae: 1926.0496 - val_loss: 1986.7313 - val_mae: 1987.2312\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1914.8585 - mae: 1915.3595 - val_loss: 1972.0898 - val_mae: 1972.5894\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1905.0208 - mae: 1905.5201 - val_loss: 1961.6685 - val_mae: 1962.1681\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1895.2780 - mae: 1895.7786 - val_loss: 1952.9242 - val_mae: 1953.4238\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1886.1875 - mae: 1886.6816 - val_loss: 1952.8370 - val_mae: 1953.3369\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1877.9677 - mae: 1878.4690 - val_loss: 1936.5076 - val_mae: 1937.0077\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1870.5630 - mae: 1871.0676 - val_loss: 1928.3644 - val_mae: 1928.8643\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1862.5334 - mae: 1863.0339 - val_loss: 1929.4508 - val_mae: 1929.9508\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1855.8149 - mae: 1856.3113 - val_loss: 1929.2417 - val_mae: 1929.7415\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1850.8187 - mae: 1851.3232 - val_loss: 1905.6891 - val_mae: 1906.1890\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1844.3147 - mae: 1844.8195 - val_loss: 1906.3984 - val_mae: 1906.8984\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1838.8944 - mae: 1839.3893 - val_loss: 1895.7156 - val_mae: 1896.2156\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1832.7299 - mae: 1833.2321 - val_loss: 1892.0323 - val_mae: 1892.5320\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1828.5966 - mae: 1829.0935 - val_loss: 1892.4062 - val_mae: 1892.9062\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1824.8794 - mae: 1825.3712 - val_loss: 1897.5693 - val_mae: 1898.0690\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1819.3352 - mae: 1819.8398 - val_loss: 1902.1841 - val_mae: 1902.6840\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1814.4880 - mae: 1814.9841 - val_loss: 1888.3624 - val_mae: 1888.8623\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1811.3168 - mae: 1811.8147 - val_loss: 1873.9810 - val_mae: 1874.4808\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1807.7827 - mae: 1808.2854 - val_loss: 1868.0781 - val_mae: 1868.5779\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1803.5524 - mae: 1804.0570 - val_loss: 1873.1334 - val_mae: 1873.6333\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1800.2528 - mae: 1800.7607 - val_loss: 1873.5143 - val_mae: 1874.0142\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1797.0275 - mae: 1797.5258 - val_loss: 1859.9116 - val_mae: 1860.4111\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1793.3284 - mae: 1793.8285 - val_loss: 1860.8918 - val_mae: 1861.3915\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1789.5353 - mae: 1790.0392 - val_loss: 1851.1448 - val_mae: 1851.6449\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1785.3575 - mae: 1785.8636 - val_loss: 1849.6569 - val_mae: 1850.1565\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 1782.7474 - mae: 1783.2496 - val_loss: 1865.0321 - val_mae: 1865.5322\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1779.3546 - mae: 1779.8514 - val_loss: 1877.0253 - val_mae: 1877.5249\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1777.3777 - mae: 1777.8829 - val_loss: 1850.5195 - val_mae: 1851.0192\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1773.9891 - mae: 1774.4850 - val_loss: 1865.1741 - val_mae: 1865.6737\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1771.4227 - mae: 1771.9181 - val_loss: 1840.0548 - val_mae: 1840.5549\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1768.7638 - mae: 1769.2675 - val_loss: 1827.3391 - val_mae: 1827.8390\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1766.4683 - mae: 1766.9650 - val_loss: 1856.7565 - val_mae: 1857.2565\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1763.4292 - mae: 1763.9215 - val_loss: 1836.5067 - val_mae: 1837.0065\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1761.1671 - mae: 1761.6687 - val_loss: 1826.8052 - val_mae: 1827.3049\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1758.3883 - mae: 1758.8846 - val_loss: 1818.1274 - val_mae: 1818.6276\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1756.0485 - mae: 1756.5513 - val_loss: 1834.6519 - val_mae: 1835.1516\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1753.5085 - mae: 1754.0144 - val_loss: 1831.2791 - val_mae: 1831.7789\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1751.4254 - mae: 1751.9296 - val_loss: 1827.5092 - val_mae: 1828.0088\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1750.5402 - mae: 1751.0360 - val_loss: 1848.3309 - val_mae: 1848.8306\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1747.0676 - mae: 1747.5668 - val_loss: 1817.8464 - val_mae: 1818.3464\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1745.5316 - mae: 1746.0283 - val_loss: 1815.3591 - val_mae: 1815.8586\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1743.3661 - mae: 1743.8689 - val_loss: 1812.7202 - val_mae: 1813.2201\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1740.2164 - mae: 1740.7172 - val_loss: 1810.4277 - val_mae: 1810.9270\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1738.4332 - mae: 1738.9297 - val_loss: 1806.8040 - val_mae: 1807.3040\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1736.7709 - mae: 1737.2679 - val_loss: 1830.6035 - val_mae: 1831.1035\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1736.3969 - mae: 1736.8969 - val_loss: 1824.8547 - val_mae: 1825.3544\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1734.4667 - mae: 1734.9686 - val_loss: 1818.7167 - val_mae: 1819.2168\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1733.0991 - mae: 1733.5977 - val_loss: 1804.2726 - val_mae: 1804.7722\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1730.8718 - mae: 1731.3669 - val_loss: 1806.1864 - val_mae: 1806.6863\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1728.5988 - mae: 1729.0951 - val_loss: 1801.3842 - val_mae: 1801.8842\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1726.9572 - mae: 1727.4604 - val_loss: 1801.9556 - val_mae: 1802.4552\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1725.6876 - mae: 1726.1904 - val_loss: 1803.9427 - val_mae: 1804.4426\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1723.7728 - mae: 1724.2766 - val_loss: 1798.9773 - val_mae: 1799.4772\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1722.5503 - mae: 1723.0535 - val_loss: 1795.6296 - val_mae: 1796.1295\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1719.6505 - mae: 1720.1458 - val_loss: 1796.4932 - val_mae: 1796.9929\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1719.1532 - mae: 1719.6562 - val_loss: 1801.7161 - val_mae: 1802.2161\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1717.6622 - mae: 1718.1611 - val_loss: 1793.0631 - val_mae: 1793.5627\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1715.5950 - mae: 1716.0908 - val_loss: 1800.0151 - val_mae: 1800.5153\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1715.3821 - mae: 1715.8802 - val_loss: 1789.5051 - val_mae: 1790.0050\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1712.9266 - mae: 1713.4276 - val_loss: 1781.1918 - val_mae: 1781.6917\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1711.9208 - mae: 1712.4161 - val_loss: 1794.0240 - val_mae: 1794.5236\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1710.0245 - mae: 1710.5315 - val_loss: 1802.8243 - val_mae: 1803.3243\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1709.4281 - mae: 1709.9331 - val_loss: 1816.8792 - val_mae: 1817.3789\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1707.7006 - mae: 1708.2001 - val_loss: 1793.9354 - val_mae: 1794.4351\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1705.5314 - mae: 1706.0337 - val_loss: 1796.5117 - val_mae: 1797.0117\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1705.0798 - mae: 1705.5763 - val_loss: 1780.8153 - val_mae: 1781.3152\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1703.1095 - mae: 1703.6083 - val_loss: 1782.6090 - val_mae: 1783.1086\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1702.5819 - mae: 1703.0824 - val_loss: 1794.1312 - val_mae: 1794.6311\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1701.1940 - mae: 1701.6958 - val_loss: 1810.6571 - val_mae: 1811.1570\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 1700.8228 - mae: 1701.3221 - val_loss: 1790.1776 - val_mae: 1790.6774\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 1782.5482 - mae: 1783.0481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 14733.2412 - mae: 14733.7705 - val_loss: 13237.9443 - val_mae: 13238.4355\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 12846.9854 - mae: 12847.4912 - val_loss: 12513.5137 - val_mae: 12514.0127\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 12243.4336 - mae: 12243.9375 - val_loss: 11881.4668 - val_mae: 11881.9639\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 11530.8613 - mae: 11531.3730 - val_loss: 11071.2148 - val_mae: 11071.7129\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 10611.2754 - mae: 10611.7871 - val_loss: 10081.2129 - val_mae: 10081.7256\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 9632.4170 - mae: 9632.9258 - val_loss: 9181.7607 - val_mae: 9182.2666\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 8842.0889 - mae: 8842.5820 - val_loss: 8497.7422 - val_mae: 8498.2295\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 8216.6396 - mae: 8217.1270 - val_loss: 7927.5317 - val_mae: 7928.0312\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 7689.0449 - mae: 7689.5479 - val_loss: 7456.9175 - val_mae: 7457.4219\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 7257.7808 - mae: 7258.2754 - val_loss: 7073.2852 - val_mae: 7073.7915\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 6906.5493 - mae: 6907.0532 - val_loss: 6760.7666 - val_mae: 6761.2554\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 6623.3589 - mae: 6623.8599 - val_loss: 6509.5010 - val_mae: 6509.9980\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6393.7876 - mae: 6394.2739 - val_loss: 6307.5166 - val_mae: 6308.0142\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 6207.0747 - mae: 6207.5742 - val_loss: 6142.5234 - val_mae: 6143.0200\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 6055.0933 - mae: 6055.5947 - val_loss: 6009.8828 - val_mae: 6010.3833\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5929.8130 - mae: 5930.3130 - val_loss: 5896.2505 - val_mae: 5896.7554\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5822.5986 - mae: 5823.1084 - val_loss: 5796.6182 - val_mae: 5797.1201\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5731.3057 - mae: 5731.8047 - val_loss: 5712.9985 - val_mae: 5713.5010\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5656.0571 - mae: 5656.5459 - val_loss: 5643.8564 - val_mae: 5644.3564\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5591.5288 - mae: 5592.0132 - val_loss: 5584.5918 - val_mae: 5585.0967\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5534.4707 - mae: 5534.9580 - val_loss: 5531.7510 - val_mae: 5532.2588\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5485.8120 - mae: 5486.3066 - val_loss: 5486.9946 - val_mae: 5487.4863\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5442.9019 - mae: 5443.3979 - val_loss: 5446.5107 - val_mae: 5447.0122\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5402.2222 - mae: 5402.7227 - val_loss: 5407.9873 - val_mae: 5408.4849\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5361.2290 - mae: 5361.7261 - val_loss: 5368.0615 - val_mae: 5368.5649\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5321.2935 - mae: 5321.7944 - val_loss: 5329.6401 - val_mae: 5330.1416\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5282.8115 - mae: 5283.3198 - val_loss: 5293.3330 - val_mae: 5293.8418\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5246.0024 - mae: 5246.4873 - val_loss: 5256.3203 - val_mae: 5256.8208\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5210.0610 - mae: 5210.5728 - val_loss: 5221.3887 - val_mae: 5221.8799\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5176.1860 - mae: 5176.6855 - val_loss: 5188.8911 - val_mae: 5189.3877\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5144.0972 - mae: 5144.5938 - val_loss: 5157.5205 - val_mae: 5158.0190\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5113.1050 - mae: 5113.5986 - val_loss: 5128.4600 - val_mae: 5128.9688\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5083.3506 - mae: 5083.8496 - val_loss: 5098.6616 - val_mae: 5099.1631\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5054.6948 - mae: 5055.2036 - val_loss: 5070.7056 - val_mae: 5071.1982\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5026.5288 - mae: 5027.0244 - val_loss: 5043.0537 - val_mae: 5043.5508\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4998.5610 - mae: 4999.0732 - val_loss: 5015.3301 - val_mae: 5015.8276\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4970.9736 - mae: 4971.4819 - val_loss: 4987.9644 - val_mae: 4988.4673\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4943.5146 - mae: 4944.0205 - val_loss: 4960.2861 - val_mae: 4960.7944\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4915.7383 - mae: 4916.2358 - val_loss: 4932.9497 - val_mae: 4933.4478\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4885.9653 - mae: 4886.4697 - val_loss: 4901.1553 - val_mae: 4901.6450\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4852.7842 - mae: 4853.2925 - val_loss: 4866.5464 - val_mae: 4867.0566\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4818.5361 - mae: 4819.0347 - val_loss: 4833.5625 - val_mae: 4834.0591\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4784.9922 - mae: 4785.4736 - val_loss: 4799.8374 - val_mae: 4800.3428\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4752.4717 - mae: 4752.9746 - val_loss: 4768.0908 - val_mae: 4768.5879\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4721.7554 - mae: 4722.2441 - val_loss: 4739.2837 - val_mae: 4739.7788\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4692.9639 - mae: 4693.4766 - val_loss: 4710.7124 - val_mae: 4711.2114\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4663.5962 - mae: 4664.1035 - val_loss: 4681.6118 - val_mae: 4682.1128\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4633.9824 - mae: 4634.4790 - val_loss: 4651.4316 - val_mae: 4651.9316\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4603.6973 - mae: 4604.1987 - val_loss: 4622.0806 - val_mae: 4622.5747\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4574.0166 - mae: 4574.5146 - val_loss: 4592.9971 - val_mae: 4593.4995\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4545.4253 - mae: 4545.9233 - val_loss: 4564.8662 - val_mae: 4565.3652\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4517.5239 - mae: 4518.0254 - val_loss: 4537.8125 - val_mae: 4538.3154\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4490.4126 - mae: 4490.9092 - val_loss: 4513.4429 - val_mae: 4513.9385\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4464.2524 - mae: 4464.7495 - val_loss: 4486.7407 - val_mae: 4487.2495\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4439.3521 - mae: 4439.8540 - val_loss: 4462.6992 - val_mae: 4463.1909\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4415.1338 - mae: 4415.6304 - val_loss: 4439.1309 - val_mae: 4439.6348\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4391.6133 - mae: 4392.1108 - val_loss: 4417.1519 - val_mae: 4417.6489\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4368.9497 - mae: 4369.4526 - val_loss: 4395.6426 - val_mae: 4396.1489\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4347.4326 - mae: 4347.9277 - val_loss: 4375.0015 - val_mae: 4375.5015\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4326.7300 - mae: 4327.2373 - val_loss: 4355.0400 - val_mae: 4355.5371\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4307.1934 - mae: 4307.6934 - val_loss: 4336.2598 - val_mae: 4336.7598\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4288.2524 - mae: 4288.7578 - val_loss: 4318.0312 - val_mae: 4318.5332\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4270.2192 - mae: 4270.7085 - val_loss: 4301.0732 - val_mae: 4301.5708\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4253.2900 - mae: 4253.7803 - val_loss: 4284.9360 - val_mae: 4285.4346\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4237.1040 - mae: 4237.6025 - val_loss: 4269.1738 - val_mae: 4269.6699\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4221.4546 - mae: 4221.9531 - val_loss: 4253.6709 - val_mae: 4254.1743\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4206.4634 - mae: 4206.9619 - val_loss: 4239.5137 - val_mae: 4240.0186\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4192.4575 - mae: 4192.9526 - val_loss: 4225.5688 - val_mae: 4226.0571\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4178.9829 - mae: 4179.4814 - val_loss: 4212.4531 - val_mae: 4212.9502\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4166.1230 - mae: 4166.6152 - val_loss: 4202.0483 - val_mae: 4202.5459\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4153.7603 - mae: 4154.2617 - val_loss: 4187.0298 - val_mae: 4187.5283\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4140.9463 - mae: 4141.4424 - val_loss: 4173.7666 - val_mae: 4174.2681\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4128.4907 - mae: 4128.9932 - val_loss: 4161.0923 - val_mae: 4161.5952\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4115.8213 - mae: 4116.3125 - val_loss: 4149.6875 - val_mae: 4150.1929\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4103.3291 - mae: 4103.8286 - val_loss: 4135.2754 - val_mae: 4135.7676\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4090.6465 - mae: 4091.1509 - val_loss: 4122.9990 - val_mae: 4123.5024\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4078.4524 - mae: 4078.9568 - val_loss: 4110.5166 - val_mae: 4111.0166\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4066.5830 - mae: 4067.0796 - val_loss: 4098.5845 - val_mae: 4099.0898\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4055.0161 - mae: 4055.5146 - val_loss: 4089.5361 - val_mae: 4090.0383\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4044.3904 - mae: 4044.8926 - val_loss: 4078.0100 - val_mae: 4078.5161\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4034.1519 - mae: 4034.6433 - val_loss: 4068.2207 - val_mae: 4068.7241\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4024.5286 - mae: 4025.0095 - val_loss: 4059.0286 - val_mae: 4059.5317\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4015.5500 - mae: 4016.0474 - val_loss: 4050.3975 - val_mae: 4050.8984\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4007.2847 - mae: 4007.7837 - val_loss: 4042.3438 - val_mae: 4042.8335\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3999.4131 - mae: 3999.9404 - val_loss: 4035.4314 - val_mae: 4035.9224\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3992.2378 - mae: 3992.7476 - val_loss: 4029.8347 - val_mae: 4030.3335\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3985.6743 - mae: 3986.1758 - val_loss: 4022.4453 - val_mae: 4022.9512\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3979.4756 - mae: 3979.9651 - val_loss: 4016.3230 - val_mae: 4016.8315\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3973.5735 - mae: 3974.0854 - val_loss: 4011.2908 - val_mae: 4011.7878\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3967.9851 - mae: 3968.5059 - val_loss: 4006.9575 - val_mae: 4007.4507\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 3963.0352 - mae: 3963.5347 - val_loss: 4000.9465 - val_mae: 4001.4487\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3958.2097 - mae: 3958.7188 - val_loss: 3996.2703 - val_mae: 3996.7739\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3953.4800 - mae: 3953.9856 - val_loss: 3991.2278 - val_mae: 3991.7261\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3949.2417 - mae: 3949.7366 - val_loss: 3988.0029 - val_mae: 3988.5100\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3945.1321 - mae: 3945.6250 - val_loss: 3982.5554 - val_mae: 3983.0530\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3940.9897 - mae: 3941.4971 - val_loss: 3978.7783 - val_mae: 3979.2778\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3937.1602 - mae: 3937.6567 - val_loss: 3974.9580 - val_mae: 3975.4602\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3933.1072 - mae: 3933.6064 - val_loss: 3970.8169 - val_mae: 3971.3159\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3929.2344 - mae: 3929.7378 - val_loss: 3966.4480 - val_mae: 3966.9487\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3925.5295 - mae: 3926.0422 - val_loss: 3963.3435 - val_mae: 3963.8391\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 3912.7920 - mae: 3913.2966\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 14513.0811 - mae: 14513.5742 - val_loss: 13071.5137 - val_mae: 13072.0371\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 12684.3936 - mae: 12684.8945 - val_loss: 12375.8594 - val_mae: 12376.3643\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 12017.8828 - mae: 12018.3799 - val_loss: 11670.9229 - val_mae: 11671.4121\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 11224.2764 - mae: 11224.7725 - val_loss: 10762.3262 - val_mae: 10762.8262\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 10203.8535 - mae: 10204.3506 - val_loss: 9685.5791 - val_mae: 9686.0977\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 9182.0615 - mae: 9182.5732 - val_loss: 8774.5752 - val_mae: 8775.0781\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 8366.3740 - mae: 8366.8701 - val_loss: 8051.1162 - val_mae: 8051.6089\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 7723.2158 - mae: 7723.7310 - val_loss: 7489.3896 - val_mae: 7489.8833\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 7211.3203 - mae: 7211.8198 - val_loss: 7032.0669 - val_mae: 7032.5664\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6796.6050 - mae: 6797.1191 - val_loss: 6668.7456 - val_mae: 6669.2495\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6473.5034 - mae: 6474.0239 - val_loss: 6389.7983 - val_mae: 6390.2993\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6223.8779 - mae: 6224.3755 - val_loss: 6170.3721 - val_mae: 6170.8564\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6032.0015 - mae: 6032.4819 - val_loss: 6002.3975 - val_mae: 6002.8926\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5883.1519 - mae: 5883.6528 - val_loss: 5869.1758 - val_mae: 5869.6831\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5765.9692 - mae: 5766.4697 - val_loss: 5759.6470 - val_mae: 5760.1646\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5670.7026 - mae: 5671.2158 - val_loss: 5669.7632 - val_mae: 5670.2729\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5589.9897 - mae: 5590.5020 - val_loss: 5593.3364 - val_mae: 5593.8320\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5521.6450 - mae: 5522.1396 - val_loss: 5530.7280 - val_mae: 5531.2275\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5463.9028 - mae: 5464.3999 - val_loss: 5474.4927 - val_mae: 5474.9854\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5410.2681 - mae: 5410.7515 - val_loss: 5421.3096 - val_mae: 5421.8066\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5357.7241 - mae: 5358.2173 - val_loss: 5370.0405 - val_mae: 5370.5459\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5308.2734 - mae: 5308.7666 - val_loss: 5322.3945 - val_mae: 5322.8989\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5263.0298 - mae: 5263.5386 - val_loss: 5278.9336 - val_mae: 5279.4507\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5221.1582 - mae: 5221.6514 - val_loss: 5237.8594 - val_mae: 5238.3560\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5180.8423 - mae: 5181.3389 - val_loss: 5198.3267 - val_mae: 5198.8252\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5140.9619 - mae: 5141.4482 - val_loss: 5157.2583 - val_mae: 5157.7583\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5100.8687 - mae: 5101.3896 - val_loss: 5117.7422 - val_mae: 5118.2407\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5061.6260 - mae: 5062.1201 - val_loss: 5078.5840 - val_mae: 5079.0908\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5023.1567 - mae: 5023.6650 - val_loss: 5040.2451 - val_mae: 5040.7393\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4985.4087 - mae: 4985.9131 - val_loss: 5003.9946 - val_mae: 5004.4917\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4949.6509 - mae: 4950.1592 - val_loss: 4968.6890 - val_mae: 4969.1987\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4915.4214 - mae: 4915.9380 - val_loss: 4934.8813 - val_mae: 4935.3794\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4881.1274 - mae: 4881.6313 - val_loss: 4901.1592 - val_mae: 4901.6670\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4847.2607 - mae: 4847.7598 - val_loss: 4867.2397 - val_mae: 4867.7358\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4813.8765 - mae: 4814.3662 - val_loss: 4833.8760 - val_mae: 4834.3667\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4781.0957 - mae: 4781.6016 - val_loss: 4801.9653 - val_mae: 4802.4634\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4748.3994 - mae: 4748.8882 - val_loss: 4769.4570 - val_mae: 4769.9521\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4714.5161 - mae: 4715.0156 - val_loss: 4734.6675 - val_mae: 4735.1587\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4678.4443 - mae: 4678.9419 - val_loss: 4698.7197 - val_mae: 4699.2202\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4641.4336 - mae: 4641.9199 - val_loss: 4660.5083 - val_mae: 4661.0093\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4601.8071 - mae: 4602.3120 - val_loss: 4621.0884 - val_mae: 4621.5894\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4561.6968 - mae: 4562.1934 - val_loss: 4580.9023 - val_mae: 4581.3911\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4520.6821 - mae: 4521.1841 - val_loss: 4540.4326 - val_mae: 4540.9214\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4479.6162 - mae: 4480.1152 - val_loss: 4501.6997 - val_mae: 4502.1953\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4441.1899 - mae: 4441.6772 - val_loss: 4466.4243 - val_mae: 4466.9297\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4405.7822 - mae: 4406.2891 - val_loss: 4434.0200 - val_mae: 4434.5176\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4372.3076 - mae: 4372.8052 - val_loss: 4402.8315 - val_mae: 4403.3252\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4341.0718 - mae: 4341.5654 - val_loss: 4373.1846 - val_mae: 4373.6748\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4311.0898 - mae: 4311.5850 - val_loss: 4343.7969 - val_mae: 4344.2944\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4281.2515 - mae: 4281.7534 - val_loss: 4314.9277 - val_mae: 4315.4355\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4252.3945 - mae: 4252.9136 - val_loss: 4286.8618 - val_mae: 4287.3574\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4224.1133 - mae: 4224.6099 - val_loss: 4259.5776 - val_mae: 4260.0776\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4197.1860 - mae: 4197.6812 - val_loss: 4232.9482 - val_mae: 4233.4541\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4171.3271 - mae: 4171.8276 - val_loss: 4208.6064 - val_mae: 4209.1094\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4146.6694 - mae: 4147.1724 - val_loss: 4185.4595 - val_mae: 4185.9697\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4123.3760 - mae: 4123.8779 - val_loss: 4162.4443 - val_mae: 4162.9521\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4100.3789 - mae: 4100.8657 - val_loss: 4139.8599 - val_mae: 4140.3608\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4078.3352 - mae: 4078.8284 - val_loss: 4119.4790 - val_mae: 4119.9839\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4057.2776 - mae: 4057.7805 - val_loss: 4098.5845 - val_mae: 4099.0825\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4037.7747 - mae: 4038.2832 - val_loss: 4080.0813 - val_mae: 4080.5781\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4019.1526 - mae: 4019.6504 - val_loss: 4062.5774 - val_mae: 4063.0837\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4001.2981 - mae: 4001.8032 - val_loss: 4046.3247 - val_mae: 4046.8311\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3985.0457 - mae: 3985.5437 - val_loss: 4030.1240 - val_mae: 4030.6260\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3969.8779 - mae: 3970.3828 - val_loss: 4015.8955 - val_mae: 4016.3833\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3955.5520 - mae: 3956.0408 - val_loss: 4002.5686 - val_mae: 4003.0635\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3942.1279 - mae: 3942.6367 - val_loss: 3988.7708 - val_mae: 3989.2705\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3929.3584 - mae: 3929.8572 - val_loss: 3976.3938 - val_mae: 3976.8906\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3916.6260 - mae: 3917.1272 - val_loss: 3965.1953 - val_mae: 3965.6938\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3904.3315 - mae: 3904.8269 - val_loss: 3952.4956 - val_mae: 3952.9888\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3892.0618 - mae: 3892.5493 - val_loss: 3940.2249 - val_mae: 3940.7275\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3880.1445 - mae: 3880.6382 - val_loss: 3929.1023 - val_mae: 3929.6040\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3868.5430 - mae: 3869.0410 - val_loss: 3918.3032 - val_mae: 3918.8003\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3858.2715 - mae: 3858.7725 - val_loss: 3907.8481 - val_mae: 3908.3459\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3848.3235 - mae: 3848.8110 - val_loss: 3898.8083 - val_mae: 3899.3105\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3838.6531 - mae: 3839.1509 - val_loss: 3890.6067 - val_mae: 3891.1165\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3829.5293 - mae: 3830.0310 - val_loss: 3881.7769 - val_mae: 3882.2751\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3821.1758 - mae: 3821.6631 - val_loss: 3873.4395 - val_mae: 3873.9363\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3813.2051 - mae: 3813.7080 - val_loss: 3866.4893 - val_mae: 3866.9851\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3805.6826 - mae: 3806.1875 - val_loss: 3858.4077 - val_mae: 3858.9050\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3798.6758 - mae: 3799.1863 - val_loss: 3851.5845 - val_mae: 3852.0820\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3792.0085 - mae: 3792.5017 - val_loss: 3845.1936 - val_mae: 3845.6846\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3785.4912 - mae: 3786.0076 - val_loss: 3840.3184 - val_mae: 3840.8157\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3780.0540 - mae: 3780.5591 - val_loss: 3834.8208 - val_mae: 3835.3223\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3774.6670 - mae: 3775.1633 - val_loss: 3829.3643 - val_mae: 3829.8660\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3769.5337 - mae: 3770.0291 - val_loss: 3823.8774 - val_mae: 3824.3738\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3764.9507 - mae: 3765.4441 - val_loss: 3819.6523 - val_mae: 3820.1509\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3760.3970 - mae: 3760.9026 - val_loss: 3816.5581 - val_mae: 3817.0613\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3755.8806 - mae: 3756.3828 - val_loss: 3812.1465 - val_mae: 3812.6531\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3752.2778 - mae: 3752.7710 - val_loss: 3808.4180 - val_mae: 3808.9109\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3748.4915 - mae: 3748.9851 - val_loss: 3804.1155 - val_mae: 3804.6101\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3744.9832 - mae: 3745.4827 - val_loss: 3800.9727 - val_mae: 3801.4736\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3741.2405 - mae: 3741.7375 - val_loss: 3797.6016 - val_mae: 3798.0945\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3738.0693 - mae: 3738.5759 - val_loss: 3794.4426 - val_mae: 3794.9429\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3735.0637 - mae: 3735.5522 - val_loss: 3791.2405 - val_mae: 3791.7412\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3731.8408 - mae: 3732.3455 - val_loss: 3789.7292 - val_mae: 3790.2261\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3729.0654 - mae: 3729.5725 - val_loss: 3785.2788 - val_mae: 3785.7778\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3726.2024 - mae: 3726.7024 - val_loss: 3782.5212 - val_mae: 3783.0264\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3723.3809 - mae: 3723.8865 - val_loss: 3779.5186 - val_mae: 3780.0220\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3720.4763 - mae: 3720.9941 - val_loss: 3777.7446 - val_mae: 3778.2405\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3717.3081 - mae: 3717.8042 - val_loss: 3774.0552 - val_mae: 3774.5520\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 3718.4270 - mae: 3718.9211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 14646.4697 - mae: 14646.9521 - val_loss: 13229.8506 - val_mae: 13230.3643\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 12775.6572 - mae: 12776.1553 - val_loss: 12506.9043 - val_mae: 12507.3955\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 12175.6006 - mae: 12176.0996 - val_loss: 11894.7217 - val_mae: 11895.2412\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 11521.4258 - mae: 11521.9277 - val_loss: 11171.3105 - val_mae: 11171.8213\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 10688.3545 - mae: 10688.8213 - val_loss: 10242.2822 - val_mae: 10242.7861\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 9726.0469 - mae: 9726.5400 - val_loss: 9313.8477 - val_mae: 9314.3398\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 8882.2500 - mae: 8882.7803 - val_loss: 8564.3340 - val_mae: 8564.8555\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 8202.8926 - mae: 8203.4062 - val_loss: 7953.1597 - val_mae: 7953.6626\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 7651.6152 - mae: 7652.1353 - val_loss: 7463.8813 - val_mae: 7464.3711\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 7205.0562 - mae: 7205.5737 - val_loss: 7061.5112 - val_mae: 7062.0176\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 6839.0576 - mae: 6839.5430 - val_loss: 6735.5708 - val_mae: 6736.0654\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 6544.7295 - mae: 6545.2241 - val_loss: 6472.7148 - val_mae: 6473.2202\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 6307.1558 - mae: 6307.6558 - val_loss: 6261.4761 - val_mae: 6261.9668\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 6118.7275 - mae: 6119.2563 - val_loss: 6095.2710 - val_mae: 6095.7700\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5968.6875 - mae: 5969.1787 - val_loss: 5963.1357 - val_mae: 5963.6323\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5847.7124 - mae: 5848.2153 - val_loss: 5853.6753 - val_mae: 5854.1777\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5748.9209 - mae: 5749.4263 - val_loss: 5762.7002 - val_mae: 5763.2095\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5666.9839 - mae: 5667.4946 - val_loss: 5686.9536 - val_mae: 5687.4541\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5597.9062 - mae: 5598.4102 - val_loss: 5622.9043 - val_mae: 5623.3994\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5539.7407 - mae: 5540.2397 - val_loss: 5569.0317 - val_mae: 5569.5322\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5488.4292 - mae: 5488.9341 - val_loss: 5520.3008 - val_mae: 5520.8037\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5441.5718 - mae: 5442.0591 - val_loss: 5474.9663 - val_mae: 5475.4678\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5397.5469 - mae: 5398.0483 - val_loss: 5432.6240 - val_mae: 5433.1143\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5356.6426 - mae: 5357.1289 - val_loss: 5393.8057 - val_mae: 5394.2998\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5318.2236 - mae: 5318.7261 - val_loss: 5357.4053 - val_mae: 5357.9136\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5282.0464 - mae: 5282.5308 - val_loss: 5322.1045 - val_mae: 5322.6006\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5247.8481 - mae: 5248.3506 - val_loss: 5289.3501 - val_mae: 5289.8467\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5215.0010 - mae: 5215.5020 - val_loss: 5257.0771 - val_mae: 5257.5669\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5181.9785 - mae: 5182.4824 - val_loss: 5223.5718 - val_mae: 5224.0664\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5148.8354 - mae: 5149.3394 - val_loss: 5190.5986 - val_mae: 5191.1021\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5116.1060 - mae: 5116.6035 - val_loss: 5159.0444 - val_mae: 5159.5391\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5083.9321 - mae: 5084.4438 - val_loss: 5126.6455 - val_mae: 5127.1431\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5052.4316 - mae: 5052.9194 - val_loss: 5095.9512 - val_mae: 5096.4443\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5021.2974 - mae: 5021.7969 - val_loss: 5065.7251 - val_mae: 5066.2261\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4991.2783 - mae: 4991.7681 - val_loss: 5036.1211 - val_mae: 5036.6143\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4961.3560 - mae: 4961.8569 - val_loss: 5006.7266 - val_mae: 5007.2310\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4931.0063 - mae: 4931.5044 - val_loss: 4975.8574 - val_mae: 4976.3604\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4898.6807 - mae: 4899.1865 - val_loss: 4943.1870 - val_mae: 4943.6865\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4864.6250 - mae: 4865.1284 - val_loss: 4908.5503 - val_mae: 4909.0444\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4827.7681 - mae: 4828.2642 - val_loss: 4870.7183 - val_mae: 4871.2119\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4788.6021 - mae: 4789.1030 - val_loss: 4830.9097 - val_mae: 4831.4141\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4749.9634 - mae: 4750.4761 - val_loss: 4793.5308 - val_mae: 4794.0308\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4711.1216 - mae: 4711.6196 - val_loss: 4756.5898 - val_mae: 4757.0928\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4672.0684 - mae: 4672.5747 - val_loss: 4717.3267 - val_mae: 4717.8257\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4633.5669 - mae: 4634.0791 - val_loss: 4679.4043 - val_mae: 4679.9146\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4595.2881 - mae: 4595.7881 - val_loss: 4642.2734 - val_mae: 4642.7646\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4557.8979 - mae: 4558.3979 - val_loss: 4607.3701 - val_mae: 4607.8696\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4523.4253 - mae: 4523.9272 - val_loss: 4574.7397 - val_mae: 4575.2427\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4491.2959 - mae: 4491.7837 - val_loss: 4543.5508 - val_mae: 4544.0454\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4461.1074 - mae: 4461.6187 - val_loss: 4514.5620 - val_mae: 4515.0693\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4432.7397 - mae: 4433.2397 - val_loss: 4487.3882 - val_mae: 4487.8857\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4406.5747 - mae: 4407.0806 - val_loss: 4462.3320 - val_mae: 4462.8369\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4382.3164 - mae: 4382.8203 - val_loss: 4439.3589 - val_mae: 4439.8584\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4360.2036 - mae: 4360.7017 - val_loss: 4418.0039 - val_mae: 4418.5073\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4339.7637 - mae: 4340.2505 - val_loss: 4399.1211 - val_mae: 4399.6226\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4320.7681 - mae: 4321.2603 - val_loss: 4380.3882 - val_mae: 4380.8970\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4302.8013 - mae: 4303.3149 - val_loss: 4363.6504 - val_mae: 4364.1489\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4285.7847 - mae: 4286.2891 - val_loss: 4346.9839 - val_mae: 4347.4727\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4269.8579 - mae: 4270.3618 - val_loss: 4331.6641 - val_mae: 4332.1670\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4254.4336 - mae: 4254.9326 - val_loss: 4317.8008 - val_mae: 4318.2949\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4239.6636 - mae: 4240.1562 - val_loss: 4302.2085 - val_mae: 4302.7056\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4225.6377 - mae: 4226.1274 - val_loss: 4288.4160 - val_mae: 4288.9229\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4211.9541 - mae: 4212.4448 - val_loss: 4275.8242 - val_mae: 4276.3198\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4198.8760 - mae: 4199.3774 - val_loss: 4263.7280 - val_mae: 4264.2285\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4186.3389 - mae: 4186.8389 - val_loss: 4250.8843 - val_mae: 4251.3857\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4174.0161 - mae: 4174.5210 - val_loss: 4238.7417 - val_mae: 4239.2461\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4162.3740 - mae: 4162.8726 - val_loss: 4227.8394 - val_mae: 4228.3389\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4151.7993 - mae: 4152.2974 - val_loss: 4217.3555 - val_mae: 4217.8457\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4141.1079 - mae: 4141.6074 - val_loss: 4207.3242 - val_mae: 4207.8115\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4131.1738 - mae: 4131.6675 - val_loss: 4196.6240 - val_mae: 4197.1206\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4121.8975 - mae: 4122.4155 - val_loss: 4187.6978 - val_mae: 4188.1938\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4112.9873 - mae: 4113.5068 - val_loss: 4179.3901 - val_mae: 4179.8828\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4104.9014 - mae: 4105.3970 - val_loss: 4171.6968 - val_mae: 4172.1929\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4097.3257 - mae: 4097.8291 - val_loss: 4164.0610 - val_mae: 4164.5649\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4090.0403 - mae: 4090.5325 - val_loss: 4157.4365 - val_mae: 4157.9316\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4083.0376 - mae: 4083.5483 - val_loss: 4150.4429 - val_mae: 4150.9385\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4076.7732 - mae: 4077.2708 - val_loss: 4143.7021 - val_mae: 4144.1963\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4070.2786 - mae: 4070.7925 - val_loss: 4138.1294 - val_mae: 4138.6221\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4064.3606 - mae: 4064.8550 - val_loss: 4132.1128 - val_mae: 4132.6099\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4058.4392 - mae: 4058.9375 - val_loss: 4125.8901 - val_mae: 4126.3872\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4052.7156 - mae: 4053.2234 - val_loss: 4120.7070 - val_mae: 4121.2061\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4047.5112 - mae: 4048.0293 - val_loss: 4115.8745 - val_mae: 4116.3755\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4042.4683 - mae: 4042.9658 - val_loss: 4110.3208 - val_mae: 4110.8257\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4037.3215 - mae: 4037.8206 - val_loss: 4106.1523 - val_mae: 4106.6440\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4033.0889 - mae: 4033.5901 - val_loss: 4100.9458 - val_mae: 4101.4541\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4028.3037 - mae: 4028.7891 - val_loss: 4096.3521 - val_mae: 4096.8491\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4024.1255 - mae: 4024.6160 - val_loss: 4091.9165 - val_mae: 4092.4150\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4019.4407 - mae: 4019.9324 - val_loss: 4088.0640 - val_mae: 4088.5649\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4015.4124 - mae: 4015.9116 - val_loss: 4083.1228 - val_mae: 4083.6169\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4011.3708 - mae: 4011.8657 - val_loss: 4079.1924 - val_mae: 4079.6851\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4007.3386 - mae: 4007.8516 - val_loss: 4075.1389 - val_mae: 4075.6377\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4003.2493 - mae: 4003.7463 - val_loss: 4072.1003 - val_mae: 4072.6021\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3999.4814 - mae: 3999.9937 - val_loss: 4068.3594 - val_mae: 4068.8652\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3995.6560 - mae: 3996.1550 - val_loss: 4064.3650 - val_mae: 4064.8604\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3991.4956 - mae: 3992.0005 - val_loss: 4061.5950 - val_mae: 4062.0879\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3987.3792 - mae: 3987.8809 - val_loss: 4056.8789 - val_mae: 4057.3779\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3983.7898 - mae: 3984.2859 - val_loss: 4053.5845 - val_mae: 4054.0835\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3979.8547 - mae: 3980.3604 - val_loss: 4050.1284 - val_mae: 4050.6279\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3975.9084 - mae: 3976.4092 - val_loss: 4045.7339 - val_mae: 4046.2336\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3972.4656 - mae: 3972.9663 - val_loss: 4042.4353 - val_mae: 4042.9370\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 4014.8843 - mae: 4015.3801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 11664.1494 - mae: 11664.6572 - val_loss: 8692.6826 - val_mae: 8693.2041\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 7127.0620 - mae: 7127.5688 - val_loss: 6144.7578 - val_mae: 6145.2661\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5764.4126 - mae: 5764.9092 - val_loss: 5534.8198 - val_mae: 5535.3164\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 5359.0796 - mae: 5359.5698 - val_loss: 5243.2529 - val_mae: 5243.7539\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5070.1738 - mae: 5070.6699 - val_loss: 4955.7065 - val_mae: 4956.2109\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4772.2852 - mae: 4772.7886 - val_loss: 4641.4834 - val_mae: 4641.9834\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4473.1133 - mae: 4473.6138 - val_loss: 4380.1001 - val_mae: 4380.5957\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4247.5874 - mae: 4248.0815 - val_loss: 4199.3721 - val_mae: 4199.8838\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4097.2715 - mae: 4097.7715 - val_loss: 4069.4653 - val_mae: 4069.9670\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3990.7524 - mae: 3991.2571 - val_loss: 3982.1089 - val_mae: 3982.6045\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3911.7336 - mae: 3912.2366 - val_loss: 3916.2996 - val_mae: 3916.8044\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3860.6790 - mae: 3861.1897 - val_loss: 3876.4148 - val_mae: 3876.9124\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3823.1802 - mae: 3823.6702 - val_loss: 3846.5044 - val_mae: 3847.0046\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3794.8857 - mae: 3795.3845 - val_loss: 3827.8489 - val_mae: 3828.3416\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3772.0386 - mae: 3772.5203 - val_loss: 3795.3516 - val_mae: 3795.8535\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3750.7158 - mae: 3751.2185 - val_loss: 3780.7297 - val_mae: 3781.2246\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3734.4514 - mae: 3734.9517 - val_loss: 3759.3013 - val_mae: 3759.7981\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3720.9919 - mae: 3721.4907 - val_loss: 3748.2937 - val_mae: 3748.7954\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3707.9463 - mae: 3708.4465 - val_loss: 3736.9543 - val_mae: 3737.4512\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3697.7490 - mae: 3698.2451 - val_loss: 3723.7146 - val_mae: 3724.2161\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3687.6843 - mae: 3688.1909 - val_loss: 3720.3713 - val_mae: 3720.8674\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3680.7302 - mae: 3681.2371 - val_loss: 3706.3982 - val_mae: 3706.9001\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3673.8452 - mae: 3674.3328 - val_loss: 3700.8523 - val_mae: 3701.3518\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3668.3940 - mae: 3668.8896 - val_loss: 3692.2085 - val_mae: 3692.7012\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3663.9504 - mae: 3664.4451 - val_loss: 3692.0012 - val_mae: 3692.5076\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3661.4678 - mae: 3661.9807 - val_loss: 3689.4456 - val_mae: 3689.9414\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3657.3198 - mae: 3657.8140 - val_loss: 3687.2317 - val_mae: 3687.7322\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3654.0122 - mae: 3654.5161 - val_loss: 3683.6233 - val_mae: 3684.1240\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3650.9873 - mae: 3651.4844 - val_loss: 3680.2900 - val_mae: 3680.7869\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3648.4736 - mae: 3648.9727 - val_loss: 3676.9128 - val_mae: 3677.4160\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3645.5835 - mae: 3646.0977 - val_loss: 3673.6587 - val_mae: 3674.1611\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3644.2056 - mae: 3644.7090 - val_loss: 3672.7766 - val_mae: 3673.2803\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3642.3447 - mae: 3642.8499 - val_loss: 3672.1091 - val_mae: 3672.6060\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3640.6643 - mae: 3641.1770 - val_loss: 3670.4214 - val_mae: 3670.9216\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3638.6350 - mae: 3639.1294 - val_loss: 3666.9077 - val_mae: 3667.4001\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3636.8667 - mae: 3637.3660 - val_loss: 3668.5964 - val_mae: 3669.0952\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3635.5471 - mae: 3636.0513 - val_loss: 3664.7180 - val_mae: 3665.2112\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3634.4443 - mae: 3634.9456 - val_loss: 3663.9734 - val_mae: 3664.4729\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3632.8418 - mae: 3633.3442 - val_loss: 3663.4294 - val_mae: 3663.9280\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3631.5239 - mae: 3632.0161 - val_loss: 3663.0774 - val_mae: 3663.5750\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3629.6516 - mae: 3630.1555 - val_loss: 3670.7397 - val_mae: 3671.2407\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3628.8669 - mae: 3629.3765 - val_loss: 3662.7334 - val_mae: 3663.2322\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3627.8132 - mae: 3628.3181 - val_loss: 3661.0654 - val_mae: 3661.5657\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3626.7031 - mae: 3627.1958 - val_loss: 3662.7749 - val_mae: 3663.2808\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3625.4097 - mae: 3625.9067 - val_loss: 3658.2148 - val_mae: 3658.7112\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3624.7307 - mae: 3625.2261 - val_loss: 3657.6743 - val_mae: 3658.1775\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3623.4612 - mae: 3623.9546 - val_loss: 3655.3337 - val_mae: 3655.8257\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3622.9011 - mae: 3623.3928 - val_loss: 3656.8799 - val_mae: 3657.3801\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3621.6726 - mae: 3622.1619 - val_loss: 3654.0261 - val_mae: 3654.5256\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3621.6982 - mae: 3622.1985 - val_loss: 3653.8000 - val_mae: 3654.3022\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3620.4080 - mae: 3620.9067 - val_loss: 3655.1763 - val_mae: 3655.6829\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3620.3108 - mae: 3620.8010 - val_loss: 3654.1799 - val_mae: 3654.6802\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3619.4851 - mae: 3619.9722 - val_loss: 3653.4531 - val_mae: 3653.9512\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3617.9727 - mae: 3618.4673 - val_loss: 3656.1072 - val_mae: 3656.6067\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3618.2590 - mae: 3618.7578 - val_loss: 3655.8264 - val_mae: 3656.3301\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3617.8311 - mae: 3618.3264 - val_loss: 3652.3931 - val_mae: 3652.8931\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3617.3345 - mae: 3617.8313 - val_loss: 3654.7700 - val_mae: 3655.2776\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3617.1599 - mae: 3617.6680 - val_loss: 3654.2244 - val_mae: 3654.7231\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3616.9622 - mae: 3617.4636 - val_loss: 3650.0078 - val_mae: 3650.5027\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3616.4023 - mae: 3616.8999 - val_loss: 3651.2332 - val_mae: 3651.7305\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3615.6948 - mae: 3616.1992 - val_loss: 3651.4541 - val_mae: 3651.9529\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3614.8398 - mae: 3615.3281 - val_loss: 3652.7959 - val_mae: 3653.2930\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3615.2388 - mae: 3615.7485 - val_loss: 3654.3125 - val_mae: 3654.8083\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3614.4382 - mae: 3614.9211 - val_loss: 3650.3762 - val_mae: 3650.8757\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3614.0103 - mae: 3614.5159 - val_loss: 3650.9854 - val_mae: 3651.4890\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3613.5376 - mae: 3614.0359 - val_loss: 3649.6321 - val_mae: 3650.1326\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3613.2153 - mae: 3613.7190 - val_loss: 3649.3525 - val_mae: 3649.8479\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3612.9226 - mae: 3613.4202 - val_loss: 3649.1272 - val_mae: 3649.6296\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3611.9536 - mae: 3612.4602 - val_loss: 3649.2273 - val_mae: 3649.7253\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3611.7908 - mae: 3612.2974 - val_loss: 3648.6575 - val_mae: 3649.1619\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3610.6506 - mae: 3611.1582 - val_loss: 3644.6902 - val_mae: 3645.1885\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3609.9365 - mae: 3610.4304 - val_loss: 3648.7837 - val_mae: 3649.2878\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3608.7551 - mae: 3609.2554 - val_loss: 3646.3430 - val_mae: 3646.8455\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3608.5500 - mae: 3609.0500 - val_loss: 3654.2646 - val_mae: 3654.7610\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3606.2168 - mae: 3606.7170 - val_loss: 3643.3826 - val_mae: 3643.8901\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3604.5359 - mae: 3605.0391 - val_loss: 3646.5144 - val_mae: 3647.0110\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3602.4988 - mae: 3603.0129 - val_loss: 3640.8372 - val_mae: 3641.3376\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3601.0671 - mae: 3601.5596 - val_loss: 3639.2161 - val_mae: 3639.7134\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3599.5598 - mae: 3600.0540 - val_loss: 3641.6167 - val_mae: 3642.1191\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3598.9692 - mae: 3599.4756 - val_loss: 3640.4954 - val_mae: 3640.9988\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3598.6665 - mae: 3599.1533 - val_loss: 3640.6326 - val_mae: 3641.1277\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3598.3503 - mae: 3598.8521 - val_loss: 3637.9336 - val_mae: 3638.4395\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3597.7783 - mae: 3598.2739 - val_loss: 3636.9517 - val_mae: 3637.4512\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3596.5471 - mae: 3597.0374 - val_loss: 3640.1812 - val_mae: 3640.6807\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3596.4556 - mae: 3596.9551 - val_loss: 3636.0708 - val_mae: 3636.5598\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3595.6477 - mae: 3596.1389 - val_loss: 3638.0059 - val_mae: 3638.5063\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3595.2690 - mae: 3595.7683 - val_loss: 3637.5742 - val_mae: 3638.0698\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3594.7168 - mae: 3595.2302 - val_loss: 3640.6150 - val_mae: 3641.1089\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3593.6731 - mae: 3594.1685 - val_loss: 3634.7964 - val_mae: 3635.2966\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3593.5256 - mae: 3594.0234 - val_loss: 3638.6370 - val_mae: 3639.1360\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3592.9910 - mae: 3593.4861 - val_loss: 3638.9583 - val_mae: 3639.4543\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3592.7195 - mae: 3593.2173 - val_loss: 3641.0698 - val_mae: 3641.5737\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3592.3984 - mae: 3592.8967 - val_loss: 3630.9685 - val_mae: 3631.4690\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3591.7200 - mae: 3592.2153 - val_loss: 3638.1702 - val_mae: 3638.6699\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3591.6650 - mae: 3592.1628 - val_loss: 3633.9695 - val_mae: 3634.4653\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3591.1479 - mae: 3591.6489 - val_loss: 3633.8293 - val_mae: 3634.3333\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3590.9919 - mae: 3591.4883 - val_loss: 3631.7571 - val_mae: 3632.2561\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3590.8076 - mae: 3591.3130 - val_loss: 3629.3171 - val_mae: 3629.8174\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3589.5269 - mae: 3590.0149 - val_loss: 3639.6958 - val_mae: 3640.1960\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3589.9214 - mae: 3590.4331 - val_loss: 3631.2874 - val_mae: 3631.7864\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 3559.1353 - mae: 3559.6335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 12248.2539 - mae: 12248.7686 - val_loss: 9932.6816 - val_mae: 9933.1982\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 7946.1523 - mae: 7946.6699 - val_loss: 6677.9355 - val_mae: 6678.4512\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6091.6523 - mae: 6092.1484 - val_loss: 5791.4028 - val_mae: 5791.9058\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5572.6821 - mae: 5573.1733 - val_loss: 5475.6895 - val_mae: 5476.1938\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5337.5732 - mae: 5338.0728 - val_loss: 5277.0493 - val_mae: 5277.5459\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5160.5142 - mae: 5161.0195 - val_loss: 5109.4038 - val_mae: 5109.9077\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4996.7100 - mae: 4997.2090 - val_loss: 4944.6514 - val_mae: 4945.1494\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4814.6792 - mae: 4815.1846 - val_loss: 4742.0015 - val_mae: 4742.5005\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4615.1680 - mae: 4615.6807 - val_loss: 4570.4146 - val_mae: 4570.9155\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4458.9248 - mae: 4459.4263 - val_loss: 4438.9487 - val_mae: 4439.4521\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4341.4102 - mae: 4341.9189 - val_loss: 4339.5645 - val_mae: 4340.0664\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4253.9604 - mae: 4254.4600 - val_loss: 4263.1714 - val_mae: 4263.6660\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4189.2935 - mae: 4189.7935 - val_loss: 4205.4346 - val_mae: 4205.9390\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4141.7422 - mae: 4142.2363 - val_loss: 4171.3623 - val_mae: 4171.8594\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4106.5220 - mae: 4107.0269 - val_loss: 4143.6343 - val_mae: 4144.1421\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4074.5374 - mae: 4075.0317 - val_loss: 4112.3188 - val_mae: 4112.8105\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4049.1775 - mae: 4049.6826 - val_loss: 4086.6091 - val_mae: 4087.1011\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4025.9944 - mae: 4026.5051 - val_loss: 4062.1038 - val_mae: 4062.6018\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4003.0864 - mae: 4003.5869 - val_loss: 4040.0269 - val_mae: 4040.5254\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3980.6919 - mae: 3981.1895 - val_loss: 4021.7673 - val_mae: 4022.2737\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3963.1938 - mae: 3963.6978 - val_loss: 4005.1514 - val_mae: 4005.6497\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3948.7285 - mae: 3949.2307 - val_loss: 3995.1938 - val_mae: 3995.6931\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3936.8193 - mae: 3937.3220 - val_loss: 3987.2859 - val_mae: 3987.7847\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3927.7490 - mae: 3928.2478 - val_loss: 3975.6799 - val_mae: 3976.1829\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3919.6086 - mae: 3920.1177 - val_loss: 3965.3877 - val_mae: 3965.8855\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3910.2456 - mae: 3910.7434 - val_loss: 3956.8716 - val_mae: 3957.3682\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3903.3772 - mae: 3903.8833 - val_loss: 3952.0972 - val_mae: 3952.5952\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3899.4368 - mae: 3899.9585 - val_loss: 3946.0793 - val_mae: 3946.5823\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3895.1829 - mae: 3895.6819 - val_loss: 3943.6443 - val_mae: 3944.1436\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3891.8523 - mae: 3892.3452 - val_loss: 3944.3501 - val_mae: 3944.8557\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3888.5676 - mae: 3889.0698 - val_loss: 3938.9373 - val_mae: 3939.4321\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3884.7415 - mae: 3885.2515 - val_loss: 3942.4839 - val_mae: 3942.9805\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3882.8525 - mae: 3883.3645 - val_loss: 3936.0481 - val_mae: 3936.5449\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3880.0928 - mae: 3880.6108 - val_loss: 3931.4836 - val_mae: 3931.9937\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3877.9583 - mae: 3878.4612 - val_loss: 3931.3833 - val_mae: 3931.8867\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3875.4294 - mae: 3875.9390 - val_loss: 3925.8303 - val_mae: 3926.3296\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3874.2913 - mae: 3874.7925 - val_loss: 3926.0964 - val_mae: 3926.5981\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3872.2729 - mae: 3872.7861 - val_loss: 3923.8049 - val_mae: 3924.3042\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3871.3906 - mae: 3871.8950 - val_loss: 3926.1548 - val_mae: 3926.6533\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3870.2407 - mae: 3870.7490 - val_loss: 3924.0959 - val_mae: 3924.5913\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3869.0178 - mae: 3869.5320 - val_loss: 3920.5898 - val_mae: 3921.0938\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3868.0996 - mae: 3868.6021 - val_loss: 3918.9482 - val_mae: 3919.4509\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3866.6260 - mae: 3867.1282 - val_loss: 3920.3157 - val_mae: 3920.8149\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3865.1165 - mae: 3865.6040 - val_loss: 3918.1050 - val_mae: 3918.6116\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3864.6042 - mae: 3865.1116 - val_loss: 3916.0034 - val_mae: 3916.4954\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3862.9644 - mae: 3863.4646 - val_loss: 3922.7288 - val_mae: 3923.2339\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3862.4675 - mae: 3862.9688 - val_loss: 3912.1028 - val_mae: 3912.5969\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3861.8479 - mae: 3862.3430 - val_loss: 3915.3511 - val_mae: 3915.8513\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3860.8533 - mae: 3861.3503 - val_loss: 3911.3542 - val_mae: 3911.8499\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3860.1204 - mae: 3860.6152 - val_loss: 3909.4551 - val_mae: 3909.9500\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3859.3137 - mae: 3859.8110 - val_loss: 3911.9102 - val_mae: 3912.4075\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3858.9431 - mae: 3859.4600 - val_loss: 3914.5618 - val_mae: 3915.0637\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3857.4360 - mae: 3857.9316 - val_loss: 3910.7871 - val_mae: 3911.2839\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3856.4929 - mae: 3856.9866 - val_loss: 3906.3201 - val_mae: 3906.8225\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3855.0002 - mae: 3855.5005 - val_loss: 3915.0698 - val_mae: 3915.5757\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3854.2642 - mae: 3854.7656 - val_loss: 3905.8323 - val_mae: 3906.3337\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3852.8892 - mae: 3853.3894 - val_loss: 3903.0015 - val_mae: 3903.4985\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3852.9448 - mae: 3853.4456 - val_loss: 3903.1628 - val_mae: 3903.6604\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3851.8525 - mae: 3852.3606 - val_loss: 3900.9155 - val_mae: 3901.4150\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3850.9485 - mae: 3851.4539 - val_loss: 3902.1965 - val_mae: 3902.6948\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3851.1360 - mae: 3851.6409 - val_loss: 3910.0168 - val_mae: 3910.5110\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3850.5159 - mae: 3851.0234 - val_loss: 3901.8750 - val_mae: 3902.3765\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3850.6433 - mae: 3851.1475 - val_loss: 3901.3044 - val_mae: 3901.8086\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3849.6184 - mae: 3850.1040 - val_loss: 3904.2910 - val_mae: 3904.7939\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3849.1672 - mae: 3849.6577 - val_loss: 3903.7625 - val_mae: 3904.2568\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3847.7605 - mae: 3848.2666 - val_loss: 3901.8574 - val_mae: 3902.3569\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3847.1228 - mae: 3847.6362 - val_loss: 3909.8711 - val_mae: 3910.3704\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3847.1824 - mae: 3847.6819 - val_loss: 3898.0117 - val_mae: 3898.5156\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3846.0483 - mae: 3846.5508 - val_loss: 3899.5154 - val_mae: 3900.0076\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3846.1497 - mae: 3846.6499 - val_loss: 3899.3010 - val_mae: 3899.7986\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3845.4988 - mae: 3846.0098 - val_loss: 3897.6060 - val_mae: 3898.1089\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3844.0410 - mae: 3844.5444 - val_loss: 3899.3538 - val_mae: 3899.8547\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3843.4856 - mae: 3843.9792 - val_loss: 3895.4590 - val_mae: 3895.9668\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3842.5396 - mae: 3843.0449 - val_loss: 3893.0239 - val_mae: 3893.5312\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3842.0632 - mae: 3842.5520 - val_loss: 3898.3958 - val_mae: 3898.8958\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3840.6892 - mae: 3841.1912 - val_loss: 3893.6675 - val_mae: 3894.1663\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3840.7898 - mae: 3841.2722 - val_loss: 3894.1353 - val_mae: 3894.6379\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3840.9490 - mae: 3841.4414 - val_loss: 3894.7539 - val_mae: 3895.2522\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3840.8462 - mae: 3841.3462 - val_loss: 3890.7969 - val_mae: 3891.2898\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3840.5747 - mae: 3841.0813 - val_loss: 3892.0144 - val_mae: 3892.5093\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3840.4397 - mae: 3840.9417 - val_loss: 3891.8345 - val_mae: 3892.3279\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3840.0938 - mae: 3840.5933 - val_loss: 3895.2708 - val_mae: 3895.7683\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3839.9709 - mae: 3840.4644 - val_loss: 3890.3064 - val_mae: 3890.8086\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3840.0364 - mae: 3840.5376 - val_loss: 3891.0525 - val_mae: 3891.5510\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3839.7896 - mae: 3840.2998 - val_loss: 3890.6655 - val_mae: 3891.1741\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3839.2808 - mae: 3839.7632 - val_loss: 3889.3462 - val_mae: 3889.8552\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3838.4768 - mae: 3838.9709 - val_loss: 3894.2427 - val_mae: 3894.7393\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3837.6184 - mae: 3838.1152 - val_loss: 3891.1782 - val_mae: 3891.6819\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3837.0173 - mae: 3837.5142 - val_loss: 3888.0029 - val_mae: 3888.5051\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3837.6775 - mae: 3838.1711 - val_loss: 3891.6821 - val_mae: 3892.1882\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3836.8499 - mae: 3837.3491 - val_loss: 3888.9026 - val_mae: 3889.4050\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3836.5142 - mae: 3837.0234 - val_loss: 3887.7578 - val_mae: 3888.2615\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3836.5247 - mae: 3837.0237 - val_loss: 3887.2402 - val_mae: 3887.7366\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3836.4592 - mae: 3836.9646 - val_loss: 3889.9854 - val_mae: 3890.4851\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3836.0884 - mae: 3836.5876 - val_loss: 3888.6331 - val_mae: 3889.1353\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3835.3367 - mae: 3835.8291 - val_loss: 3887.0117 - val_mae: 3887.5073\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3834.6917 - mae: 3835.1931 - val_loss: 3885.6089 - val_mae: 3886.1079\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3834.6824 - mae: 3835.1892 - val_loss: 3883.8228 - val_mae: 3884.3269\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3834.1851 - mae: 3834.6768 - val_loss: 3883.2927 - val_mae: 3883.7913\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3834.7664 - mae: 3835.2637 - val_loss: 3889.2778 - val_mae: 3889.7693\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 3838.2524 - mae: 3838.7488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 11041.5781 - mae: 11042.0479 - val_loss: 7898.1187 - val_mae: 7898.6191\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6524.2500 - mae: 6524.7461 - val_loss: 5827.8716 - val_mae: 5828.3774\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5499.9136 - mae: 5500.4189 - val_loss: 5338.5146 - val_mae: 5339.0093\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5084.7539 - mae: 5085.2661 - val_loss: 4937.1948 - val_mae: 4937.7061\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4680.8491 - mae: 4681.3477 - val_loss: 4543.6450 - val_mae: 4544.1504\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4328.2061 - mae: 4328.7178 - val_loss: 4245.6602 - val_mae: 4246.1514\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 4077.5813 - mae: 4078.0806 - val_loss: 4032.5552 - val_mae: 4033.0471\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3902.6184 - mae: 3903.1274 - val_loss: 3896.2629 - val_mae: 3896.7634\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 16s 2ms/step - loss: 3787.7280 - mae: 3788.2307 - val_loss: 3797.6995 - val_mae: 3798.2004\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3705.9644 - mae: 3706.4651 - val_loss: 3731.5410 - val_mae: 3732.0342\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3646.2051 - mae: 3646.7017 - val_loss: 3686.6558 - val_mae: 3687.1545\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3606.9658 - mae: 3607.4690 - val_loss: 3651.8481 - val_mae: 3652.3477\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3579.0984 - mae: 3579.5962 - val_loss: 3627.6350 - val_mae: 3628.1348\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3557.6499 - mae: 3558.1504 - val_loss: 3610.3367 - val_mae: 3610.8362\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3540.3572 - mae: 3540.8613 - val_loss: 3592.4602 - val_mae: 3592.9612\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3526.1748 - mae: 3526.6643 - val_loss: 3580.2820 - val_mae: 3580.7834\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3512.7776 - mae: 3513.2927 - val_loss: 3571.4617 - val_mae: 3571.9578\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3501.9985 - mae: 3502.4812 - val_loss: 3557.4858 - val_mae: 3557.9902\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3491.7805 - mae: 3492.2808 - val_loss: 3546.9746 - val_mae: 3547.4763\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3483.4106 - mae: 3483.9119 - val_loss: 3536.6123 - val_mae: 3537.1128\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3475.1504 - mae: 3475.6460 - val_loss: 3536.8281 - val_mae: 3537.3271\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3468.2827 - mae: 3468.7700 - val_loss: 3525.6289 - val_mae: 3526.1299\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3459.2041 - mae: 3459.7002 - val_loss: 3517.8438 - val_mae: 3518.3389\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3451.2920 - mae: 3451.7957 - val_loss: 3507.4583 - val_mae: 3507.9612\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3444.9482 - mae: 3445.4358 - val_loss: 3497.4915 - val_mae: 3497.9863\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3437.3252 - mae: 3437.8254 - val_loss: 3494.3601 - val_mae: 3494.8665\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3431.8977 - mae: 3432.4092 - val_loss: 3490.8896 - val_mae: 3491.3850\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3425.4973 - mae: 3425.9797 - val_loss: 3481.7954 - val_mae: 3482.2944\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3420.1416 - mae: 3420.6389 - val_loss: 3473.9688 - val_mae: 3474.4727\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3412.6265 - mae: 3413.1418 - val_loss: 3469.7258 - val_mae: 3470.2268\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3407.6633 - mae: 3408.1667 - val_loss: 3458.8804 - val_mae: 3459.3882\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3401.0232 - mae: 3401.5181 - val_loss: 3451.9014 - val_mae: 3452.4028\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3395.9338 - mae: 3396.4263 - val_loss: 3447.8689 - val_mae: 3448.3687\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3390.6533 - mae: 3391.1592 - val_loss: 3444.0527 - val_mae: 3444.5518\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3386.0981 - mae: 3386.6062 - val_loss: 3442.6199 - val_mae: 3443.1233\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3383.7590 - mae: 3384.2512 - val_loss: 3438.5601 - val_mae: 3439.0596\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3379.9744 - mae: 3380.4785 - val_loss: 3433.8953 - val_mae: 3434.3909\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3378.3899 - mae: 3378.9006 - val_loss: 3431.5759 - val_mae: 3432.0750\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3376.3083 - mae: 3376.8079 - val_loss: 3435.0916 - val_mae: 3435.5872\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3373.2693 - mae: 3373.7712 - val_loss: 3427.9250 - val_mae: 3428.4277\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3370.8342 - mae: 3371.3267 - val_loss: 3429.7698 - val_mae: 3430.2695\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3367.9165 - mae: 3368.4111 - val_loss: 3423.7856 - val_mae: 3424.2859\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3365.3354 - mae: 3365.8396 - val_loss: 3419.6829 - val_mae: 3420.1841\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3363.7207 - mae: 3364.2275 - val_loss: 3419.7878 - val_mae: 3420.2939\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3361.0051 - mae: 3361.5181 - val_loss: 3415.3469 - val_mae: 3415.8450\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3359.0771 - mae: 3359.5752 - val_loss: 3414.0547 - val_mae: 3414.5576\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3356.5359 - mae: 3357.0325 - val_loss: 3411.1926 - val_mae: 3411.6929\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3354.9902 - mae: 3355.4985 - val_loss: 3405.9812 - val_mae: 3406.4827\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3351.0923 - mae: 3351.5974 - val_loss: 3406.8093 - val_mae: 3407.3093\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3349.1838 - mae: 3349.6658 - val_loss: 3400.5410 - val_mae: 3401.0386\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3345.8350 - mae: 3346.3264 - val_loss: 3400.5237 - val_mae: 3401.0203\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3343.9048 - mae: 3344.4041 - val_loss: 3395.2373 - val_mae: 3395.7375\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3342.3389 - mae: 3342.8396 - val_loss: 3397.4023 - val_mae: 3397.9053\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3341.0464 - mae: 3341.5425 - val_loss: 3390.3328 - val_mae: 3390.8303\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3337.5996 - mae: 3338.1084 - val_loss: 3391.0964 - val_mae: 3391.5974\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3335.3474 - mae: 3335.8396 - val_loss: 3390.7305 - val_mae: 3391.2327\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3333.3569 - mae: 3333.8623 - val_loss: 3388.8335 - val_mae: 3389.3342\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3330.0461 - mae: 3330.5459 - val_loss: 3382.7122 - val_mae: 3383.2119\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3325.9670 - mae: 3326.4644 - val_loss: 3378.8455 - val_mae: 3379.3457\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3322.4238 - mae: 3322.9231 - val_loss: 3373.0271 - val_mae: 3373.5308\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3318.0361 - mae: 3318.5354 - val_loss: 3370.2549 - val_mae: 3370.7610\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3314.1167 - mae: 3314.6067 - val_loss: 3368.5610 - val_mae: 3369.0630\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3311.4290 - mae: 3311.9158 - val_loss: 3364.0056 - val_mae: 3364.5027\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3308.4875 - mae: 3308.9832 - val_loss: 3363.3699 - val_mae: 3363.8679\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3306.7122 - mae: 3307.2073 - val_loss: 3363.7900 - val_mae: 3364.2898\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3304.5427 - mae: 3305.0540 - val_loss: 3357.8005 - val_mae: 3358.3022\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3302.4065 - mae: 3302.9092 - val_loss: 3361.0535 - val_mae: 3361.5520\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3300.9426 - mae: 3301.4385 - val_loss: 3356.6033 - val_mae: 3357.1023\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3298.9521 - mae: 3299.4429 - val_loss: 3358.1638 - val_mae: 3358.6626\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3297.4668 - mae: 3297.9648 - val_loss: 3349.2585 - val_mae: 3349.7571\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3295.5918 - mae: 3296.0959 - val_loss: 3351.7908 - val_mae: 3352.2900\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3294.2722 - mae: 3294.7610 - val_loss: 3347.8196 - val_mae: 3348.3184\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3292.6528 - mae: 3293.1614 - val_loss: 3347.0500 - val_mae: 3347.5493\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3291.0159 - mae: 3291.5110 - val_loss: 3347.8708 - val_mae: 3348.3684\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3289.3579 - mae: 3289.8647 - val_loss: 3346.3352 - val_mae: 3346.8369\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3288.0503 - mae: 3288.5564 - val_loss: 3342.0671 - val_mae: 3342.5696\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3286.1299 - mae: 3286.6292 - val_loss: 3348.2822 - val_mae: 3348.7805\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3284.8770 - mae: 3285.3767 - val_loss: 3342.8970 - val_mae: 3343.3977\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3283.2734 - mae: 3283.7629 - val_loss: 3340.3186 - val_mae: 3340.8210\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3282.7903 - mae: 3283.2825 - val_loss: 3339.3716 - val_mae: 3339.8704\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3281.8865 - mae: 3282.3848 - val_loss: 3337.7844 - val_mae: 3338.2861\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3280.0483 - mae: 3280.5503 - val_loss: 3339.3906 - val_mae: 3339.8884\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3279.4412 - mae: 3279.9402 - val_loss: 3334.7205 - val_mae: 3335.2173\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3279.6155 - mae: 3280.1226 - val_loss: 3335.5403 - val_mae: 3336.0393\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3278.6726 - mae: 3279.1672 - val_loss: 3336.0310 - val_mae: 3336.5305\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3277.9983 - mae: 3278.5105 - val_loss: 3332.0554 - val_mae: 3332.5566\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3277.1357 - mae: 3277.6277 - val_loss: 3335.2200 - val_mae: 3335.7170\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3276.8027 - mae: 3277.3005 - val_loss: 3340.1667 - val_mae: 3340.6707\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3275.5530 - mae: 3276.0564 - val_loss: 3335.5425 - val_mae: 3336.0457\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3274.5896 - mae: 3275.0930 - val_loss: 3334.6499 - val_mae: 3335.1501\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3274.4954 - mae: 3274.9875 - val_loss: 3330.5376 - val_mae: 3331.0354\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3272.9675 - mae: 3273.4568 - val_loss: 3336.7764 - val_mae: 3337.2800\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3271.8093 - mae: 3272.3083 - val_loss: 3333.3777 - val_mae: 3333.8748\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3272.0615 - mae: 3272.5569 - val_loss: 3331.1641 - val_mae: 3331.6633\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3271.3315 - mae: 3271.8376 - val_loss: 3329.2634 - val_mae: 3329.7629\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3270.3564 - mae: 3270.8616 - val_loss: 3330.7295 - val_mae: 3331.2297\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3270.0684 - mae: 3270.5769 - val_loss: 3325.7305 - val_mae: 3326.2290\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3269.6772 - mae: 3270.1868 - val_loss: 3329.1018 - val_mae: 3329.6033\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3269.9287 - mae: 3270.4229 - val_loss: 3327.1621 - val_mae: 3327.6606\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3268.5635 - mae: 3269.0579 - val_loss: 3324.0278 - val_mae: 3324.5266\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 3300.0056 - mae: 3300.5081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 5705.8765 - mae: 5706.3735 - val_loss: 4166.6929 - val_mae: 4167.1938\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3934.3870 - mae: 3934.8811 - val_loss: 4111.2729 - val_mae: 4111.7729\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3809.1304 - mae: 3809.6301 - val_loss: 3801.1951 - val_mae: 3801.6975\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3754.3347 - mae: 3754.8459 - val_loss: 3756.0869 - val_mae: 3756.5884\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3719.5916 - mae: 3720.0769 - val_loss: 3694.0193 - val_mae: 3694.5195\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3694.1636 - mae: 3694.6655 - val_loss: 3697.7197 - val_mae: 3698.2180\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3672.6467 - mae: 3673.1399 - val_loss: 3645.4810 - val_mae: 3645.9824\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 3654.6235 - mae: 3655.1226 - val_loss: 3701.3777 - val_mae: 3701.8721\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3641.3752 - mae: 3641.8721 - val_loss: 3653.9241 - val_mae: 3654.4270\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3627.3220 - mae: 3627.8247 - val_loss: 3653.1211 - val_mae: 3653.6194\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3614.9814 - mae: 3615.4895 - val_loss: 3699.5737 - val_mae: 3700.0720\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3593.5505 - mae: 3594.0430 - val_loss: 3690.8933 - val_mae: 3691.3879\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3566.8247 - mae: 3567.3235 - val_loss: 3607.8875 - val_mae: 3608.3862\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 3555.5054 - mae: 3556.0051 - val_loss: 3598.4641 - val_mae: 3598.9551\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 3530.6389 - mae: 3531.1384 - val_loss: 3499.8328 - val_mae: 3500.3352\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3504.7891 - mae: 3505.2781 - val_loss: 3540.0166 - val_mae: 3540.5171\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3493.4441 - mae: 3493.9480 - val_loss: 3555.5486 - val_mae: 3556.0427\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3483.2695 - mae: 3483.7683 - val_loss: 3512.6045 - val_mae: 3513.1055\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3475.8911 - mae: 3476.3901 - val_loss: 3509.7349 - val_mae: 3510.2368\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 3469.9055 - mae: 3470.4070 - val_loss: 3560.4946 - val_mae: 3560.9949\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3462.8718 - mae: 3463.3735 - val_loss: 3530.1191 - val_mae: 3530.6152\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3458.4546 - mae: 3458.9526 - val_loss: 3525.4805 - val_mae: 3525.9836\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3455.1399 - mae: 3455.6343 - val_loss: 3500.6301 - val_mae: 3501.1284\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3452.4397 - mae: 3452.9304 - val_loss: 3586.9902 - val_mae: 3587.4963\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3448.3191 - mae: 3448.8167 - val_loss: 3537.0732 - val_mae: 3537.5735\n",
            "3514/3514 [==============================] - 5s 2ms/step - loss: 3481.8848 - mae: 3482.3762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 6200.5522 - mae: 6201.0312 - val_loss: 4378.6528 - val_mae: 4379.1646\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 4080.1658 - mae: 4080.6594 - val_loss: 3967.0652 - val_mae: 3967.5642\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3827.7336 - mae: 3828.2285 - val_loss: 3820.1985 - val_mae: 3820.7012\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3709.8921 - mae: 3710.3887 - val_loss: 3679.6638 - val_mae: 3680.1609\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3643.3242 - mae: 3643.8208 - val_loss: 3669.9170 - val_mae: 3670.4182\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3600.1726 - mae: 3600.6731 - val_loss: 3630.5745 - val_mae: 3631.0718\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3572.4287 - mae: 3572.9192 - val_loss: 3722.5984 - val_mae: 3723.0938\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3550.5869 - mae: 3551.0869 - val_loss: 3691.8203 - val_mae: 3692.3264\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3541.2578 - mae: 3541.7590 - val_loss: 3556.8367 - val_mae: 3557.3374\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3530.0911 - mae: 3530.5989 - val_loss: 3597.6750 - val_mae: 3598.1741\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3514.4543 - mae: 3514.9443 - val_loss: 3577.1047 - val_mae: 3577.6045\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3507.7280 - mae: 3508.2144 - val_loss: 3682.9741 - val_mae: 3683.4731\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3497.3362 - mae: 3497.8240 - val_loss: 3529.7947 - val_mae: 3530.2976\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3484.2627 - mae: 3484.7529 - val_loss: 3497.1694 - val_mae: 3497.6697\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3478.3730 - mae: 3478.8799 - val_loss: 3625.6216 - val_mae: 3626.1211\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3472.9639 - mae: 3473.4600 - val_loss: 3545.1523 - val_mae: 3545.6526\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3465.5950 - mae: 3466.0835 - val_loss: 3466.7151 - val_mae: 3467.2100\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3462.1875 - mae: 3462.6953 - val_loss: 3466.9375 - val_mae: 3467.4275\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3454.2808 - mae: 3454.7715 - val_loss: 3525.6243 - val_mae: 3526.1230\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3448.6978 - mae: 3449.2068 - val_loss: 3505.1780 - val_mae: 3505.6741\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3437.3425 - mae: 3437.8428 - val_loss: 3468.9253 - val_mae: 3469.4221\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3434.8945 - mae: 3435.3940 - val_loss: 3480.1345 - val_mae: 3480.6321\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3426.4495 - mae: 3426.9468 - val_loss: 3491.2468 - val_mae: 3491.7444\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3421.9695 - mae: 3422.4763 - val_loss: 3426.6294 - val_mae: 3427.1316\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3419.0193 - mae: 3419.5247 - val_loss: 3448.8662 - val_mae: 3449.3711\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3418.5142 - mae: 3419.0254 - val_loss: 3417.9644 - val_mae: 3418.4636\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3410.1719 - mae: 3410.6677 - val_loss: 3477.1631 - val_mae: 3477.6714\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3408.2170 - mae: 3408.7227 - val_loss: 3411.6279 - val_mae: 3412.1228\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3405.1670 - mae: 3405.6743 - val_loss: 3469.2400 - val_mae: 3469.7417\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3404.1235 - mae: 3404.6240 - val_loss: 3422.6091 - val_mae: 3423.1084\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3401.3767 - mae: 3401.8716 - val_loss: 3659.8137 - val_mae: 3660.3147\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3398.3184 - mae: 3398.8220 - val_loss: 3398.3127 - val_mae: 3398.8093\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3395.5566 - mae: 3396.0593 - val_loss: 3412.9817 - val_mae: 3413.4785\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3392.7690 - mae: 3393.2622 - val_loss: 3396.8535 - val_mae: 3397.3518\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3388.0225 - mae: 3388.5181 - val_loss: 3428.9036 - val_mae: 3429.4011\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3386.0508 - mae: 3386.5503 - val_loss: 3495.3374 - val_mae: 3495.8342\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3386.6924 - mae: 3387.1948 - val_loss: 3423.2957 - val_mae: 3423.7954\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3381.8518 - mae: 3382.3464 - val_loss: 3399.0388 - val_mae: 3399.5405\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3381.4255 - mae: 3381.9238 - val_loss: 3421.3481 - val_mae: 3421.8481\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3381.2778 - mae: 3381.7847 - val_loss: 3426.9868 - val_mae: 3427.4854\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3376.9907 - mae: 3377.4807 - val_loss: 3400.1707 - val_mae: 3400.6719\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3373.9268 - mae: 3374.4312 - val_loss: 3379.4692 - val_mae: 3379.9661\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3372.4590 - mae: 3372.9592 - val_loss: 3408.9746 - val_mae: 3409.4727\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3373.7883 - mae: 3374.2961 - val_loss: 3475.3013 - val_mae: 3475.8037\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3368.7769 - mae: 3369.2676 - val_loss: 3448.8679 - val_mae: 3449.3655\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3366.3081 - mae: 3366.7954 - val_loss: 3404.1660 - val_mae: 3404.6655\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3368.4353 - mae: 3368.9385 - val_loss: 3479.8442 - val_mae: 3480.3467\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3368.4517 - mae: 3368.9456 - val_loss: 3431.0845 - val_mae: 3431.5820\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3367.6538 - mae: 3368.1584 - val_loss: 3388.9873 - val_mae: 3389.4890\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3366.6711 - mae: 3367.1790 - val_loss: 3421.5669 - val_mae: 3422.0681\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3364.9661 - mae: 3365.4663 - val_loss: 3414.5571 - val_mae: 3415.0566\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3364.2419 - mae: 3364.7534 - val_loss: 3389.9387 - val_mae: 3390.4409\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 3358.5315 - mae: 3359.0391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 5471.1772 - mae: 5471.6724 - val_loss: 4053.7131 - val_mae: 4054.2170\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3828.6929 - mae: 3829.1892 - val_loss: 3781.1069 - val_mae: 3781.6023\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3673.7778 - mae: 3674.2837 - val_loss: 3719.6184 - val_mae: 3720.1196\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3613.6809 - mae: 3614.1860 - val_loss: 3687.7925 - val_mae: 3688.2917\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3587.3638 - mae: 3587.8611 - val_loss: 3740.9883 - val_mae: 3741.4878\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3557.9739 - mae: 3558.4766 - val_loss: 3574.9744 - val_mae: 3575.4719\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3530.9302 - mae: 3531.4336 - val_loss: 3531.9827 - val_mae: 3532.4810\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3500.0127 - mae: 3500.5134 - val_loss: 3572.9766 - val_mae: 3573.4805\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3485.0576 - mae: 3485.5557 - val_loss: 3515.4209 - val_mae: 3515.9199\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3469.8130 - mae: 3470.3210 - val_loss: 3971.1887 - val_mae: 3971.6921\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3459.2954 - mae: 3459.7910 - val_loss: 3519.5969 - val_mae: 3520.0957\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3451.0142 - mae: 3451.5151 - val_loss: 3478.0103 - val_mae: 3478.5056\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3447.0637 - mae: 3447.5520 - val_loss: 3650.1360 - val_mae: 3650.6362\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3438.1245 - mae: 3438.6177 - val_loss: 3491.1213 - val_mae: 3491.6208\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3427.2166 - mae: 3427.7200 - val_loss: 3434.5564 - val_mae: 3435.0574\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3421.7791 - mae: 3422.2808 - val_loss: 3500.8462 - val_mae: 3501.3489\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3412.8604 - mae: 3413.3572 - val_loss: 3539.8960 - val_mae: 3540.3928\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3407.8203 - mae: 3408.3064 - val_loss: 3438.1768 - val_mae: 3438.6721\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 3406.3625 - mae: 3406.8586 - val_loss: 3786.4033 - val_mae: 3786.9131\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3399.1108 - mae: 3399.6167 - val_loss: 3592.4417 - val_mae: 3592.9436\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3389.9854 - mae: 3390.4714 - val_loss: 3449.4846 - val_mae: 3449.9829\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3387.3413 - mae: 3387.8420 - val_loss: 3466.0391 - val_mae: 3466.5347\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3384.6306 - mae: 3385.1240 - val_loss: 3394.6316 - val_mae: 3395.1296\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3379.9565 - mae: 3380.4563 - val_loss: 3465.3259 - val_mae: 3465.8247\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3373.5366 - mae: 3374.0366 - val_loss: 3401.8152 - val_mae: 3402.3113\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 3371.0435 - mae: 3371.5383 - val_loss: 3470.8845 - val_mae: 3471.3877\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 3366.0701 - mae: 3366.5605 - val_loss: 3415.6580 - val_mae: 3416.1572\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3369.0020 - mae: 3369.5054 - val_loss: 3397.0847 - val_mae: 3397.5859\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3363.7537 - mae: 3364.2566 - val_loss: 3409.8000 - val_mae: 3410.2996\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3360.9038 - mae: 3361.4055 - val_loss: 3419.5720 - val_mae: 3420.0691\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3361.4424 - mae: 3361.9448 - val_loss: 3397.7014 - val_mae: 3398.2019\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3355.8074 - mae: 3356.3135 - val_loss: 3450.0564 - val_mae: 3450.5552\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 20s 3ms/step - loss: 3358.2192 - mae: 3358.7197 - val_loss: 3443.5842 - val_mae: 3444.0884\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 3424.4214 - mae: 3424.9114\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 14163.6494 - mae: 14164.1182 - val_loss: 12796.1367 - val_mae: 12796.6279\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 12379.4619 - mae: 12379.9697 - val_loss: 11869.3057 - val_mae: 11869.8164\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 11343.3525 - mae: 11343.8389 - val_loss: 10678.1729 - val_mae: 10678.6602\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 10004.1475 - mae: 10004.6465 - val_loss: 9312.6455 - val_mae: 9313.1504\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 8792.6543 - mae: 8793.1670 - val_loss: 8288.6221 - val_mae: 8289.0996\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 7896.2925 - mae: 7896.7910 - val_loss: 7523.2402 - val_mae: 7523.7500\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 7220.5352 - mae: 7221.0298 - val_loss: 6945.0757 - val_mae: 6945.5728\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 6716.9819 - mae: 6717.4810 - val_loss: 6520.7788 - val_mae: 6521.2627\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 6348.8291 - mae: 6349.3169 - val_loss: 6216.4097 - val_mae: 6216.9116\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 6085.6704 - mae: 6086.1626 - val_loss: 5999.5967 - val_mae: 6000.1021\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5894.2134 - mae: 5894.7173 - val_loss: 5833.5098 - val_mae: 5834.0054\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5748.5132 - mae: 5749.0093 - val_loss: 5705.8765 - val_mae: 5706.3652\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5634.8979 - mae: 5635.3896 - val_loss: 5605.4062 - val_mae: 5605.9058\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 5542.1040 - mae: 5542.6167 - val_loss: 5522.4634 - val_mae: 5522.9609\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5464.9771 - mae: 5465.4976 - val_loss: 5452.7119 - val_mae: 5453.2129\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5398.8516 - mae: 5399.3403 - val_loss: 5390.9565 - val_mae: 5391.4619\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5337.2930 - mae: 5337.7827 - val_loss: 5332.8662 - val_mae: 5333.3594\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5278.2573 - mae: 5278.7461 - val_loss: 5276.3364 - val_mae: 5276.8457\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5221.1934 - mae: 5221.7192 - val_loss: 5221.7285 - val_mae: 5222.2222\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 5167.2725 - mae: 5167.7769 - val_loss: 5168.7310 - val_mae: 5169.2275\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5115.7739 - mae: 5116.2876 - val_loss: 5118.5806 - val_mae: 5119.0757\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5066.5005 - mae: 5066.9990 - val_loss: 5072.5254 - val_mae: 5073.0234\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5019.8687 - mae: 5020.3618 - val_loss: 5025.9746 - val_mae: 5026.4775\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4973.2271 - mae: 4973.7227 - val_loss: 4979.8770 - val_mae: 4980.3857\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4925.7925 - mae: 4926.2993 - val_loss: 4931.4263 - val_mae: 4931.9170\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 4876.3784 - mae: 4876.8848 - val_loss: 4881.0542 - val_mae: 4881.5518\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 4823.1631 - mae: 4823.6553 - val_loss: 4825.1587 - val_mae: 4825.6528\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4766.6323 - mae: 4767.1279 - val_loss: 4767.3662 - val_mae: 4767.8726\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4707.7363 - mae: 4708.2529 - val_loss: 4708.4009 - val_mae: 4708.9033\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4646.8076 - mae: 4647.3110 - val_loss: 4647.6060 - val_mae: 4648.1108\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4586.2393 - mae: 4586.7393 - val_loss: 4588.8579 - val_mae: 4589.3564\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4525.9209 - mae: 4526.4287 - val_loss: 4529.5854 - val_mae: 4530.0957\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 4467.1699 - mae: 4467.6821 - val_loss: 4472.6665 - val_mae: 4473.1626\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4409.4321 - mae: 4409.9395 - val_loss: 4416.5020 - val_mae: 4416.9922\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4353.2373 - mae: 4353.7383 - val_loss: 4361.5918 - val_mae: 4362.0977\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4298.9370 - mae: 4299.4263 - val_loss: 4309.5576 - val_mae: 4310.0615\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4246.3584 - mae: 4246.8726 - val_loss: 4257.7817 - val_mae: 4258.2866\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4196.8965 - mae: 4197.3975 - val_loss: 4210.5518 - val_mae: 4211.0498\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4150.2329 - mae: 4150.7354 - val_loss: 4165.4058 - val_mae: 4165.9072\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4105.7295 - mae: 4106.2334 - val_loss: 4122.1973 - val_mae: 4122.7046\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4062.7200 - mae: 4063.2170 - val_loss: 4081.3577 - val_mae: 4081.8545\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4022.1606 - mae: 4022.6594 - val_loss: 4042.0129 - val_mae: 4042.5161\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3983.5378 - mae: 3984.0342 - val_loss: 4005.4983 - val_mae: 4006.0076\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3946.9688 - mae: 3947.4729 - val_loss: 3970.0437 - val_mae: 3970.5410\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3912.1111 - mae: 3912.6099 - val_loss: 3936.3872 - val_mae: 3936.8892\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3878.9163 - mae: 3879.4172 - val_loss: 3905.3667 - val_mae: 3905.8706\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3847.9392 - mae: 3848.4399 - val_loss: 3876.4155 - val_mae: 3876.9167\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3818.4805 - mae: 3818.9785 - val_loss: 3848.4895 - val_mae: 3848.9905\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3791.5642 - mae: 3792.0793 - val_loss: 3823.4858 - val_mae: 3823.9883\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3766.4600 - mae: 3766.9578 - val_loss: 3799.8867 - val_mae: 3800.3889\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3742.5889 - mae: 3743.0896 - val_loss: 3777.3518 - val_mae: 3777.8464\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3720.6489 - mae: 3721.1477 - val_loss: 3756.3826 - val_mae: 3756.8772\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3700.4001 - mae: 3700.9004 - val_loss: 3738.0879 - val_mae: 3738.5913\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3681.9495 - mae: 3682.4507 - val_loss: 3720.2097 - val_mae: 3720.7100\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3664.6201 - mae: 3665.1367 - val_loss: 3704.4834 - val_mae: 3704.9954\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3648.5334 - mae: 3649.0410 - val_loss: 3690.3457 - val_mae: 3690.8455\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3634.1760 - mae: 3634.6836 - val_loss: 3675.8850 - val_mae: 3676.3818\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3620.3481 - mae: 3620.8406 - val_loss: 3663.1863 - val_mae: 3663.6860\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3607.3945 - mae: 3607.8970 - val_loss: 3651.1619 - val_mae: 3651.6621\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3594.9048 - mae: 3595.4172 - val_loss: 3640.2605 - val_mae: 3640.7664\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3583.1882 - mae: 3583.6711 - val_loss: 3629.3931 - val_mae: 3629.8950\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3571.4136 - mae: 3571.9133 - val_loss: 3616.4197 - val_mae: 3616.9143\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3560.6062 - mae: 3561.1138 - val_loss: 3606.4243 - val_mae: 3606.9280\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3549.8569 - mae: 3550.3611 - val_loss: 3596.2888 - val_mae: 3596.7883\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3539.7866 - mae: 3540.2822 - val_loss: 3586.1094 - val_mae: 3586.6096\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3530.0015 - mae: 3530.4856 - val_loss: 3576.9673 - val_mae: 3577.4702\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3520.6858 - mae: 3521.1912 - val_loss: 3567.7048 - val_mae: 3568.2058\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3511.5989 - mae: 3512.1052 - val_loss: 3559.7712 - val_mae: 3560.2747\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3503.0220 - mae: 3503.5083 - val_loss: 3550.9448 - val_mae: 3551.4485\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3494.6460 - mae: 3495.1409 - val_loss: 3543.1982 - val_mae: 3543.6980\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3486.6072 - mae: 3487.1060 - val_loss: 3535.5769 - val_mae: 3536.0774\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3478.8164 - mae: 3479.3193 - val_loss: 3527.3230 - val_mae: 3527.8184\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3471.1077 - mae: 3471.6052 - val_loss: 3520.4187 - val_mae: 3520.9197\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3463.6653 - mae: 3464.1599 - val_loss: 3513.0166 - val_mae: 3513.5115\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3456.1885 - mae: 3456.6797 - val_loss: 3505.3796 - val_mae: 3505.8833\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3448.7344 - mae: 3449.2317 - val_loss: 3499.4385 - val_mae: 3499.9353\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3441.5320 - mae: 3442.0300 - val_loss: 3493.6824 - val_mae: 3494.1887\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3434.7317 - mae: 3435.2256 - val_loss: 3485.4138 - val_mae: 3485.9141\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3427.7468 - mae: 3428.2485 - val_loss: 3479.5706 - val_mae: 3480.0735\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3421.2205 - mae: 3421.7241 - val_loss: 3472.1108 - val_mae: 3472.6130\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3414.4368 - mae: 3414.9277 - val_loss: 3466.6318 - val_mae: 3467.1326\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3408.4067 - mae: 3408.9011 - val_loss: 3460.4189 - val_mae: 3460.9180\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3402.1272 - mae: 3402.6377 - val_loss: 3453.5732 - val_mae: 3454.0730\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3395.8821 - mae: 3396.3911 - val_loss: 3447.7107 - val_mae: 3448.2075\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3389.8657 - mae: 3390.3687 - val_loss: 3441.6885 - val_mae: 3442.1860\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3383.9001 - mae: 3384.4009 - val_loss: 3436.3604 - val_mae: 3436.8567\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3377.9709 - mae: 3378.4714 - val_loss: 3430.1689 - val_mae: 3430.6687\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3372.1465 - mae: 3372.6418 - val_loss: 3424.6660 - val_mae: 3425.1648\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 3366.6741 - mae: 3367.1697 - val_loss: 3419.1929 - val_mae: 3419.6926\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3361.0417 - mae: 3361.5510 - val_loss: 3413.6028 - val_mae: 3414.1028\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3355.8171 - mae: 3356.3115 - val_loss: 3408.1382 - val_mae: 3408.6392\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3350.2764 - mae: 3350.7815 - val_loss: 3403.7268 - val_mae: 3404.2275\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3345.1226 - mae: 3345.6257 - val_loss: 3398.2478 - val_mae: 3398.7507\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3340.1304 - mae: 3340.6396 - val_loss: 3393.5852 - val_mae: 3394.0872\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3335.0342 - mae: 3335.5359 - val_loss: 3387.7212 - val_mae: 3388.2173\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3329.8418 - mae: 3330.3438 - val_loss: 3383.0559 - val_mae: 3383.5549\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3325.1936 - mae: 3325.6914 - val_loss: 3378.1523 - val_mae: 3378.6545\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3320.0413 - mae: 3320.5425 - val_loss: 3373.1580 - val_mae: 3373.6599\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3315.2910 - mae: 3315.7925 - val_loss: 3368.5903 - val_mae: 3369.0872\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3310.5950 - mae: 3311.0994 - val_loss: 3363.0044 - val_mae: 3363.5054\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 3307.2427 - mae: 3307.7354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 19s 3ms/step - loss: 14047.8887 - mae: 14048.4092 - val_loss: 12736.8271 - val_mae: 12737.3252\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 12226.6484 - mae: 12227.1572 - val_loss: 11705.5078 - val_mae: 11705.9912\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 11012.4551 - mae: 11012.9326 - val_loss: 10279.2715 - val_mae: 10279.7695\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 9521.3867 - mae: 9521.8896 - val_loss: 8897.4219 - val_mae: 8897.9287\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 8352.6211 - mae: 8353.1084 - val_loss: 7931.8374 - val_mae: 7932.3452\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 7518.5742 - mae: 7519.0737 - val_loss: 7226.7207 - val_mae: 7227.2192\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 6907.9023 - mae: 6908.3979 - val_loss: 6717.4033 - val_mae: 6717.8979\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 6473.1001 - mae: 6473.5947 - val_loss: 6355.0073 - val_mae: 6355.5137\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 6166.0977 - mae: 6166.5996 - val_loss: 6102.6113 - val_mae: 6103.1006\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5954.0605 - mae: 5954.5581 - val_loss: 5921.0483 - val_mae: 5921.5542\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5797.5581 - mae: 5798.0576 - val_loss: 5776.4951 - val_mae: 5776.9907\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5673.6621 - mae: 5674.1611 - val_loss: 5664.5122 - val_mae: 5665.0137\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5575.2847 - mae: 5575.7842 - val_loss: 5572.9834 - val_mae: 5573.4810\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5492.8032 - mae: 5493.2979 - val_loss: 5495.3276 - val_mae: 5495.8335\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5419.1167 - mae: 5419.6021 - val_loss: 5424.7715 - val_mae: 5425.2651\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5350.8804 - mae: 5351.3770 - val_loss: 5359.1279 - val_mae: 5359.6226\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5285.3423 - mae: 5285.8262 - val_loss: 5293.8394 - val_mae: 5294.3374\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5222.8809 - mae: 5223.3716 - val_loss: 5233.0205 - val_mae: 5233.5161\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5162.0122 - mae: 5162.5273 - val_loss: 5172.6440 - val_mae: 5173.1421\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5101.2236 - mae: 5101.7207 - val_loss: 5112.0630 - val_mae: 5112.5596\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5039.1631 - mae: 5039.6655 - val_loss: 5047.2666 - val_mae: 5047.7637\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4975.6587 - mae: 4976.1514 - val_loss: 4984.9341 - val_mae: 4985.4409\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4910.7407 - mae: 4911.2285 - val_loss: 4918.2334 - val_mae: 4918.7397\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4841.7749 - mae: 4842.2866 - val_loss: 4847.4302 - val_mae: 4847.9380\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 4768.5986 - mae: 4769.1040 - val_loss: 4771.4468 - val_mae: 4771.9478\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4691.5815 - mae: 4692.0869 - val_loss: 4694.1733 - val_mae: 4694.6777\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4614.0615 - mae: 4614.5645 - val_loss: 4617.5430 - val_mae: 4618.0435\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4538.9072 - mae: 4539.4150 - val_loss: 4544.7939 - val_mae: 4545.2959\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 4467.7134 - mae: 4468.2075 - val_loss: 4476.3394 - val_mae: 4476.8398\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4400.4683 - mae: 4400.9683 - val_loss: 4410.5078 - val_mae: 4411.0103\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4336.3926 - mae: 4336.8965 - val_loss: 4347.3970 - val_mae: 4347.8906\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4275.2017 - mae: 4275.6968 - val_loss: 4289.2754 - val_mae: 4289.7729\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4217.2485 - mae: 4217.7446 - val_loss: 4232.4141 - val_mae: 4232.9180\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4161.4839 - mae: 4161.9839 - val_loss: 4177.4595 - val_mae: 4177.9609\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4108.3960 - mae: 4108.8960 - val_loss: 4126.0430 - val_mae: 4126.5479\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4058.3118 - mae: 4058.8167 - val_loss: 4076.5854 - val_mae: 4077.0847\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4010.5273 - mae: 4011.0383 - val_loss: 4030.8416 - val_mae: 4031.3359\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3964.9702 - mae: 3965.4727 - val_loss: 3989.0317 - val_mae: 3989.5276\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3922.3767 - mae: 3922.8794 - val_loss: 3947.7290 - val_mae: 3948.2310\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3882.9368 - mae: 3883.4500 - val_loss: 3910.3943 - val_mae: 3910.8945\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3847.3215 - mae: 3847.8215 - val_loss: 3876.0842 - val_mae: 3876.5886\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3814.0342 - mae: 3814.5347 - val_loss: 3845.9890 - val_mae: 3846.4912\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3783.3506 - mae: 3783.8469 - val_loss: 3817.7305 - val_mae: 3818.2349\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3755.5542 - mae: 3756.0569 - val_loss: 3790.2451 - val_mae: 3790.7441\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3729.4722 - mae: 3729.9731 - val_loss: 3766.7720 - val_mae: 3767.2693\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3705.6218 - mae: 3706.1228 - val_loss: 3743.5889 - val_mae: 3744.0898\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3683.4255 - mae: 3683.9136 - val_loss: 3722.4382 - val_mae: 3722.9412\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3662.8406 - mae: 3663.3481 - val_loss: 3702.7720 - val_mae: 3703.2744\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3643.9070 - mae: 3644.4126 - val_loss: 3686.8164 - val_mae: 3687.3147\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3626.2358 - mae: 3626.7410 - val_loss: 3670.9561 - val_mae: 3671.4543\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3609.5452 - mae: 3610.0425 - val_loss: 3654.5825 - val_mae: 3655.0771\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3594.1365 - mae: 3594.6453 - val_loss: 3640.2297 - val_mae: 3640.7332\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3579.6121 - mae: 3580.1150 - val_loss: 3626.3215 - val_mae: 3626.8193\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3565.9993 - mae: 3566.4917 - val_loss: 3614.3972 - val_mae: 3614.9021\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3553.2490 - mae: 3553.7505 - val_loss: 3602.9771 - val_mae: 3603.4751\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3541.0349 - mae: 3541.5410 - val_loss: 3590.8684 - val_mae: 3591.3767\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3529.0386 - mae: 3529.5308 - val_loss: 3580.1963 - val_mae: 3580.6943\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3517.6604 - mae: 3518.1545 - val_loss: 3569.9561 - val_mae: 3570.4587\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3506.5835 - mae: 3507.0776 - val_loss: 3559.8511 - val_mae: 3560.3445\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3496.0122 - mae: 3496.5178 - val_loss: 3551.1677 - val_mae: 3551.6714\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3485.7019 - mae: 3486.2051 - val_loss: 3539.8242 - val_mae: 3540.3237\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3475.8145 - mae: 3476.3213 - val_loss: 3530.8167 - val_mae: 3531.3191\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3466.2654 - mae: 3466.7712 - val_loss: 3521.0691 - val_mae: 3521.5725\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3456.8940 - mae: 3457.3882 - val_loss: 3513.9490 - val_mae: 3514.4478\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3447.9438 - mae: 3448.4451 - val_loss: 3505.2051 - val_mae: 3505.7041\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3439.6475 - mae: 3440.1521 - val_loss: 3496.2166 - val_mae: 3496.7156\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3431.3958 - mae: 3431.8933 - val_loss: 3487.5298 - val_mae: 3488.0266\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3423.3042 - mae: 3423.8064 - val_loss: 3480.6682 - val_mae: 3481.1672\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3415.7795 - mae: 3416.2778 - val_loss: 3472.4626 - val_mae: 3472.9600\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3408.0361 - mae: 3408.5369 - val_loss: 3466.9658 - val_mae: 3467.4666\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3400.7563 - mae: 3401.2502 - val_loss: 3457.0520 - val_mae: 3457.5562\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3393.2791 - mae: 3393.7817 - val_loss: 3450.7380 - val_mae: 3451.2354\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3386.4199 - mae: 3386.9163 - val_loss: 3443.7866 - val_mae: 3444.2842\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3379.3650 - mae: 3379.8577 - val_loss: 3438.0544 - val_mae: 3438.5613\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3372.9204 - mae: 3373.4167 - val_loss: 3431.2939 - val_mae: 3431.7925\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3366.3420 - mae: 3366.8357 - val_loss: 3424.8447 - val_mae: 3425.3477\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3359.9404 - mae: 3360.4514 - val_loss: 3418.6228 - val_mae: 3419.1182\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3353.5649 - mae: 3354.0718 - val_loss: 3412.1763 - val_mae: 3412.6809\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3347.3682 - mae: 3347.8650 - val_loss: 3406.5195 - val_mae: 3407.0208\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3341.7041 - mae: 3342.2058 - val_loss: 3399.5164 - val_mae: 3400.0181\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3335.6958 - mae: 3336.1973 - val_loss: 3393.8203 - val_mae: 3394.3174\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3329.9678 - mae: 3330.4719 - val_loss: 3388.2454 - val_mae: 3388.7444\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3324.2600 - mae: 3324.7656 - val_loss: 3383.5012 - val_mae: 3384.0005\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3318.5901 - mae: 3319.0945 - val_loss: 3377.9087 - val_mae: 3378.4104\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3313.1433 - mae: 3313.6375 - val_loss: 3373.1326 - val_mae: 3373.6294\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3307.3435 - mae: 3307.8401 - val_loss: 3367.2795 - val_mae: 3367.7754\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3302.2144 - mae: 3302.7014 - val_loss: 3360.6497 - val_mae: 3361.1472\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3296.9587 - mae: 3297.4578 - val_loss: 3356.2905 - val_mae: 3356.7917\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3291.9431 - mae: 3292.4399 - val_loss: 3349.9131 - val_mae: 3350.4114\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3286.7737 - mae: 3287.2751 - val_loss: 3345.7329 - val_mae: 3346.2351\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3281.6519 - mae: 3282.1494 - val_loss: 3340.2175 - val_mae: 3340.7136\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3276.8926 - mae: 3277.3945 - val_loss: 3335.5317 - val_mae: 3336.0347\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3272.0632 - mae: 3272.5586 - val_loss: 3331.1448 - val_mae: 3331.6482\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3267.2385 - mae: 3267.7456 - val_loss: 3326.1152 - val_mae: 3326.6162\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3262.3948 - mae: 3262.8970 - val_loss: 3321.4155 - val_mae: 3321.9126\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3257.6863 - mae: 3258.1953 - val_loss: 3318.0312 - val_mae: 3318.5305\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3253.2751 - mae: 3253.7761 - val_loss: 3312.1384 - val_mae: 3312.6370\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3248.5000 - mae: 3249.0066 - val_loss: 3308.2175 - val_mae: 3308.7175\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3244.1099 - mae: 3244.6067 - val_loss: 3303.7627 - val_mae: 3304.2620\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3239.8877 - mae: 3240.3831 - val_loss: 3299.2520 - val_mae: 3299.7502\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 3255.2078 - mae: 3255.7075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 13965.7490 - mae: 13966.2373 - val_loss: 12702.5840 - val_mae: 12703.0898\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 12157.8320 - mae: 12158.3467 - val_loss: 11645.3262 - val_mae: 11645.8359\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 10931.1055 - mae: 10931.5938 - val_loss: 10199.5635 - val_mae: 10200.0615\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 9405.8584 - mae: 9406.3408 - val_loss: 8785.6738 - val_mae: 8786.1562\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 8217.7256 - mae: 8218.2412 - val_loss: 7798.0317 - val_mae: 7798.5215\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 7379.1201 - mae: 7379.6216 - val_loss: 7096.6304 - val_mae: 7097.1455\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6771.7964 - mae: 6772.2944 - val_loss: 6590.1655 - val_mae: 6590.6777\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6346.6597 - mae: 6347.1758 - val_loss: 6236.4902 - val_mae: 6236.9980\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 6048.8809 - mae: 6049.3667 - val_loss: 5992.3389 - val_mae: 5992.8374\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5841.7285 - mae: 5842.2300 - val_loss: 5815.4556 - val_mae: 5815.9517\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5685.9561 - mae: 5686.4482 - val_loss: 5675.5835 - val_mae: 5676.0864\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 5565.6499 - mae: 5566.1479 - val_loss: 5569.3682 - val_mae: 5569.8589\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5470.9106 - mae: 5471.4170 - val_loss: 5484.6108 - val_mae: 5485.1152\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5391.5435 - mae: 5392.0371 - val_loss: 5410.1226 - val_mae: 5410.6226\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5319.9648 - mae: 5320.4541 - val_loss: 5343.9536 - val_mae: 5344.4575\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5254.8613 - mae: 5255.3560 - val_loss: 5281.1577 - val_mae: 5281.6494\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5193.1904 - mae: 5193.6982 - val_loss: 5220.9697 - val_mae: 5221.4614\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5132.1279 - mae: 5132.6118 - val_loss: 5160.2754 - val_mae: 5160.7686\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 5071.0088 - mae: 5071.4980 - val_loss: 5100.2417 - val_mae: 5100.7476\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 5010.5952 - mae: 5011.1016 - val_loss: 5042.6245 - val_mae: 5043.1221\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4950.0073 - mae: 4950.5171 - val_loss: 4979.4224 - val_mae: 4979.9321\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4886.7588 - mae: 4887.2744 - val_loss: 4914.8589 - val_mae: 4915.3530\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4820.5596 - mae: 4821.0708 - val_loss: 4846.9883 - val_mae: 4847.4932\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4748.1133 - mae: 4748.5977 - val_loss: 4772.0498 - val_mae: 4772.5474\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4670.3643 - mae: 4670.8657 - val_loss: 4692.5239 - val_mae: 4693.0200\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4590.1226 - mae: 4590.6152 - val_loss: 4612.9619 - val_mae: 4613.4609\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4509.9448 - mae: 4510.4517 - val_loss: 4534.5156 - val_mae: 4535.0229\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4432.4077 - mae: 4432.9019 - val_loss: 4459.2002 - val_mae: 4459.6978\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4358.8174 - mae: 4359.3125 - val_loss: 4388.1431 - val_mae: 4388.6450\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4289.1113 - mae: 4289.6157 - val_loss: 4319.4375 - val_mae: 4319.9380\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4221.9033 - mae: 4222.3989 - val_loss: 4255.4009 - val_mae: 4255.9014\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 4159.0020 - mae: 4159.4995 - val_loss: 4194.5981 - val_mae: 4195.0962\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4100.8384 - mae: 4101.3438 - val_loss: 4137.4419 - val_mae: 4137.9463\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 4046.8286 - mae: 4047.3293 - val_loss: 4085.1060 - val_mae: 4085.6111\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3996.4448 - mae: 3996.9497 - val_loss: 4037.6646 - val_mae: 4038.1667\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3949.1433 - mae: 3949.6433 - val_loss: 3991.6357 - val_mae: 3992.1426\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3904.6021 - mae: 3905.1082 - val_loss: 3950.3513 - val_mae: 3950.8489\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3863.5850 - mae: 3864.0894 - val_loss: 3911.0164 - val_mae: 3911.5200\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3825.9668 - mae: 3826.4551 - val_loss: 3875.2952 - val_mae: 3875.7920\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3791.5696 - mae: 3792.0664 - val_loss: 3842.4912 - val_mae: 3842.9919\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3759.8547 - mae: 3760.3525 - val_loss: 3812.3042 - val_mae: 3812.8069\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3731.1724 - mae: 3731.6655 - val_loss: 3784.5737 - val_mae: 3785.0747\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3704.9863 - mae: 3705.4822 - val_loss: 3761.6089 - val_mae: 3762.1094\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3681.9675 - mae: 3682.4683 - val_loss: 3740.7861 - val_mae: 3741.2852\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3661.4001 - mae: 3661.8977 - val_loss: 3719.8188 - val_mae: 3720.3262\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3642.4539 - mae: 3642.9500 - val_loss: 3701.7332 - val_mae: 3702.2324\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3625.2498 - mae: 3625.7522 - val_loss: 3684.8599 - val_mae: 3685.3582\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3609.3083 - mae: 3609.8015 - val_loss: 3670.1592 - val_mae: 3670.6570\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3594.4927 - mae: 3594.9968 - val_loss: 3656.3889 - val_mae: 3656.8926\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3580.3538 - mae: 3580.8428 - val_loss: 3643.5432 - val_mae: 3644.0396\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3567.5244 - mae: 3568.0247 - val_loss: 3630.2314 - val_mae: 3630.7285\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3555.3965 - mae: 3555.9023 - val_loss: 3618.8787 - val_mae: 3619.3733\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3543.5117 - mae: 3544.0264 - val_loss: 3608.1394 - val_mae: 3608.6343\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3532.5103 - mae: 3533.0002 - val_loss: 3596.9756 - val_mae: 3597.4741\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3521.4331 - mae: 3521.9270 - val_loss: 3588.9028 - val_mae: 3589.4023\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3511.2720 - mae: 3511.7847 - val_loss: 3577.6106 - val_mae: 3578.1082\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3501.0786 - mae: 3501.5752 - val_loss: 3568.0422 - val_mae: 3568.5457\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3491.7485 - mae: 3492.2305 - val_loss: 3558.9333 - val_mae: 3559.4324\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3482.3254 - mae: 3482.8347 - val_loss: 3550.0312 - val_mae: 3550.5298\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3473.7205 - mae: 3474.2107 - val_loss: 3540.9851 - val_mae: 3541.4873\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3465.0010 - mae: 3465.4995 - val_loss: 3532.7759 - val_mae: 3533.2734\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3456.8267 - mae: 3457.3232 - val_loss: 3524.9055 - val_mae: 3525.4084\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3448.1284 - mae: 3448.6230 - val_loss: 3517.0579 - val_mae: 3517.5520\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3440.2598 - mae: 3440.7622 - val_loss: 3510.4104 - val_mae: 3510.9080\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3432.3411 - mae: 3432.8337 - val_loss: 3502.2432 - val_mae: 3502.7454\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3424.3428 - mae: 3424.8403 - val_loss: 3493.8718 - val_mae: 3494.3730\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3416.8311 - mae: 3417.3521 - val_loss: 3485.6028 - val_mae: 3486.1030\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3409.2991 - mae: 3409.8062 - val_loss: 3478.0327 - val_mae: 3478.5303\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3401.8694 - mae: 3402.3652 - val_loss: 3471.9458 - val_mae: 3472.4490\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3394.4521 - mae: 3394.9504 - val_loss: 3463.7068 - val_mae: 3464.2097\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3387.4453 - mae: 3387.9390 - val_loss: 3459.2903 - val_mae: 3459.7942\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3380.4177 - mae: 3380.9148 - val_loss: 3451.0925 - val_mae: 3451.5925\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3373.4417 - mae: 3373.9509 - val_loss: 3443.0537 - val_mae: 3443.5513\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3366.6558 - mae: 3367.1602 - val_loss: 3437.0293 - val_mae: 3437.5259\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3359.6995 - mae: 3360.2063 - val_loss: 3432.0779 - val_mae: 3432.5793\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3353.1577 - mae: 3353.6462 - val_loss: 3423.4526 - val_mae: 3423.9495\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 18s 2ms/step - loss: 3346.7932 - mae: 3347.2881 - val_loss: 3417.2786 - val_mae: 3417.7795\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3340.2747 - mae: 3340.7649 - val_loss: 3410.4229 - val_mae: 3410.9238\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3334.1763 - mae: 3334.6838 - val_loss: 3407.6812 - val_mae: 3408.1812\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3328.0703 - mae: 3328.5623 - val_loss: 3400.9460 - val_mae: 3401.4473\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3322.4878 - mae: 3322.9849 - val_loss: 3395.0906 - val_mae: 3395.5916\n",
            "Epoch 82/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3316.7036 - mae: 3317.2036 - val_loss: 3388.5337 - val_mae: 3389.0291\n",
            "Epoch 83/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3311.1143 - mae: 3311.6177 - val_loss: 3382.0586 - val_mae: 3382.5542\n",
            "Epoch 84/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3305.7327 - mae: 3306.2192 - val_loss: 3377.3496 - val_mae: 3377.8491\n",
            "Epoch 85/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3300.1433 - mae: 3300.6377 - val_loss: 3372.0229 - val_mae: 3372.5208\n",
            "Epoch 86/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3294.7136 - mae: 3295.2041 - val_loss: 3366.2463 - val_mae: 3366.7471\n",
            "Epoch 87/100\n",
            "7027/7027 [==============================] - 17s 2ms/step - loss: 3289.4038 - mae: 3289.9084 - val_loss: 3360.5840 - val_mae: 3361.0835\n",
            "Epoch 88/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3284.2126 - mae: 3284.7236 - val_loss: 3357.2625 - val_mae: 3357.7627\n",
            "Epoch 89/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3278.9187 - mae: 3279.4314 - val_loss: 3351.7651 - val_mae: 3352.2620\n",
            "Epoch 90/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3273.6450 - mae: 3274.1387 - val_loss: 3346.3906 - val_mae: 3346.8901\n",
            "Epoch 91/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3268.4927 - mae: 3268.9946 - val_loss: 3341.4082 - val_mae: 3341.9084\n",
            "Epoch 92/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3263.3191 - mae: 3263.8130 - val_loss: 3336.5032 - val_mae: 3337.0044\n",
            "Epoch 93/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3258.2661 - mae: 3258.7620 - val_loss: 3330.0930 - val_mae: 3330.5918\n",
            "Epoch 94/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3253.3857 - mae: 3253.8835 - val_loss: 3324.8833 - val_mae: 3325.3843\n",
            "Epoch 95/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3248.4419 - mae: 3248.9434 - val_loss: 3321.4963 - val_mae: 3321.9919\n",
            "Epoch 96/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3243.5347 - mae: 3244.0310 - val_loss: 3315.2937 - val_mae: 3315.7903\n",
            "Epoch 97/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3238.6201 - mae: 3239.1311 - val_loss: 3311.1350 - val_mae: 3311.6360\n",
            "Epoch 98/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3233.9072 - mae: 3234.4114 - val_loss: 3307.5325 - val_mae: 3308.0374\n",
            "Epoch 99/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3229.3284 - mae: 3229.8313 - val_loss: 3300.9966 - val_mae: 3301.4961\n",
            "Epoch 100/100\n",
            "7027/7027 [==============================] - 18s 3ms/step - loss: 3224.5391 - mae: 3225.0359 - val_loss: 3296.6753 - val_mae: 3297.1772\n",
            "3514/3514 [==============================] - 5s 1ms/step - loss: 3266.8184 - mae: 3267.3193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 3870.6487 - mae: 3871.1448 - val_loss: 3480.3733 - val_mae: 3480.8723\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2844.8047 - mae: 2845.3030 - val_loss: 2553.0200 - val_mae: 2553.5195\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2573.4241 - mae: 2573.9246 - val_loss: 2483.5300 - val_mae: 2484.0298\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2424.2109 - mae: 2424.7139 - val_loss: 2239.1492 - val_mae: 2239.6492\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2320.5962 - mae: 2321.0994 - val_loss: 2335.2075 - val_mae: 2335.7068\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2249.0039 - mae: 2249.4985 - val_loss: 2187.6353 - val_mae: 2188.1353\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2191.7930 - mae: 2192.2864 - val_loss: 2141.5288 - val_mae: 2142.0288\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2139.6560 - mae: 2140.1558 - val_loss: 2248.4639 - val_mae: 2248.9636\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2094.1689 - mae: 2094.6719 - val_loss: 2147.9395 - val_mae: 2148.4390\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2057.2051 - mae: 2057.7019 - val_loss: 2036.5387 - val_mae: 2037.0387\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2022.5864 - mae: 2023.0891 - val_loss: 1956.0483 - val_mae: 1956.5481\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1997.5118 - mae: 1998.0103 - val_loss: 2706.7229 - val_mae: 2707.2229\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1977.7739 - mae: 1978.2686 - val_loss: 2229.7612 - val_mae: 2230.2610\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1952.5967 - mae: 1953.0963 - val_loss: 1945.8628 - val_mae: 1946.3622\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1936.9510 - mae: 1937.4498 - val_loss: 2011.3541 - val_mae: 2011.8540\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1922.4293 - mae: 1922.9294 - val_loss: 1957.1906 - val_mae: 1957.6899\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1908.5685 - mae: 1909.0640 - val_loss: 1944.2942 - val_mae: 1944.7938\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1896.8743 - mae: 1897.3800 - val_loss: 2255.7612 - val_mae: 2256.2610\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1875.2258 - mae: 1875.7168 - val_loss: 1973.2717 - val_mae: 1973.7717\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1862.5581 - mae: 1863.0590 - val_loss: 1882.8560 - val_mae: 1883.3556\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1852.6880 - mae: 1853.1869 - val_loss: 1909.4858 - val_mae: 1909.9858\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1843.1370 - mae: 1843.6362 - val_loss: 1992.5414 - val_mae: 1993.0409\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1840.7482 - mae: 1841.2441 - val_loss: 2118.6423 - val_mae: 2119.1423\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1826.3136 - mae: 1826.8142 - val_loss: 2045.1499 - val_mae: 2045.6494\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1824.6239 - mae: 1825.1252 - val_loss: 1966.1022 - val_mae: 1966.6022\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1820.8043 - mae: 1821.3057 - val_loss: 1808.2399 - val_mae: 1808.7395\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1808.9232 - mae: 1809.4207 - val_loss: 1800.3936 - val_mae: 1800.8932\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1805.7968 - mae: 1806.2941 - val_loss: 1828.0460 - val_mae: 1828.5455\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1803.0695 - mae: 1803.5724 - val_loss: 1793.8102 - val_mae: 1794.3098\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1799.7705 - mae: 1800.2699 - val_loss: 1931.2734 - val_mae: 1931.7733\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1793.6588 - mae: 1794.1571 - val_loss: 1972.3817 - val_mae: 1972.8813\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1791.1428 - mae: 1791.6373 - val_loss: 1798.8051 - val_mae: 1799.3047\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1786.3257 - mae: 1786.8225 - val_loss: 1925.1461 - val_mae: 1925.6461\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1785.3304 - mae: 1785.8268 - val_loss: 1935.9091 - val_mae: 1936.4089\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1778.9242 - mae: 1779.4200 - val_loss: 1822.4277 - val_mae: 1822.9270\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1773.4618 - mae: 1773.9652 - val_loss: 1804.4625 - val_mae: 1804.9622\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1772.7083 - mae: 1773.2119 - val_loss: 1930.7727 - val_mae: 1931.2721\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1764.3877 - mae: 1764.8900 - val_loss: 2038.8197 - val_mae: 2039.3195\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1763.6230 - mae: 1764.1217 - val_loss: 1805.7980 - val_mae: 1806.2976\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 1799.3070 - mae: 1799.8066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 3917.1321 - mae: 3917.6350 - val_loss: 3489.0183 - val_mae: 3489.5181\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2872.4514 - mae: 2872.9619 - val_loss: 3406.9495 - val_mae: 3407.4500\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2583.4409 - mae: 2583.9333 - val_loss: 3033.5774 - val_mae: 3034.0769\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2421.1721 - mae: 2421.6694 - val_loss: 2313.9976 - val_mae: 2314.4973\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2303.1052 - mae: 2303.6050 - val_loss: 2334.2402 - val_mae: 2334.7400\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2222.0703 - mae: 2222.5669 - val_loss: 2189.6104 - val_mae: 2190.1104\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2170.1567 - mae: 2170.6648 - val_loss: 2454.4695 - val_mae: 2454.9692\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2129.0879 - mae: 2129.5859 - val_loss: 2036.1774 - val_mae: 2036.6771\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2090.9033 - mae: 2091.4004 - val_loss: 2889.1030 - val_mae: 2889.6033\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2068.2271 - mae: 2068.7246 - val_loss: 2379.1477 - val_mae: 2379.6472\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 2033.2765 - mae: 2033.7809 - val_loss: 2355.7693 - val_mae: 2356.2688\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2013.5989 - mae: 2014.0992 - val_loss: 2086.6831 - val_mae: 2087.1831\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1999.7640 - mae: 2000.2644 - val_loss: 2271.1680 - val_mae: 2271.6675\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1988.5933 - mae: 1989.0952 - val_loss: 2037.1290 - val_mae: 2037.6287\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1976.7908 - mae: 1977.2882 - val_loss: 2009.2838 - val_mae: 2009.7836\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1963.5627 - mae: 1964.0575 - val_loss: 1922.4320 - val_mae: 1922.9318\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1947.9529 - mae: 1948.4559 - val_loss: 1906.9441 - val_mae: 1907.4435\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1936.6129 - mae: 1937.1161 - val_loss: 2054.1230 - val_mae: 2054.6226\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1925.6647 - mae: 1926.1617 - val_loss: 1943.7448 - val_mae: 1944.2448\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1918.3722 - mae: 1918.8754 - val_loss: 1962.2688 - val_mae: 1962.7689\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1907.9000 - mae: 1908.3978 - val_loss: 1904.3651 - val_mae: 1904.8647\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1893.5710 - mae: 1894.0706 - val_loss: 2091.3784 - val_mae: 2091.8782\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1891.8252 - mae: 1892.3203 - val_loss: 1925.1417 - val_mae: 1925.6416\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1883.9788 - mae: 1884.4729 - val_loss: 1936.6135 - val_mae: 1937.1134\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1879.4043 - mae: 1879.8971 - val_loss: 1968.5482 - val_mae: 1969.0475\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1871.6301 - mae: 1872.1266 - val_loss: 2082.9861 - val_mae: 2083.4858\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1868.0383 - mae: 1868.5403 - val_loss: 2308.2339 - val_mae: 2308.7334\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1862.7108 - mae: 1863.2134 - val_loss: 2292.4475 - val_mae: 2292.9475\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1859.9125 - mae: 1860.4125 - val_loss: 2253.3677 - val_mae: 2253.8677\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1852.5048 - mae: 1852.9996 - val_loss: 1897.0662 - val_mae: 1897.5662\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1847.3138 - mae: 1847.8108 - val_loss: 1841.5889 - val_mae: 1842.0886\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1841.5529 - mae: 1842.0511 - val_loss: 2151.7039 - val_mae: 2152.2039\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1834.3571 - mae: 1834.8539 - val_loss: 1886.1090 - val_mae: 1886.6090\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1832.0920 - mae: 1832.5948 - val_loss: 1916.7760 - val_mae: 1917.2762\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1826.4215 - mae: 1826.9242 - val_loss: 1932.5592 - val_mae: 1933.0588\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1823.6354 - mae: 1824.1384 - val_loss: 1841.4352 - val_mae: 1841.9351\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1819.6901 - mae: 1820.1907 - val_loss: 2027.0396 - val_mae: 2027.5392\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1816.5083 - mae: 1817.0095 - val_loss: 2112.3728 - val_mae: 2112.8726\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1812.4392 - mae: 1812.9414 - val_loss: 2036.3348 - val_mae: 2036.8347\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1814.3958 - mae: 1814.8936 - val_loss: 1849.8834 - val_mae: 1850.3831\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1805.9393 - mae: 1806.4352 - val_loss: 1821.4972 - val_mae: 1821.9971\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1807.4460 - mae: 1807.9453 - val_loss: 1904.2410 - val_mae: 1904.7408\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1800.2278 - mae: 1800.7269 - val_loss: 1921.6460 - val_mae: 1922.1458\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1798.9169 - mae: 1799.4203 - val_loss: 2016.9020 - val_mae: 2017.4019\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1796.5532 - mae: 1797.0541 - val_loss: 1944.2853 - val_mae: 1944.7850\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1797.8461 - mae: 1798.3514 - val_loss: 2096.2180 - val_mae: 2096.7178\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1793.0560 - mae: 1793.5509 - val_loss: 2023.4899 - val_mae: 2023.9895\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1790.5913 - mae: 1791.0918 - val_loss: 1807.9712 - val_mae: 1808.4709\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1786.7284 - mae: 1787.2310 - val_loss: 1837.0400 - val_mae: 1837.5400\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1783.6970 - mae: 1784.2000 - val_loss: 2099.9365 - val_mae: 2100.4363\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1785.7924 - mae: 1786.2891 - val_loss: 2040.1731 - val_mae: 2040.6730\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1779.3345 - mae: 1779.8297 - val_loss: 1839.7389 - val_mae: 1840.2385\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1783.8405 - mae: 1784.3411 - val_loss: 1783.3163 - val_mae: 1783.8158\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1776.6438 - mae: 1777.1440 - val_loss: 2022.0426 - val_mae: 2022.5424\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1775.0669 - mae: 1775.5624 - val_loss: 1825.9867 - val_mae: 1826.4863\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1770.0005 - mae: 1770.4988 - val_loss: 1798.3907 - val_mae: 1798.8899\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1768.8462 - mae: 1769.3492 - val_loss: 1868.6533 - val_mae: 1869.1531\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1768.7723 - mae: 1769.2780 - val_loss: 1907.8240 - val_mae: 1908.3236\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1766.9185 - mae: 1767.4126 - val_loss: 1792.0668 - val_mae: 1792.5667\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1764.9049 - mae: 1765.4044 - val_loss: 1868.9326 - val_mae: 1869.4323\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1766.1047 - mae: 1766.6036 - val_loss: 2069.7688 - val_mae: 2070.2686\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1764.3171 - mae: 1764.8156 - val_loss: 1788.7755 - val_mae: 1789.2748\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1761.1088 - mae: 1761.6107 - val_loss: 1829.0582 - val_mae: 1829.5579\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 1809.2207 - mae: 1809.7205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 3927.1406 - mae: 3927.6528 - val_loss: 4206.6699 - val_mae: 4207.1680\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2879.4136 - mae: 2879.9102 - val_loss: 2558.6670 - val_mae: 2559.1670\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2582.1033 - mae: 2582.5972 - val_loss: 2380.6938 - val_mae: 2381.1938\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2432.5254 - mae: 2433.0249 - val_loss: 2624.5491 - val_mae: 2625.0491\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2317.5688 - mae: 2318.0662 - val_loss: 2921.8193 - val_mae: 2922.3191\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2237.0825 - mae: 2237.5864 - val_loss: 2195.5691 - val_mae: 2196.0691\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2178.8547 - mae: 2179.3506 - val_loss: 2521.4336 - val_mae: 2521.9329\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2112.2227 - mae: 2112.7209 - val_loss: 2087.0342 - val_mae: 2087.5339\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2073.5500 - mae: 2074.0596 - val_loss: 2099.4722 - val_mae: 2099.9719\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2038.1122 - mae: 2038.6205 - val_loss: 3092.4128 - val_mae: 3092.9124\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 2003.0958 - mae: 2003.5963 - val_loss: 2616.0164 - val_mae: 2616.5164\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1976.7972 - mae: 1977.2977 - val_loss: 2041.3929 - val_mae: 2041.8920\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1960.8585 - mae: 1961.3594 - val_loss: 2003.5040 - val_mae: 2004.0037\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1939.3518 - mae: 1939.8517 - val_loss: 2262.3784 - val_mae: 2262.8784\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1924.9773 - mae: 1925.4797 - val_loss: 2036.9584 - val_mae: 2037.4579\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1917.0243 - mae: 1917.5186 - val_loss: 1901.1079 - val_mae: 1901.6077\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1905.2321 - mae: 1905.7375 - val_loss: 1922.9126 - val_mae: 1923.4122\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1889.1366 - mae: 1889.6332 - val_loss: 1961.4817 - val_mae: 1961.9813\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1874.7142 - mae: 1875.2186 - val_loss: 1891.0150 - val_mae: 1891.5150\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1868.1681 - mae: 1868.6676 - val_loss: 1881.9969 - val_mae: 1882.4966\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1860.1654 - mae: 1860.6648 - val_loss: 1878.8698 - val_mae: 1879.3690\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1844.9554 - mae: 1845.4478 - val_loss: 1874.5104 - val_mae: 1875.0101\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1838.1349 - mae: 1838.6354 - val_loss: 2043.4818 - val_mae: 2043.9817\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1832.6498 - mae: 1833.1466 - val_loss: 1967.5435 - val_mae: 1968.0428\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1823.2418 - mae: 1823.7452 - val_loss: 1874.5109 - val_mae: 1875.0106\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1819.4402 - mae: 1819.9381 - val_loss: 1785.8793 - val_mae: 1786.3788\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1813.9990 - mae: 1814.4916 - val_loss: 2098.7161 - val_mae: 2099.2156\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1808.3521 - mae: 1808.8562 - val_loss: 1946.8960 - val_mae: 1947.3956\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1804.8242 - mae: 1805.3254 - val_loss: 1816.4224 - val_mae: 1816.9221\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1800.3479 - mae: 1800.8435 - val_loss: 2230.3416 - val_mae: 2230.8418\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 22s 3ms/step - loss: 1793.8016 - mae: 1794.2953 - val_loss: 1795.6440 - val_mae: 1796.1438\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1790.2664 - mae: 1790.7697 - val_loss: 2027.2905 - val_mae: 2027.7900\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1785.0801 - mae: 1785.5833 - val_loss: 1810.6506 - val_mae: 1811.1503\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1780.2556 - mae: 1780.7539 - val_loss: 1864.7416 - val_mae: 1865.2408\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1777.1727 - mae: 1777.6672 - val_loss: 1797.6630 - val_mae: 1798.1627\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 21s 3ms/step - loss: 1767.1785 - mae: 1767.6771 - val_loss: 1861.7158 - val_mae: 1862.2155\n",
            "3514/3514 [==============================] - 5s 2ms/step - loss: 1876.0187 - mae: 1876.5186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 5506.5190 - mae: 5507.0093 - val_loss: 3325.8940 - val_mae: 3326.3953\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2843.5591 - mae: 2844.0615 - val_loss: 2627.0295 - val_mae: 2627.5293\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2378.4480 - mae: 2378.9463 - val_loss: 2282.3921 - val_mae: 2282.8921\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2157.0466 - mae: 2157.5479 - val_loss: 2122.2583 - val_mae: 2122.7578\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2037.6881 - mae: 2038.1862 - val_loss: 2121.9192 - val_mae: 2122.4189\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1952.1782 - mae: 1952.6814 - val_loss: 2117.2253 - val_mae: 2117.7249\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1894.2356 - mae: 1894.7371 - val_loss: 2451.4075 - val_mae: 2451.9072\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1844.8585 - mae: 1845.3529 - val_loss: 2137.1357 - val_mae: 2137.6350\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1804.0051 - mae: 1804.5006 - val_loss: 2193.7539 - val_mae: 2194.2539\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1767.8602 - mae: 1768.3625 - val_loss: 2127.2217 - val_mae: 2127.7217\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1728.8154 - mae: 1729.3187 - val_loss: 1854.9009 - val_mae: 1855.4004\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1703.8435 - mae: 1704.3430 - val_loss: 1724.2567 - val_mae: 1724.7561\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1682.2939 - mae: 1682.7872 - val_loss: 1705.3872 - val_mae: 1705.8867\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1656.8593 - mae: 1657.3549 - val_loss: 2462.7861 - val_mae: 2463.2859\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1644.2390 - mae: 1644.7369 - val_loss: 1674.8826 - val_mae: 1675.3822\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1622.9878 - mae: 1623.4844 - val_loss: 1702.7369 - val_mae: 1703.2369\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1607.4597 - mae: 1607.9567 - val_loss: 1721.5897 - val_mae: 1722.0895\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1594.0704 - mae: 1594.5679 - val_loss: 1664.7057 - val_mae: 1665.2052\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1578.5215 - mae: 1579.0222 - val_loss: 1773.9052 - val_mae: 1774.4048\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1564.9210 - mae: 1565.4258 - val_loss: 1668.2928 - val_mae: 1668.7920\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1551.2319 - mae: 1551.7310 - val_loss: 1695.8690 - val_mae: 1696.3685\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1540.1780 - mae: 1540.6738 - val_loss: 1988.0963 - val_mae: 1988.5962\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1531.8488 - mae: 1532.3503 - val_loss: 1592.5693 - val_mae: 1593.0687\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1514.7468 - mae: 1515.2424 - val_loss: 1640.8492 - val_mae: 1641.3483\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1509.2102 - mae: 1509.7085 - val_loss: 1767.2755 - val_mae: 1767.7745\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1502.1136 - mae: 1502.6144 - val_loss: 1561.4490 - val_mae: 1561.9485\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1492.0137 - mae: 1492.5128 - val_loss: 1830.1382 - val_mae: 1830.6377\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1480.4972 - mae: 1480.9963 - val_loss: 1599.0118 - val_mae: 1599.5116\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1473.1278 - mae: 1473.6274 - val_loss: 1684.2540 - val_mae: 1684.7539\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1469.5209 - mae: 1470.0170 - val_loss: 1756.9069 - val_mae: 1757.4065\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1459.8151 - mae: 1460.3177 - val_loss: 1538.2545 - val_mae: 1538.7540\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1452.4347 - mae: 1452.9333 - val_loss: 1554.7932 - val_mae: 1555.2930\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1444.8420 - mae: 1445.3431 - val_loss: 1497.2009 - val_mae: 1497.7001\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1438.7789 - mae: 1439.2789 - val_loss: 1488.5935 - val_mae: 1489.0929\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1433.7091 - mae: 1434.2031 - val_loss: 1685.8436 - val_mae: 1686.3429\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1425.9867 - mae: 1426.4845 - val_loss: 1490.2290 - val_mae: 1490.7286\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1424.2775 - mae: 1424.7753 - val_loss: 1500.7037 - val_mae: 1501.2034\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1415.9539 - mae: 1416.4550 - val_loss: 1524.8433 - val_mae: 1525.3425\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1409.1656 - mae: 1409.6669 - val_loss: 1551.4457 - val_mae: 1551.9456\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1405.2174 - mae: 1405.7192 - val_loss: 1581.9923 - val_mae: 1582.4919\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1399.2523 - mae: 1399.7499 - val_loss: 1816.5985 - val_mae: 1817.0980\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1394.4666 - mae: 1394.9630 - val_loss: 1528.7129 - val_mae: 1529.2124\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1386.7537 - mae: 1387.2539 - val_loss: 1479.9423 - val_mae: 1480.4415\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1383.9137 - mae: 1384.4099 - val_loss: 1504.7859 - val_mae: 1505.2853\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1375.9615 - mae: 1376.4617 - val_loss: 1613.2734 - val_mae: 1613.7731\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1371.6035 - mae: 1372.1042 - val_loss: 1785.9766 - val_mae: 1786.4758\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1372.2766 - mae: 1372.7773 - val_loss: 1528.5933 - val_mae: 1529.0931\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1366.3474 - mae: 1366.8497 - val_loss: 1454.3600 - val_mae: 1454.8599\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1360.2781 - mae: 1360.7758 - val_loss: 1489.8218 - val_mae: 1490.3210\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1357.1160 - mae: 1357.6134 - val_loss: 1626.0490 - val_mae: 1626.5482\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1353.4480 - mae: 1353.9489 - val_loss: 1544.4706 - val_mae: 1544.9703\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1350.6057 - mae: 1351.1047 - val_loss: 1464.5953 - val_mae: 1465.0948\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1347.0176 - mae: 1347.5151 - val_loss: 1453.2268 - val_mae: 1453.7261\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1341.4719 - mae: 1341.9724 - val_loss: 1619.2249 - val_mae: 1619.7246\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1339.2516 - mae: 1339.7518 - val_loss: 1434.5402 - val_mae: 1435.0396\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1335.6890 - mae: 1336.1891 - val_loss: 1584.2499 - val_mae: 1584.7496\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1330.7443 - mae: 1331.2435 - val_loss: 1450.5382 - val_mae: 1451.0378\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1326.3069 - mae: 1326.8044 - val_loss: 1452.4824 - val_mae: 1452.9818\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1322.0022 - mae: 1322.4995 - val_loss: 1621.6372 - val_mae: 1622.1368\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1319.9030 - mae: 1320.4020 - val_loss: 1510.1842 - val_mae: 1510.6836\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1318.3347 - mae: 1318.8361 - val_loss: 1508.9957 - val_mae: 1509.4952\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1315.9800 - mae: 1316.4849 - val_loss: 1455.6410 - val_mae: 1456.1405\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1310.0146 - mae: 1310.5146 - val_loss: 1419.8004 - val_mae: 1420.3002\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1306.8599 - mae: 1307.3561 - val_loss: 1414.2612 - val_mae: 1414.7609\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1304.5208 - mae: 1305.0193 - val_loss: 1468.0659 - val_mae: 1468.5656\n",
            "Epoch 66/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1303.4098 - mae: 1303.9106 - val_loss: 1519.6661 - val_mae: 1520.1655\n",
            "Epoch 67/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1295.7737 - mae: 1296.2750 - val_loss: 1427.7434 - val_mae: 1428.2428\n",
            "Epoch 68/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1297.9799 - mae: 1298.4819 - val_loss: 1629.0333 - val_mae: 1629.5331\n",
            "Epoch 69/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1294.8651 - mae: 1295.3629 - val_loss: 1401.7877 - val_mae: 1402.2869\n",
            "Epoch 70/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1290.7811 - mae: 1291.2783 - val_loss: 1409.5028 - val_mae: 1410.0026\n",
            "Epoch 71/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1287.6017 - mae: 1288.1045 - val_loss: 1373.7125 - val_mae: 1374.2124\n",
            "Epoch 72/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1284.6660 - mae: 1285.1625 - val_loss: 1447.4170 - val_mae: 1447.9164\n",
            "Epoch 73/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1283.2172 - mae: 1283.7157 - val_loss: 1501.2572 - val_mae: 1501.7567\n",
            "Epoch 74/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1280.8494 - mae: 1281.3483 - val_loss: 1450.9150 - val_mae: 1451.4147\n",
            "Epoch 75/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1278.0055 - mae: 1278.5027 - val_loss: 1432.6265 - val_mae: 1433.1257\n",
            "Epoch 76/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1275.5491 - mae: 1276.0496 - val_loss: 1525.9688 - val_mae: 1526.4681\n",
            "Epoch 77/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1274.2479 - mae: 1274.7488 - val_loss: 1577.6644 - val_mae: 1578.1641\n",
            "Epoch 78/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1270.6289 - mae: 1271.1263 - val_loss: 1386.2095 - val_mae: 1386.7091\n",
            "Epoch 79/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1270.3701 - mae: 1270.8704 - val_loss: 1412.8992 - val_mae: 1413.3987\n",
            "Epoch 80/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1267.0667 - mae: 1267.5658 - val_loss: 1431.8164 - val_mae: 1432.3154\n",
            "Epoch 81/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1266.4199 - mae: 1266.9205 - val_loss: 1398.5620 - val_mae: 1399.0616\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 1397.7769 - mae: 1398.2762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 5499.9106 - mae: 5500.3960 - val_loss: 3439.6179 - val_mae: 3440.1165\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 2922.7114 - mae: 2923.2078 - val_loss: 2962.4724 - val_mae: 2962.9724\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2398.3667 - mae: 2398.8604 - val_loss: 2350.1272 - val_mae: 2350.6265\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2150.3450 - mae: 2150.8503 - val_loss: 2107.5996 - val_mae: 2108.0991\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2022.7751 - mae: 2023.2820 - val_loss: 2129.2900 - val_mae: 2129.7898\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1939.3363 - mae: 1939.8361 - val_loss: 1952.5554 - val_mae: 1953.0551\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1878.0450 - mae: 1878.5450 - val_loss: 1915.2665 - val_mae: 1915.7661\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1834.7062 - mae: 1835.2050 - val_loss: 2159.7527 - val_mae: 2160.2527\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1793.8015 - mae: 1794.3027 - val_loss: 1826.0024 - val_mae: 1826.5023\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1760.1696 - mae: 1760.6705 - val_loss: 1782.2919 - val_mae: 1782.7915\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1733.5936 - mae: 1734.0950 - val_loss: 1853.4198 - val_mae: 1853.9194\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1711.9531 - mae: 1712.4542 - val_loss: 1819.7301 - val_mae: 1820.2297\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1691.0278 - mae: 1691.5319 - val_loss: 1745.3800 - val_mae: 1745.8799\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1673.0804 - mae: 1673.5791 - val_loss: 1726.6437 - val_mae: 1727.1431\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1658.2399 - mae: 1658.7314 - val_loss: 1682.4281 - val_mae: 1682.9279\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1641.8005 - mae: 1642.2950 - val_loss: 1811.8817 - val_mae: 1812.3810\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1624.8799 - mae: 1625.3843 - val_loss: 2061.2705 - val_mae: 2061.7693\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 26s 4ms/step - loss: 1612.2839 - mae: 1612.7819 - val_loss: 1919.5770 - val_mae: 1920.0764\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1601.1969 - mae: 1601.6995 - val_loss: 1726.8394 - val_mae: 1727.3389\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1587.8115 - mae: 1588.3114 - val_loss: 1708.4237 - val_mae: 1708.9231\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1577.6987 - mae: 1578.1962 - val_loss: 1861.3789 - val_mae: 1861.8785\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1565.3739 - mae: 1565.8759 - val_loss: 1717.1650 - val_mae: 1717.6642\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1557.2954 - mae: 1557.7950 - val_loss: 1607.2516 - val_mae: 1607.7509\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1547.1047 - mae: 1547.6089 - val_loss: 1631.1130 - val_mae: 1631.6129\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1541.2317 - mae: 1541.7339 - val_loss: 1719.6759 - val_mae: 1720.1753\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1530.2620 - mae: 1530.7620 - val_loss: 1654.5078 - val_mae: 1655.0073\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1524.3057 - mae: 1524.8018 - val_loss: 1704.4287 - val_mae: 1704.9283\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1518.4137 - mae: 1518.9076 - val_loss: 1581.8688 - val_mae: 1582.3683\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1509.2273 - mae: 1509.7230 - val_loss: 1557.1346 - val_mae: 1557.6344\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1501.9603 - mae: 1502.4584 - val_loss: 1698.1031 - val_mae: 1698.6030\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1494.8429 - mae: 1495.3464 - val_loss: 1786.8772 - val_mae: 1787.3765\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1490.0935 - mae: 1490.5950 - val_loss: 1553.3682 - val_mae: 1553.8676\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1481.3400 - mae: 1481.8409 - val_loss: 1517.6003 - val_mae: 1518.1001\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1473.6074 - mae: 1474.1003 - val_loss: 1773.3260 - val_mae: 1773.8254\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1468.5826 - mae: 1469.0842 - val_loss: 1762.6591 - val_mae: 1763.1588\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1462.7251 - mae: 1463.2273 - val_loss: 1513.9731 - val_mae: 1514.4729\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1459.2137 - mae: 1459.7157 - val_loss: 1537.1398 - val_mae: 1537.6393\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1452.3639 - mae: 1452.8654 - val_loss: 1516.5189 - val_mae: 1517.0187\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1448.4755 - mae: 1448.9774 - val_loss: 1628.1318 - val_mae: 1628.6309\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1443.9086 - mae: 1444.4105 - val_loss: 1626.1736 - val_mae: 1626.6729\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1439.6454 - mae: 1440.1423 - val_loss: 1509.9453 - val_mae: 1510.4451\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1435.1608 - mae: 1435.6627 - val_loss: 1518.7368 - val_mae: 1519.2365\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1429.7091 - mae: 1430.2086 - val_loss: 1665.2626 - val_mae: 1665.7622\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1423.4774 - mae: 1423.9764 - val_loss: 1497.4325 - val_mae: 1497.9320\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1417.5529 - mae: 1418.0505 - val_loss: 1670.7114 - val_mae: 1671.2112\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1417.3815 - mae: 1417.8776 - val_loss: 1513.4062 - val_mae: 1513.9059\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1410.4921 - mae: 1410.9937 - val_loss: 1488.3840 - val_mae: 1488.8835\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1407.9364 - mae: 1408.4337 - val_loss: 1748.9022 - val_mae: 1749.4015\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1405.1121 - mae: 1405.6117 - val_loss: 1488.7555 - val_mae: 1489.2551\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1398.7943 - mae: 1399.2906 - val_loss: 1510.9469 - val_mae: 1511.4464\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1396.5651 - mae: 1397.0671 - val_loss: 1485.7006 - val_mae: 1486.2002\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1393.4893 - mae: 1393.9868 - val_loss: 1481.4515 - val_mae: 1481.9512\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1386.3036 - mae: 1386.8018 - val_loss: 1585.4205 - val_mae: 1585.9202\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1385.4679 - mae: 1385.9689 - val_loss: 1603.6278 - val_mae: 1604.1274\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1381.9443 - mae: 1382.4420 - val_loss: 1463.3577 - val_mae: 1463.8564\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1378.3990 - mae: 1378.8999 - val_loss: 1474.2476 - val_mae: 1474.7469\n",
            "Epoch 57/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1373.1234 - mae: 1373.6215 - val_loss: 1506.3058 - val_mae: 1506.8047\n",
            "Epoch 58/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1371.4176 - mae: 1371.9163 - val_loss: 1712.5450 - val_mae: 1713.0447\n",
            "Epoch 59/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1368.3488 - mae: 1368.8457 - val_loss: 1474.0610 - val_mae: 1474.5607\n",
            "Epoch 60/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1363.6853 - mae: 1364.1862 - val_loss: 1492.2820 - val_mae: 1492.7814\n",
            "Epoch 61/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1363.7384 - mae: 1364.2377 - val_loss: 1836.7106 - val_mae: 1837.2102\n",
            "Epoch 62/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1363.8407 - mae: 1364.3401 - val_loss: 1555.1310 - val_mae: 1555.6304\n",
            "Epoch 63/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1358.7766 - mae: 1359.2708 - val_loss: 1520.1046 - val_mae: 1520.6042\n",
            "Epoch 64/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1352.7655 - mae: 1353.2634 - val_loss: 1765.0087 - val_mae: 1765.5082\n",
            "Epoch 65/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1354.8618 - mae: 1355.3616 - val_loss: 1530.8644 - val_mae: 1531.3638\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 1524.2343 - mae: 1524.7339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 26s 4ms/step - loss: 5537.4053 - mae: 5537.8892 - val_loss: 3787.8999 - val_mae: 3788.3997\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2923.7773 - mae: 2924.2839 - val_loss: 2653.9822 - val_mae: 2654.4814\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2410.5940 - mae: 2411.0896 - val_loss: 2382.5327 - val_mae: 2383.0322\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 2174.2976 - mae: 2174.8013 - val_loss: 2190.1138 - val_mae: 2190.6135\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 2043.0841 - mae: 2043.5839 - val_loss: 2014.8861 - val_mae: 2015.3855\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1948.2651 - mae: 1948.7579 - val_loss: 1988.4454 - val_mae: 1988.9452\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1885.0135 - mae: 1885.5099 - val_loss: 1950.2505 - val_mae: 1950.7504\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1835.6379 - mae: 1836.1360 - val_loss: 1840.2166 - val_mae: 1840.7159\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1793.3635 - mae: 1793.8590 - val_loss: 1862.9662 - val_mae: 1863.4656\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1759.8868 - mae: 1760.3889 - val_loss: 1927.0706 - val_mae: 1927.5698\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1727.2335 - mae: 1727.7321 - val_loss: 1917.5889 - val_mae: 1918.0886\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1698.1567 - mae: 1698.6542 - val_loss: 1861.1560 - val_mae: 1861.6554\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1673.3269 - mae: 1673.8247 - val_loss: 1756.3848 - val_mae: 1756.8840\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1652.1124 - mae: 1652.6102 - val_loss: 1860.9569 - val_mae: 1861.4565\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1634.3383 - mae: 1634.8398 - val_loss: 1757.0907 - val_mae: 1757.5903\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1613.6453 - mae: 1614.1436 - val_loss: 1631.3513 - val_mae: 1631.8508\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1596.8461 - mae: 1597.3455 - val_loss: 1627.8513 - val_mae: 1628.3508\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1583.5953 - mae: 1584.0917 - val_loss: 1669.9216 - val_mae: 1670.4209\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1573.0948 - mae: 1573.5935 - val_loss: 1781.7837 - val_mae: 1782.2833\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1556.2793 - mae: 1556.7798 - val_loss: 1626.7140 - val_mae: 1627.2139\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1540.4745 - mae: 1540.9706 - val_loss: 1610.0504 - val_mae: 1610.5497\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1530.7104 - mae: 1531.2109 - val_loss: 1578.7742 - val_mae: 1579.2738\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1522.3187 - mae: 1522.8192 - val_loss: 1666.8755 - val_mae: 1667.3750\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1511.0193 - mae: 1511.5203 - val_loss: 1754.5643 - val_mae: 1755.0636\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1503.2211 - mae: 1503.7159 - val_loss: 1706.2950 - val_mae: 1706.7946\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1495.8976 - mae: 1496.3970 - val_loss: 1562.0088 - val_mae: 1562.5083\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1485.5718 - mae: 1486.0630 - val_loss: 1589.8066 - val_mae: 1590.3059\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1475.5920 - mae: 1476.0908 - val_loss: 1677.4849 - val_mae: 1677.9846\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1466.6953 - mae: 1467.1937 - val_loss: 1558.7682 - val_mae: 1559.2676\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1461.4017 - mae: 1461.9017 - val_loss: 1604.6904 - val_mae: 1605.1903\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1450.5220 - mae: 1451.0243 - val_loss: 1502.2825 - val_mae: 1502.7817\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1445.7417 - mae: 1446.2435 - val_loss: 1512.5514 - val_mae: 1513.0513\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1438.0479 - mae: 1438.5471 - val_loss: 1552.0167 - val_mae: 1552.5161\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1435.0074 - mae: 1435.5084 - val_loss: 1496.1570 - val_mae: 1496.6567\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1423.6953 - mae: 1424.1946 - val_loss: 1490.9812 - val_mae: 1491.4805\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1420.0663 - mae: 1420.5677 - val_loss: 1515.9951 - val_mae: 1516.4943\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1417.8676 - mae: 1418.3722 - val_loss: 1554.8201 - val_mae: 1555.3195\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1409.9028 - mae: 1410.4041 - val_loss: 1530.3134 - val_mae: 1530.8132\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1404.2937 - mae: 1404.7925 - val_loss: 1489.7445 - val_mae: 1490.2440\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1401.1344 - mae: 1401.6307 - val_loss: 1567.6023 - val_mae: 1568.1019\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1391.6759 - mae: 1392.1725 - val_loss: 1510.1381 - val_mae: 1510.6378\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1391.4844 - mae: 1391.9861 - val_loss: 1496.0090 - val_mae: 1496.5084\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1385.0107 - mae: 1385.5134 - val_loss: 1447.9148 - val_mae: 1448.4138\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1380.0864 - mae: 1380.5857 - val_loss: 1705.5889 - val_mae: 1706.0886\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1377.0670 - mae: 1377.5696 - val_loss: 1439.2974 - val_mae: 1439.7972\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1374.4784 - mae: 1374.9808 - val_loss: 1501.7451 - val_mae: 1502.2445\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1370.8568 - mae: 1371.3571 - val_loss: 1462.3254 - val_mae: 1462.8250\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1364.9181 - mae: 1365.4236 - val_loss: 1619.2483 - val_mae: 1619.7479\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1360.0221 - mae: 1360.5216 - val_loss: 1442.5825 - val_mae: 1443.0824\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1355.9677 - mae: 1356.4658 - val_loss: 1441.1165 - val_mae: 1441.6161\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1355.6575 - mae: 1356.1558 - val_loss: 1440.4542 - val_mae: 1440.9539\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1349.4546 - mae: 1349.9546 - val_loss: 1503.4124 - val_mae: 1503.9117\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1344.5664 - mae: 1345.0664 - val_loss: 1583.7764 - val_mae: 1584.2760\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1341.7751 - mae: 1342.2748 - val_loss: 1525.8287 - val_mae: 1526.3284\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1338.4110 - mae: 1338.9110 - val_loss: 1487.3477 - val_mae: 1487.8475\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 1497.2808 - mae: 1497.7806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 26s 4ms/step - loss: 4155.9922 - mae: 4156.5078 - val_loss: 2912.9556 - val_mae: 2913.4558\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2762.0017 - mae: 2762.5095 - val_loss: 2391.2886 - val_mae: 2391.7886\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2412.9036 - mae: 2413.4021 - val_loss: 2739.0732 - val_mae: 2739.5725\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2223.1155 - mae: 2223.6199 - val_loss: 2191.2109 - val_mae: 2191.7100\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2098.3997 - mae: 2098.9006 - val_loss: 2049.8979 - val_mae: 2050.3977\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2008.8030 - mae: 2009.3107 - val_loss: 2436.6838 - val_mae: 2437.1836\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1934.3765 - mae: 1934.8737 - val_loss: 1832.2549 - val_mae: 1832.7543\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1877.8414 - mae: 1878.3419 - val_loss: 1818.8103 - val_mae: 1819.3099\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1838.9078 - mae: 1839.4054 - val_loss: 1951.4197 - val_mae: 1951.9193\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1797.9235 - mae: 1798.4197 - val_loss: 2733.6594 - val_mae: 2734.1592\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1765.5968 - mae: 1766.0985 - val_loss: 2334.7588 - val_mae: 2335.2583\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1728.0277 - mae: 1728.5250 - val_loss: 2104.2441 - val_mae: 2104.7437\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1707.4213 - mae: 1707.9165 - val_loss: 1914.6437 - val_mae: 1915.1433\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1676.8170 - mae: 1677.3193 - val_loss: 1647.1997 - val_mae: 1647.6996\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1666.5669 - mae: 1667.0632 - val_loss: 1862.0677 - val_mae: 1862.5675\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1645.7756 - mae: 1646.2743 - val_loss: 1672.2939 - val_mae: 1672.7936\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1633.0835 - mae: 1633.5837 - val_loss: 1620.4645 - val_mae: 1620.9639\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1620.9194 - mae: 1621.4196 - val_loss: 1972.4258 - val_mae: 1972.9252\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1603.7233 - mae: 1604.2159 - val_loss: 2206.8894 - val_mae: 2207.3887\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1589.5607 - mae: 1590.0570 - val_loss: 1556.0626 - val_mae: 1556.5624\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1579.4440 - mae: 1579.9390 - val_loss: 1572.1166 - val_mae: 1572.6162\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1571.3599 - mae: 1571.8563 - val_loss: 2268.4272 - val_mae: 2268.9270\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1565.0192 - mae: 1565.5199 - val_loss: 2103.2925 - val_mae: 2103.7917\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1556.0750 - mae: 1556.5712 - val_loss: 1836.7975 - val_mae: 1837.2971\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1547.3169 - mae: 1547.8180 - val_loss: 1535.2731 - val_mae: 1535.7727\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1531.1273 - mae: 1531.6288 - val_loss: 1543.7184 - val_mae: 1544.2180\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1523.8087 - mae: 1524.3049 - val_loss: 1861.8411 - val_mae: 1862.3407\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1510.0076 - mae: 1510.5052 - val_loss: 1513.8213 - val_mae: 1514.3209\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1502.1685 - mae: 1502.6660 - val_loss: 1579.1772 - val_mae: 1579.6770\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1501.5402 - mae: 1502.0399 - val_loss: 1636.2404 - val_mae: 1636.7400\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1492.0239 - mae: 1492.5214 - val_loss: 2058.4805 - val_mae: 2058.9805\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1486.9034 - mae: 1487.4034 - val_loss: 1698.7106 - val_mae: 1699.2100\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1479.9905 - mae: 1480.4921 - val_loss: 1749.4387 - val_mae: 1749.9382\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1477.3691 - mae: 1477.8695 - val_loss: 1522.0771 - val_mae: 1522.5764\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1465.5068 - mae: 1466.0020 - val_loss: 1687.3030 - val_mae: 1687.8022\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1470.3126 - mae: 1470.8146 - val_loss: 1932.7543 - val_mae: 1933.2537\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1459.9434 - mae: 1460.4418 - val_loss: 2453.6760 - val_mae: 2454.1760\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1462.0194 - mae: 1462.5200 - val_loss: 1482.2312 - val_mae: 1482.7306\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1451.7623 - mae: 1452.2627 - val_loss: 1774.9730 - val_mae: 1775.4723\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1446.4225 - mae: 1446.9214 - val_loss: 1491.8080 - val_mae: 1492.3075\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1448.2415 - mae: 1448.7375 - val_loss: 1479.6704 - val_mae: 1480.1699\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1440.7579 - mae: 1441.2538 - val_loss: 1479.7294 - val_mae: 1480.2291\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1433.1559 - mae: 1433.6569 - val_loss: 1490.1740 - val_mae: 1490.6735\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1431.9520 - mae: 1432.4513 - val_loss: 1452.1887 - val_mae: 1452.6884\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 26s 4ms/step - loss: 1429.8873 - mae: 1430.3864 - val_loss: 1475.9122 - val_mae: 1476.4119\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1425.8336 - mae: 1426.3363 - val_loss: 1445.9998 - val_mae: 1446.4995\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1415.4971 - mae: 1415.9991 - val_loss: 1694.6897 - val_mae: 1695.1893\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1414.2542 - mae: 1414.7516 - val_loss: 1519.9834 - val_mae: 1520.4830\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1411.7886 - mae: 1412.2887 - val_loss: 1890.0012 - val_mae: 1890.5011\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1413.1719 - mae: 1413.6708 - val_loss: 1538.1312 - val_mae: 1538.6310\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1406.8282 - mae: 1407.3264 - val_loss: 1661.1738 - val_mae: 1661.6731\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1402.3851 - mae: 1402.8868 - val_loss: 1458.4240 - val_mae: 1458.9235\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1400.0945 - mae: 1400.5906 - val_loss: 1497.0922 - val_mae: 1497.5919\n",
            "Epoch 54/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1394.4584 - mae: 1394.9565 - val_loss: 1550.9066 - val_mae: 1551.4062\n",
            "Epoch 55/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1399.2511 - mae: 1399.7507 - val_loss: 1461.1672 - val_mae: 1461.6670\n",
            "Epoch 56/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1396.3804 - mae: 1396.8807 - val_loss: 2415.4849 - val_mae: 2415.9841\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 2397.1675 - mae: 2397.6672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 4134.8687 - mae: 4135.3667 - val_loss: 2703.6631 - val_mae: 2704.1626\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 2671.0610 - mae: 2671.5696 - val_loss: 2414.1191 - val_mae: 2414.6189\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2342.3818 - mae: 2342.8865 - val_loss: 2166.7085 - val_mae: 2167.2083\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 2158.8855 - mae: 2159.3770 - val_loss: 2174.5481 - val_mae: 2175.0471\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2058.3542 - mae: 2058.8511 - val_loss: 3021.8801 - val_mae: 3022.3799\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1984.6508 - mae: 1985.1539 - val_loss: 1840.9489 - val_mae: 1841.4485\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1919.1820 - mae: 1919.6829 - val_loss: 1953.0200 - val_mae: 1953.5194\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1867.5651 - mae: 1868.0725 - val_loss: 2837.7498 - val_mae: 2838.2495\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1826.1494 - mae: 1826.6479 - val_loss: 1882.5759 - val_mae: 1883.0756\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1784.1775 - mae: 1784.6752 - val_loss: 2019.8572 - val_mae: 2020.3571\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1752.8013 - mae: 1753.3038 - val_loss: 1845.2194 - val_mae: 1845.7186\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1730.8145 - mae: 1731.3129 - val_loss: 2120.9102 - val_mae: 2121.4102\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1703.1271 - mae: 1703.6306 - val_loss: 1837.7465 - val_mae: 1838.2463\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1674.7913 - mae: 1675.2937 - val_loss: 1829.7004 - val_mae: 1830.1998\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1647.4396 - mae: 1647.9364 - val_loss: 1828.6188 - val_mae: 1829.1184\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1631.9769 - mae: 1632.4811 - val_loss: 1596.3879 - val_mae: 1596.8878\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1613.7817 - mae: 1614.2831 - val_loss: 2050.8259 - val_mae: 2051.3259\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1591.7656 - mae: 1592.2642 - val_loss: 1814.4978 - val_mae: 1814.9974\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1579.1455 - mae: 1579.6423 - val_loss: 1690.6298 - val_mae: 1691.1294\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1568.8365 - mae: 1569.3339 - val_loss: 1961.6796 - val_mae: 1962.1794\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1557.8706 - mae: 1558.3691 - val_loss: 1601.3380 - val_mae: 1601.8376\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1539.6163 - mae: 1540.1162 - val_loss: 1761.2109 - val_mae: 1761.7106\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1533.5789 - mae: 1534.0804 - val_loss: 1601.4081 - val_mae: 1601.9077\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1521.5734 - mae: 1522.0686 - val_loss: 1537.2734 - val_mae: 1537.7728\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1516.3536 - mae: 1516.8522 - val_loss: 1703.8877 - val_mae: 1704.3871\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1504.5126 - mae: 1505.0068 - val_loss: 1531.3071 - val_mae: 1531.8069\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1500.5374 - mae: 1501.0366 - val_loss: 1548.7415 - val_mae: 1549.2412\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1497.3699 - mae: 1497.8696 - val_loss: 2293.0710 - val_mae: 2293.5708\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1488.8613 - mae: 1489.3594 - val_loss: 1585.7583 - val_mae: 1586.2581\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1480.9733 - mae: 1481.4783 - val_loss: 1716.8573 - val_mae: 1717.3569\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1472.3630 - mae: 1472.8632 - val_loss: 2112.4006 - val_mae: 2112.9004\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 25s 4ms/step - loss: 1466.7568 - mae: 1467.2506 - val_loss: 1505.9221 - val_mae: 1506.4216\n",
            "Epoch 33/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1468.8536 - mae: 1469.3536 - val_loss: 1876.2325 - val_mae: 1876.7321\n",
            "Epoch 34/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1456.1880 - mae: 1456.6825 - val_loss: 1788.2745 - val_mae: 1788.7743\n",
            "Epoch 35/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1450.2183 - mae: 1450.7207 - val_loss: 1919.8402 - val_mae: 1920.3401\n",
            "Epoch 36/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1450.9532 - mae: 1451.4575 - val_loss: 1485.2710 - val_mae: 1485.7708\n",
            "Epoch 37/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1445.5228 - mae: 1446.0186 - val_loss: 1485.3356 - val_mae: 1485.8351\n",
            "Epoch 38/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1440.0565 - mae: 1440.5568 - val_loss: 1657.8428 - val_mae: 1658.3427\n",
            "Epoch 39/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1439.2733 - mae: 1439.7716 - val_loss: 1596.1685 - val_mae: 1596.6678\n",
            "Epoch 40/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1429.3323 - mae: 1429.8374 - val_loss: 1546.7328 - val_mae: 1547.2323\n",
            "Epoch 41/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1430.9440 - mae: 1431.4432 - val_loss: 1847.0734 - val_mae: 1847.5732\n",
            "Epoch 42/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1428.3047 - mae: 1428.7983 - val_loss: 1477.3405 - val_mae: 1477.8402\n",
            "Epoch 43/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1424.9546 - mae: 1425.4559 - val_loss: 1455.5712 - val_mae: 1456.0708\n",
            "Epoch 44/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1418.0182 - mae: 1418.5178 - val_loss: 1481.5376 - val_mae: 1482.0375\n",
            "Epoch 45/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1417.6686 - mae: 1418.1680 - val_loss: 1503.8324 - val_mae: 1504.3320\n",
            "Epoch 46/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1414.0829 - mae: 1414.5804 - val_loss: 1801.8420 - val_mae: 1802.3416\n",
            "Epoch 47/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1409.9041 - mae: 1410.4033 - val_loss: 1634.0686 - val_mae: 1634.5684\n",
            "Epoch 48/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1405.7599 - mae: 1406.2561 - val_loss: 1544.5050 - val_mae: 1545.0049\n",
            "Epoch 49/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1401.1680 - mae: 1401.6692 - val_loss: 1717.3385 - val_mae: 1717.8381\n",
            "Epoch 50/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1398.9891 - mae: 1399.4872 - val_loss: 1614.6996 - val_mae: 1615.1992\n",
            "Epoch 51/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 1397.9404 - mae: 1398.4426 - val_loss: 1785.4639 - val_mae: 1785.9635\n",
            "Epoch 52/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1396.1204 - mae: 1396.6201 - val_loss: 1547.1090 - val_mae: 1547.6084\n",
            "Epoch 53/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1391.1528 - mae: 1391.6519 - val_loss: 1590.6919 - val_mae: 1591.1915\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 1599.7938 - mae: 1600.2936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7027/7027 [==============================] - 25s 3ms/step - loss: 4064.7791 - mae: 4065.2739 - val_loss: 2769.4402 - val_mae: 2769.9399\n",
            "Epoch 2/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2718.3770 - mae: 2718.8826 - val_loss: 3113.9658 - val_mae: 3114.4653\n",
            "Epoch 3/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2380.3906 - mae: 2380.8933 - val_loss: 2276.2346 - val_mae: 2276.7344\n",
            "Epoch 4/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2201.8638 - mae: 2202.3640 - val_loss: 2808.4963 - val_mae: 2808.9963\n",
            "Epoch 5/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 2078.5017 - mae: 2078.9980 - val_loss: 2197.9482 - val_mae: 2198.4480\n",
            "Epoch 6/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1997.7661 - mae: 1998.2693 - val_loss: 1912.0315 - val_mae: 1912.5310\n",
            "Epoch 7/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1928.1943 - mae: 1928.6964 - val_loss: 2214.2737 - val_mae: 2214.7734\n",
            "Epoch 8/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1880.4111 - mae: 1880.9124 - val_loss: 1905.5553 - val_mae: 1906.0554\n",
            "Epoch 9/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1821.7391 - mae: 1822.2371 - val_loss: 2286.8962 - val_mae: 2287.3958\n",
            "Epoch 10/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1782.4539 - mae: 1782.9562 - val_loss: 2990.4011 - val_mae: 2990.9006\n",
            "Epoch 11/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1741.0298 - mae: 1741.5272 - val_loss: 1694.3455 - val_mae: 1694.8447\n",
            "Epoch 12/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1715.8530 - mae: 1716.3514 - val_loss: 1796.4663 - val_mae: 1796.9658\n",
            "Epoch 13/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1694.3728 - mae: 1694.8678 - val_loss: 1681.0629 - val_mae: 1681.5624\n",
            "Epoch 14/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1678.7667 - mae: 1679.2621 - val_loss: 1813.9841 - val_mae: 1814.4838\n",
            "Epoch 15/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1660.0774 - mae: 1660.5724 - val_loss: 2032.2190 - val_mae: 2032.7189\n",
            "Epoch 16/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1643.2402 - mae: 1643.7432 - val_loss: 1677.7410 - val_mae: 1678.2408\n",
            "Epoch 17/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1629.5612 - mae: 1630.0603 - val_loss: 1747.6542 - val_mae: 1748.1541\n",
            "Epoch 18/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1615.4351 - mae: 1615.9368 - val_loss: 1618.0537 - val_mae: 1618.5533\n",
            "Epoch 19/100\n",
            "7027/7027 [==============================] - 23s 3ms/step - loss: 1603.3438 - mae: 1603.8448 - val_loss: 1629.8240 - val_mae: 1630.3236\n",
            "Epoch 20/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1586.6764 - mae: 1587.1798 - val_loss: 1891.9642 - val_mae: 1892.4641\n",
            "Epoch 21/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1582.4789 - mae: 1582.9735 - val_loss: 1564.2728 - val_mae: 1564.7726\n",
            "Epoch 22/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1566.9230 - mae: 1567.4208 - val_loss: 1532.5524 - val_mae: 1533.0519\n",
            "Epoch 23/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1562.9795 - mae: 1563.4763 - val_loss: 1789.9144 - val_mae: 1790.4139\n",
            "Epoch 24/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1557.4570 - mae: 1557.9543 - val_loss: 1606.5529 - val_mae: 1607.0527\n",
            "Epoch 25/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1546.7441 - mae: 1547.2427 - val_loss: 2066.4309 - val_mae: 2066.9307\n",
            "Epoch 26/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1537.9429 - mae: 1538.4427 - val_loss: 2097.7097 - val_mae: 2098.2092\n",
            "Epoch 27/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1530.1957 - mae: 1530.6940 - val_loss: 2120.5874 - val_mae: 2121.0869\n",
            "Epoch 28/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1524.0819 - mae: 1524.5870 - val_loss: 1932.0969 - val_mae: 1932.5967\n",
            "Epoch 29/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1516.8440 - mae: 1517.3416 - val_loss: 1711.7689 - val_mae: 1712.2686\n",
            "Epoch 30/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1507.3707 - mae: 1507.8669 - val_loss: 1799.9312 - val_mae: 1800.4305\n",
            "Epoch 31/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1500.0516 - mae: 1500.5581 - val_loss: 1544.0781 - val_mae: 1544.5775\n",
            "Epoch 32/100\n",
            "7027/7027 [==============================] - 24s 3ms/step - loss: 1496.2555 - mae: 1496.7572 - val_loss: 1730.0107 - val_mae: 1730.5106\n",
            "3514/3514 [==============================] - 6s 2ms/step - loss: 1742.9541 - mae: 1743.4537\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10540/10540 [==============================] - 35s 3ms/step - loss: 4661.2700 - mae: 4661.7617 - val_loss: 2927.7227 - val_mae: 2928.2224\n",
            "Epoch 2/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 2498.3064 - mae: 2498.8076 - val_loss: 2230.3440 - val_mae: 2230.8440\n",
            "Epoch 3/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 2127.2610 - mae: 2127.7593 - val_loss: 1995.1874 - val_mae: 1995.6870\n",
            "Epoch 4/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1971.1987 - mae: 1971.6949 - val_loss: 1996.2921 - val_mae: 1996.7917\n",
            "Epoch 5/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1881.0580 - mae: 1881.5515 - val_loss: 2371.0771 - val_mae: 2371.5769\n",
            "Epoch 6/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1819.3152 - mae: 1819.8137 - val_loss: 1875.6112 - val_mae: 1876.1110\n",
            "Epoch 7/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1768.5088 - mae: 1769.0048 - val_loss: 1828.0723 - val_mae: 1828.5719\n",
            "Epoch 8/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1731.0962 - mae: 1731.5959 - val_loss: 1722.1952 - val_mae: 1722.6948\n",
            "Epoch 9/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1698.6936 - mae: 1699.1976 - val_loss: 1684.8618 - val_mae: 1685.3613\n",
            "Epoch 10/100\n",
            "10540/10540 [==============================] - 36s 3ms/step - loss: 1668.2178 - mae: 1668.7163 - val_loss: 1871.3478 - val_mae: 1871.8474\n",
            "Epoch 11/100\n",
            "10540/10540 [==============================] - 36s 3ms/step - loss: 1645.7446 - mae: 1646.2479 - val_loss: 2032.2249 - val_mae: 2032.7245\n",
            "Epoch 12/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1621.6375 - mae: 1622.1342 - val_loss: 1600.3955 - val_mae: 1600.8951\n",
            "Epoch 13/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1601.0430 - mae: 1601.5436 - val_loss: 1702.6001 - val_mae: 1703.0994\n",
            "Epoch 14/100\n",
            "10540/10540 [==============================] - 36s 3ms/step - loss: 1584.0812 - mae: 1584.5775 - val_loss: 1597.6465 - val_mae: 1598.1456\n",
            "Epoch 15/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1568.5099 - mae: 1569.0160 - val_loss: 1571.7799 - val_mae: 1572.2791\n",
            "Epoch 16/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1555.1022 - mae: 1555.5997 - val_loss: 1565.6376 - val_mae: 1566.1370\n",
            "Epoch 17/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1539.6960 - mae: 1540.1925 - val_loss: 1640.4127 - val_mae: 1640.9124\n",
            "Epoch 18/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1529.9724 - mae: 1530.4753 - val_loss: 1564.2598 - val_mae: 1564.7594\n",
            "Epoch 19/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1519.2283 - mae: 1519.7250 - val_loss: 1588.6371 - val_mae: 1589.1368\n",
            "Epoch 20/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1505.6383 - mae: 1506.1379 - val_loss: 1554.8895 - val_mae: 1555.3889\n",
            "Epoch 21/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1496.7875 - mae: 1497.2880 - val_loss: 1550.1660 - val_mae: 1550.6655\n",
            "Epoch 22/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1491.2549 - mae: 1491.7604 - val_loss: 1823.3064 - val_mae: 1823.8059\n",
            "Epoch 23/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1478.5538 - mae: 1479.0557 - val_loss: 1642.5869 - val_mae: 1643.0864\n",
            "Epoch 24/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1469.5325 - mae: 1470.0302 - val_loss: 1619.0966 - val_mae: 1619.5964\n",
            "Epoch 25/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1463.8123 - mae: 1464.3099 - val_loss: 1817.5100 - val_mae: 1818.0094\n",
            "Epoch 26/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1456.5717 - mae: 1457.0674 - val_loss: 1526.6890 - val_mae: 1527.1884\n",
            "Epoch 27/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1448.6938 - mae: 1449.1965 - val_loss: 1508.8849 - val_mae: 1509.3844\n",
            "Epoch 28/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1440.6384 - mae: 1441.1378 - val_loss: 1474.8918 - val_mae: 1475.3912\n",
            "Epoch 29/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1435.7476 - mae: 1436.2455 - val_loss: 1490.8716 - val_mae: 1491.3710\n",
            "Epoch 30/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1427.9897 - mae: 1428.4873 - val_loss: 1541.1140 - val_mae: 1541.6136\n",
            "Epoch 31/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1420.8090 - mae: 1421.3132 - val_loss: 1463.9415 - val_mae: 1464.4409\n",
            "Epoch 32/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1418.4313 - mae: 1418.9319 - val_loss: 1643.2234 - val_mae: 1643.7233\n",
            "Epoch 33/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1412.5798 - mae: 1413.0819 - val_loss: 1489.6984 - val_mae: 1490.1979\n",
            "Epoch 34/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1406.1926 - mae: 1406.6864 - val_loss: 1455.1825 - val_mae: 1455.6820\n",
            "Epoch 35/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1401.2311 - mae: 1401.7291 - val_loss: 1472.0586 - val_mae: 1472.5579\n",
            "Epoch 36/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1395.7361 - mae: 1396.2344 - val_loss: 1535.7930 - val_mae: 1536.2925\n",
            "Epoch 37/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1390.0846 - mae: 1390.5865 - val_loss: 1458.6820 - val_mae: 1459.1816\n",
            "Epoch 38/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1385.3975 - mae: 1385.8982 - val_loss: 1434.1731 - val_mae: 1434.6726\n",
            "Epoch 39/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1380.6169 - mae: 1381.1113 - val_loss: 1471.5302 - val_mae: 1472.0294\n",
            "Epoch 40/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1372.7866 - mae: 1373.2925 - val_loss: 1411.8132 - val_mae: 1412.3126\n",
            "Epoch 41/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1373.0527 - mae: 1373.5493 - val_loss: 1602.9670 - val_mae: 1603.4664\n",
            "Epoch 42/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1366.4307 - mae: 1366.9232 - val_loss: 1483.0511 - val_mae: 1483.5505\n",
            "Epoch 43/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1361.8462 - mae: 1362.3447 - val_loss: 1592.7739 - val_mae: 1593.2736\n",
            "Epoch 44/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1357.2339 - mae: 1357.7374 - val_loss: 1528.8643 - val_mae: 1529.3636\n",
            "Epoch 45/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1354.3123 - mae: 1354.8169 - val_loss: 1417.4768 - val_mae: 1417.9764\n",
            "Epoch 46/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1349.1565 - mae: 1349.6549 - val_loss: 1598.6433 - val_mae: 1599.1426\n",
            "Epoch 47/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1347.0126 - mae: 1347.5135 - val_loss: 1472.1575 - val_mae: 1472.6571\n",
            "Epoch 48/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1343.3746 - mae: 1343.8760 - val_loss: 1438.1936 - val_mae: 1438.6936\n",
            "Epoch 49/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1339.4933 - mae: 1339.9960 - val_loss: 1401.5887 - val_mae: 1402.0881\n",
            "Epoch 50/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1333.0325 - mae: 1333.5360 - val_loss: 1413.1564 - val_mae: 1413.6558\n",
            "Epoch 51/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1330.2161 - mae: 1330.7145 - val_loss: 1414.6958 - val_mae: 1415.1948\n",
            "Epoch 52/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1326.3247 - mae: 1326.8180 - val_loss: 1388.2877 - val_mae: 1388.7871\n",
            "Epoch 53/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1323.0249 - mae: 1323.5226 - val_loss: 1385.0128 - val_mae: 1385.5123\n",
            "Epoch 54/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1320.0347 - mae: 1320.5347 - val_loss: 1500.0531 - val_mae: 1500.5532\n",
            "Epoch 55/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1316.1951 - mae: 1316.6930 - val_loss: 1389.9102 - val_mae: 1390.4095\n",
            "Epoch 56/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1314.5405 - mae: 1315.0391 - val_loss: 1379.1794 - val_mae: 1379.6788\n",
            "Epoch 57/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1308.3630 - mae: 1308.8611 - val_loss: 1500.3552 - val_mae: 1500.8546\n",
            "Epoch 58/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1306.8822 - mae: 1307.3773 - val_loss: 1382.2761 - val_mae: 1382.7758\n",
            "Epoch 59/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1306.9620 - mae: 1307.4630 - val_loss: 1459.3546 - val_mae: 1459.8541\n",
            "Epoch 60/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1301.0688 - mae: 1301.5658 - val_loss: 1383.2469 - val_mae: 1383.7466\n",
            "Epoch 61/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1300.8058 - mae: 1301.3098 - val_loss: 1414.9634 - val_mae: 1415.4629\n",
            "Epoch 62/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1297.9427 - mae: 1298.4379 - val_loss: 1378.3362 - val_mae: 1378.8354\n",
            "Epoch 63/100\n",
            "10540/10540 [==============================] - 36s 3ms/step - loss: 1293.4031 - mae: 1293.9036 - val_loss: 1345.8087 - val_mae: 1346.3077\n",
            "Epoch 64/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1291.8716 - mae: 1292.3732 - val_loss: 1432.4304 - val_mae: 1432.9291\n",
            "Epoch 65/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1288.1825 - mae: 1288.6823 - val_loss: 1363.2469 - val_mae: 1363.7463\n",
            "Epoch 66/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1285.3379 - mae: 1285.8396 - val_loss: 1342.3586 - val_mae: 1342.8578\n",
            "Epoch 67/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1283.9113 - mae: 1284.4093 - val_loss: 1425.6123 - val_mae: 1426.1119\n",
            "Epoch 68/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1278.6495 - mae: 1279.1492 - val_loss: 1338.0880 - val_mae: 1338.5875\n",
            "Epoch 69/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1277.9875 - mae: 1278.4880 - val_loss: 1343.5771 - val_mae: 1344.0764\n",
            "Epoch 70/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1274.4259 - mae: 1274.9253 - val_loss: 1361.9714 - val_mae: 1362.4708\n",
            "Epoch 71/100\n",
            "10540/10540 [==============================] - 35s 3ms/step - loss: 1273.6306 - mae: 1274.1311 - val_loss: 1339.7961 - val_mae: 1340.2954\n",
            "Epoch 72/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1270.3140 - mae: 1270.8148 - val_loss: 1370.7729 - val_mae: 1371.2726\n",
            "Epoch 73/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1269.2034 - mae: 1269.7047 - val_loss: 1383.3423 - val_mae: 1383.8417\n",
            "Epoch 74/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1264.1157 - mae: 1264.6176 - val_loss: 1358.1042 - val_mae: 1358.6040\n",
            "Epoch 75/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1264.1874 - mae: 1264.6904 - val_loss: 1363.3672 - val_mae: 1363.8666\n",
            "Epoch 76/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1262.2670 - mae: 1262.7681 - val_loss: 1403.4774 - val_mae: 1403.9768\n",
            "Epoch 77/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1259.1190 - mae: 1259.6172 - val_loss: 1414.6888 - val_mae: 1415.1884\n",
            "Epoch 78/100\n",
            "10540/10540 [==============================] - 34s 3ms/step - loss: 1258.6799 - mae: 1259.1797 - val_loss: 1347.0918 - val_mae: 1347.5913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fb5902d8ad0>,\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions={'dropout': [0.1, 0.2, 0.3],\n",
              "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fb5902d87d0>,\n",
              "                                        'n_hidden': [1, 2, 3, 4, 5, 6],\n",
              "                                        'n_neurons': array([ 1,  2...\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
              "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
              "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
              "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
              "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDz_EAtlUTUn",
        "outputId": "e1645e3e-67e3-4b96-f474-b1480ba534fa"
      },
      "source": [
        "rnd_search_cv.best_score_"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1473.0972900390625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKphSU6c-9ss",
        "outputId": "d09ae11d-5841-45ad-a08b-b989839e760d"
      },
      "source": [
        "rnd_search_cv.best_params_"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dropout': 0.1,\n",
              " 'learning_rate': 0.0004020110173006439,\n",
              " 'n_hidden': 6,\n",
              " 'n_neurons': 88}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G8rDQkM_D7M"
      },
      "source": [
        "# make predictions and submission\n",
        "y_pred = rnd_search_cv.best_estimator_.model.predict(X_test_tr) \n",
        "sample_submission[\"Weekly_Sales\"] = y_pred\n",
        "save_dataframe(sample_submission, \"deep_learning_rnd_search.csv\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJwe10kU_qNp"
      },
      "source": [
        "# save the model\n",
        "model_path = \"/content/drive/MyDrive/workspace/walmart/models\"\n",
        "\n",
        "def save_model(model, model_name, path=model_path):\n",
        "    path = os.path.join(model_path, model_name)\n",
        "    model.save(path)\n",
        "\n",
        "save_model(rnd_search_cv.best_estimator_.model, \"dnn_rnd_search.h5\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5YMzb5fCJga"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}