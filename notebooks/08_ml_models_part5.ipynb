{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lpJTOeTezcK0"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# for making the output constant across all run\n",
    "np.random.seed(42)\n",
    "\n",
    "# display settings & code formatting\n",
    "pd.options.display.max_columns = 999\n",
    "%matplotlib inline\n",
    "\n",
    "# project paths\n",
    "# project_root_dir = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "\n",
    "# data_path = os.path.join(project_root_dir, \"data\")\n",
    "# os.makedirs(data_path, exist_ok=True)\n",
    "\n",
    "data_path = \"/content/drive/MyDrive/workspace/walmart/data\"\n",
    "\n",
    "# function for loading data\n",
    "def read_data(filename, date_col=None, data_path=data_path):\n",
    "    csv_path = os.path.join(data_path, filename)\n",
    "    return pd.read_csv(csv_path, parse_dates=date_col)\n",
    "\n",
    "# function for saving data as csv file\n",
    "def save_dataframe(df, filename, file_path=data_path):\n",
    "    path = os.path.join(file_path, filename)\n",
    "    df.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1NkjG3mhzoNA"
   },
   "outputs": [],
   "source": [
    "train = read_data(\"train.csv\", date_col=[\"Date\"])\n",
    "test = read_data(\"test.csv\", date_col=[\"Date\"])\n",
    "stores = read_data(\"stores.csv\")\n",
    "features = read_data(\"features.csv\", date_col=[\"Date\"])\n",
    "sample_submission = read_data(\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7UfKZcyzsS4",
    "outputId": "1e481718-853a-4805-9478-e4b33cd3c12f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: FutureWarning:\n",
      "\n",
      "Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: FutureWarning:\n",
      "\n",
      "Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Merge the stores data with train and test\n",
    "train = pd.merge(train, stores, how=\"left\", on=\"Store\")\n",
    "test = pd.merge(test, stores, how=\"left\", on=\"Store\")\n",
    "\n",
    "# Merge the features data with train and test\n",
    "train = pd.merge(train, features, how=\"left\", on=[\"Store\", \"Date\"])\n",
    "test = pd.merge(test, features, how=\"left\", on=[\"Store\", \"Date\"])\n",
    "\n",
    "train.drop([\"IsHoliday_y\"], axis=1, inplace=True)\n",
    "test.drop([\"IsHoliday_y\"], axis=1, inplace=True)\n",
    "\n",
    "# rename column\n",
    "train.rename(columns={\"IsHoliday_x\": \"IsHoliday\"}, inplace=True)\n",
    "test.rename(columns={\"IsHoliday_x\": \"IsHoliday\"}, inplace=True)\n",
    "\n",
    "## Datetime features\n",
    "train[\"Year\"] = train[\"Date\"].dt.year\n",
    "train[\"Month\"] = train[\"Date\"].dt.month\n",
    "train[\"Day\"] = train[\"Date\"].dt.day\n",
    "train[\"WeekOfYear\"] = train[\"Date\"].dt.weekofyear\n",
    "train[\"DayOfWeek\"] = train[\"Date\"].dt.dayofweek\n",
    "train[\"Weekend\"] = (train[\"Date\"].dt.weekday >= 5).astype(int)\n",
    "\n",
    "test[\"Year\"] = test[\"Date\"].dt.year\n",
    "test[\"Month\"] = test[\"Date\"].dt.month\n",
    "test[\"Day\"] = test[\"Date\"].dt.day\n",
    "test[\"WeekOfYear\"] = test[\"Date\"].dt.weekofyear\n",
    "test[\"DayOfWeek\"] = test[\"Date\"].dt.dayofweek\n",
    "test[\"Weekend\"] = (test[\"Date\"].dt.weekday >= 5).astype(int)\n",
    "\n",
    "# convert boolean column to categorical column\n",
    "train[\"IsHoliday\"] = train[\"IsHoliday\"].map({True: \"Yes\", False: \"No\"})\n",
    "test[\"IsHoliday\"] = test[\"IsHoliday\"].map({True: \"Yes\", False: \"No\"})\n",
    "train[\"IsHoliday\"] = train[\"IsHoliday\"].astype(\"category\")\n",
    "test[\"IsHoliday\"] = test[\"IsHoliday\"].astype(\"category\")\n",
    "\n",
    "# ordered the categorical store type col\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "cat_type = CategoricalDtype(categories=[\"C\", \"B\", \"A\"], ordered=True)\n",
    "train[\"Type\"] = train[\"Type\"].astype(cat_type)\n",
    "test[\"Type\"] = test[\"Type\"].astype(cat_type)\n",
    "\n",
    "# convert to categorical columns\n",
    "train[\"Store\"] = train[\"Store\"].astype(\"category\")\n",
    "train[\"Dept\"] = train[\"Dept\"].astype(\"category\")\n",
    "train[\"Year\"] = train[\"Year\"].astype(\"category\")\n",
    "train[\"Month\"] = train[\"Month\"].astype(\"category\")\n",
    "train[\"DayOfWeek\"] = train[\"DayOfWeek\"].astype(\"category\")\n",
    "train[\"Weekend\"] = train[\"Weekend\"].astype(\"category\")\n",
    "\n",
    "# convert to categorical columns\n",
    "test[\"Store\"] = test[\"Store\"].astype(\"category\")\n",
    "test[\"Dept\"] = test[\"Dept\"].astype(\"category\")\n",
    "test[\"Year\"] = test[\"Year\"].astype(\"category\")\n",
    "test[\"Month\"] = test[\"Month\"].astype(\"category\")\n",
    "test[\"DayOfWeek\"] = test[\"DayOfWeek\"].astype(\"category\")\n",
    "test[\"Weekend\"] = test[\"Weekend\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVUXtpTxz3US",
    "outputId": "2bd7d63f-24c8-473e-92cb-db796c9eb930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('num',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='median',\n",
       "                                                                verbose=0)),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True))],\n",
       "                                          verbose...\n",
       "                                          steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value='NA',\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='constant',\n",
       "                                                                verbose=0)),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                sparse=False))],\n",
       "                                          verbose=False),\n",
       "                                 ['Store', 'Dept', 'IsHoliday', 'Type', 'Year',\n",
       "                                  'Month', 'DayOfWeek', 'Weekend'])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# features and labels of train and test set\n",
    "# labels of test are not provided as we need to predict them\n",
    "\n",
    "X_train = train.drop([\"Weekly_Sales\"], axis=1).copy()\n",
    "y_train = train[\"Weekly_Sales\"].copy()\n",
    "\n",
    "X_test = test.copy()\n",
    "\n",
    "# drop and save the date column in a variable\n",
    "train_date = X_train.pop(\"Date\")\n",
    "test_date = X_test.pop(\"Date\")\n",
    "\n",
    "\n",
    "#### Data preparation pipeline\n",
    "\n",
    "# select numerical and categorical columns\n",
    "num_cols = X_train.select_dtypes(exclude=[\"object\", \"category\"]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# numerical date preprocessing pipeline\n",
    "num_pipe = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "\n",
    "# categorical data preprocessing pipeline\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "\n",
    "# full pipeline\n",
    "full_pipe = ColumnTransformer(\n",
    "    [(\"num\", num_pipe, num_cols), (\"cat\", cat_pipe, cat_cols)]\n",
    ")\n",
    "\n",
    "full_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "r0l64ukSz6u2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full = X_train.copy()\n",
    "y_train_full = y_train.copy()\n",
    "\n",
    "# randomly select 30% of the data only\n",
    "train = pd.concat([X_train, y_train], axis='columns')\n",
    "train = train.sample(frac=0.3, random_state=42)\n",
    "\n",
    "X_train = train.drop([\"Weekly_Sales\"], axis=1).copy()\n",
    "y_train = train[\"Weekly_Sales\"].copy()\n",
    "\n",
    "# now divide it to train and validation set\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0PFFkcwz_6_"
   },
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "teLmudqA0Mrc",
    "outputId": "8583768e-8c7a-4180-b4a2-8689023c2615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntransformer',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None,\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='median',\n",
       "                                                                                                        v...\n",
       "                                                     scale_pos_weight=1,\n",
       "                                                     seed=None, silent=None,\n",
       "                                                     subsample=1,\n",
       "                                                     tree_method='gpu_hist',\n",
       "                                                     verbosity=1))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'xgbregressor__learning_rate': [0.1, 0.2, 0.3, 0.4,\n",
       "                                                         0.5, 0.6, 0.7, 0.8,\n",
       "                                                         0.9],\n",
       "                         'xgbregressor__max_depth': [6, 9, 12, 15, 18, 21, 24]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_reg = make_pipeline(full_pipe, XGBRegressor(objective= \"reg:squarederror\", random_state=42, tree_method=\"gpu_hist\", n_jobs=-1,))\n",
    "\n",
    "params = {\n",
    "    \"xgbregressor__learning_rate\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"xgbregressor__max_depth\": list(range(6,27, 3))\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator= xgb_reg,\n",
    "    param_grid = params,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=3\n",
    ")\n",
    "xgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aMPb2IzJ5fMc",
    "outputId": "10806e21-23e4-49a7-b568-ce25c6b74b07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1779.5820899296223"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1UUu00xNALq",
    "outputId": "9881f686-fb21-4886-a90a-05a347e13528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbregressor__learning_rate': 0.2, 'xgbregressor__max_depth': 24}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cr4S3q91NFib"
   },
   "outputs": [],
   "source": [
    "# make submission\n",
    "y_pred = xgb_grid.best_estimator_.predict(X_test)\n",
    "sample_submission[\"Weekly_Sales\"] = y_pred\n",
    "save_dataframe(sample_submission, \"xgb_tunned_lr_max_depth.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pt_QdCf1NdrX",
    "outputId": "3fa0eaf4-36b1-40c8-d68a-f713e611449f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntransformer',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None,\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='median',\n",
       "                                                                                                        v...\n",
       "                                                     tree_method='gpu_hist',\n",
       "                                                     verbosity=1))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'xgbregressor__colsample_bylevel': [0, 0.1, 0.2, 0.3,\n",
       "                                                             0.4, 0.5, 0.6, 0.7,\n",
       "                                                             0.8, 0.9, 1],\n",
       "                         'xgbregressor__colsample_bytree': [0, 0.1, 0.2, 0.3,\n",
       "                                                            0.4, 0.5, 0.6, 0.7,\n",
       "                                                            0.8, 0.9, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_reg = make_pipeline(full_pipe, XGBRegressor(objective= \"reg:squarederror\",\n",
    "                                                learning_rate=0.2, \n",
    "                                                max_depth= 24,\n",
    "                                                min_child_weight=4,\n",
    "                                                random_state=42, \n",
    "                                                tree_method=\"gpu_hist\", \n",
    "                                                n_jobs=-1,))\n",
    "\n",
    "params = {\n",
    "    \"xgbregressor__colsample_bytree\": [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    \"xgbregressor__colsample_bylevel\": [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator= xgb_reg,\n",
    "    param_grid = params,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=3\n",
    ")\n",
    "xgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYKHaedNQOdi",
    "outputId": "5273b281-02cb-4ac8-8b83-a289976c364b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1744.6734322330256"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sbLzeH1Za15-",
    "outputId": "a34f1fa7-497f-46e0-90f1-9af1b9862088"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbregressor__colsample_bylevel': 0.9, 'xgbregressor__colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyBBKymna5my"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_reg = make_pipeline(full_pipe, XGBRegressor(objective= \"reg:squarederror\",\n",
    "                                                learning_rate=0.2, \n",
    "                                                max_depth= 24,\n",
    "                                                min_child_weight=4,\n",
    "                                                colsample_bylevel=0.9,\n",
    "                                                colsample_bytree=0.9,\n",
    "                                                random_state=42, \n",
    "                                                tree_method=\"gpu_hist\", \n",
    "                                                n_jobs=-1,))\n",
    "xgb_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# make submission\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "sample_submission[\"Weekly_Sales\"] = y_pred\n",
    "save_dataframe(sample_submission, \"xgb_tunned_lr_md_mc_col_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juUHT6sx2-xX"
   },
   "source": [
    "Now, this models performance is very similar to the random forest model and this is also by far the best xgboost model that we have created. The hyper-parameter tunning is going in the right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwZwTmwR4eqf",
    "outputId": "09303461-3988-4d8a-b1c8-7e5065226236"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('columntransformer',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value=None,\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy='median',\n",
       "                                                                                                        v...\n",
       "                                                     reg_alpha=27, reg_lambda=1,\n",
       "                                                     scale_pos_weight=1,\n",
       "                                                     seed=None, silent=None,\n",
       "                                                     subsample=1,\n",
       "                                                     tree_method='gpu_hist',\n",
       "                                                     verbosity=1))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'xgbregressor__tree_method': ['auto', 'exact',\n",
       "                                                       'approx', 'hist',\n",
       "                                                       'gpu_hist']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_reg = make_pipeline(full_pipe, XGBRegressor(objective= \"reg:squarederror\",\n",
    "                                                learning_rate=0.2, \n",
    "                                                max_depth= 24,\n",
    "                                                min_child_weight=4,\n",
    "                                                colsample_bylevel=0.9,\n",
    "                                                colsample_bytree=0.9,\n",
    "                                                reg_alpha=27,\n",
    "                                                random_state=42, \n",
    "                                                tree_method=\"gpu_hist\", \n",
    "                                                n_jobs=-1,))\n",
    "\n",
    "params = {\n",
    "    \"xgbregressor__tree_method\": [\"auto\", \"exact\", \"approx\", \"hist\", \"gpu_hist\"]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator= xgb_reg,\n",
    "    param_grid = params,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=3\n",
    ")\n",
    "xgb_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r1LAYRQw6eFC",
    "outputId": "7cfab582-dcf5-469e-8e62-d3f813c107ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1737.078187289079"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILE6Jv_09nv2",
    "outputId": "633f4f98-518d-4844-9be1-2a82a51d966e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xgbregressor__tree_method': 'approx'}"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4thCoucuENDQ"
   },
   "outputs": [],
   "source": [
    "xgb_reg = make_pipeline(full_pipe, XGBRegressor(objective= \"reg:squarederror\",\n",
    "                                                learning_rate=0.2, \n",
    "                                                max_depth= 24,\n",
    "                                                min_child_weight=4,\n",
    "                                                colsample_bylevel=0.9,\n",
    "                                                colsample_bytree=0.9,\n",
    "                                                reg_alpha=27,\n",
    "                                                tree_method=\"approx\",\n",
    "                                                random_state=42, \n",
    "                                                n_jobs=-1,))\n",
    "\n",
    "xgb_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# make submission\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "sample_submission[\"Weekly_Sales\"] = y_pred\n",
    "save_dataframe(sample_submission, \"xgb_tree_method_approx_tunned_params.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJB9kNmxlD8b"
   },
   "source": [
    "This model has beatean every other models we have used so far even the rf model. Now, let's try to find of the optimal number of trees to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zeCy3PfoqzoN"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "xgb_reg = make_pipeline(full_pipe, XGBRegressor(objective= \"reg:squarederror\",\n",
    "                                                n_estimators=3000,\n",
    "                                                learning_rate=0.2, \n",
    "                                                max_depth= 24,\n",
    "                                                min_child_weight=4,\n",
    "                                                colsample_bylevel=0.9,\n",
    "                                                colsample_bytree=0.9,\n",
    "                                                reg_alpha=27,\n",
    "                                                tree_method=\"gpu_hist\",\n",
    "                                                random_state=42, \n",
    "                                                n_jobs=-1,))\n",
    "\n",
    "xgb_reg.fit(X_train_full, y_train_full)\n",
    "\n",
    "# make submission\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "sample_submission[\"Weekly_Sales\"] = y_pred\n",
    "save_dataframe(sample_submission, \"xgb_final_without_early_stopping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRYwXCLHGs48",
    "outputId": "9c7602f9-43e6-4c94-bb32-277bbab06dd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('standardscaler',\n",
       "                                                                   StandardScaler(...\n",
       "                              colsample_bylevel=0.9, colsample_bynode=1,\n",
       "                              colsample_bytree=0.9, gamma=0,\n",
       "                              importance_type='gain', learning_rate=0.2,\n",
       "                              max_delta_step=0, max_depth=24,\n",
       "                              min_child_weight=4, missing=None,\n",
       "                              n_estimators=700, n_jobs=-1, nthread=None,\n",
       "                              objective='reg:squarederror', random_state=42,\n",
       "                              reg_alpha=27, reg_lambda=1, scale_pos_weight=1,\n",
       "                              seed=None, silent=None, subsample=1,\n",
       "                              tree_method='approx', verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "xgb_reg = make_pipeline(full_pipe, XGBRegressor(objective= \"reg:squarederror\",\n",
    "                                                n_estimators=700,\n",
    "                                                learning_rate=0.2,\n",
    "                                                max_depth= 24,\n",
    "                                                min_child_weight=4,\n",
    "                                                colsample_bylevel=0.9,\n",
    "                                                colsample_bytree=0.9,\n",
    "                                                reg_alpha=27,\n",
    "                                                tree_method=\"approx\",\n",
    "                                                random_state=42,\n",
    "                                                n_jobs=-1))\n",
    "\n",
    "xgb_reg.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPLMRFKaKCcF"
   },
   "outputs": [],
   "source": [
    "# make submission\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "sample_submission[\"Weekly_Sales\"] = y_pred\n",
    "save_dataframe(sample_submission, \"xgb_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jLTD3k-9D4d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
